{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvKyhdlTZvlM",
        "outputId": "73405d98-baf7-4e67-dfb2-af14dfd3ff1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch Version:  1.13.0\n",
            "Torchvision Version:  0.14.0\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parameter as Parameter\n",
        "import time\n",
        "import random\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import os\n",
        "print(\"PyTorch Version: \", torch.__version__)\n",
        "print(\"Torchvision Version: \", torchvision.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBgXUCr0Sb6d",
        "outputId": "ae75170e-5023-463d-adc7-abaaf76e7850"
      },
      "outputs": [],
      "source": [
        "folder = r'./'\n",
        "\n",
        "net_fn = os.path.join(folder, 'binarized_net.pt')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size = 50 # the original paper use batch size of 50 on CIFAR-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rl_CArykGs6L",
        "outputId": "2c392615-2394-4782-adce-c9aa8074013c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose(\n",
        "  [transforms.ToTensor(),\n",
        "  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "trainset = torchvision.datasets.CIFAR10(root='./../data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "testset = torchvision.datasets.CIFAR10(root='./../data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "w859n_WnZ6lQ"
      },
      "outputs": [],
      "source": [
        "def hard_sigmoid(x):\n",
        "  return torch.clamp((x+1)/2, 0, 1) # The clip function\n",
        "\n",
        "def binarize(W, binary=\"stochastic\"):\n",
        "  if binary == \"stochastic\": # Stochastic binarization\n",
        "    sigma = hard_sigmoid(W)\n",
        "    Wb = torch.distributions.binomial.Binomial(total_count=1, probs=sigma).sample()\n",
        "    Wb = torch.where(Wb==0, torch.tensor(-1., device=device), torch.tensor(1., device=device)) # If we want to binarize the network with 0 and 1, we can delete this line\n",
        "  elif binary == \"deterministic\": # Deterministic binarization with 1 and -1\n",
        "    Wb = torch.where(W >= 0, torch.tensor(1., device=device), torch.tensor(-1., device=device)) # https://pytorch.org/docs/stable/generated/torch.where.html\n",
        "    # Wb = torch.where(W >= 0.5, torch.tensor(1., device=device), torch.tensor(0, device=device)) # Deterministic binarization with 1 and 0\n",
        "  else:\n",
        "    Wb = W\n",
        "  return Wb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SQEJumq9hZxd"
      },
      "outputs": [],
      "source": [
        "class binConv2d(nn.Conv2d):\n",
        "  def __init__(self, *kargs, **kwargs):\n",
        "    super(binConv2d, self).__init__(*kargs, **kwargs)\n",
        "    self.require_binarization = True\n",
        "  \n",
        "  def forward(self, input):\n",
        "    if not hasattr(self.weight, 'org'):\n",
        "      self.weight.org = self.weight.data.clone()\n",
        "    if self.training:\n",
        "      self.weight.data = binarize(self.weight.org, binary=\"stochastic\")\n",
        "    output = nn.functional.conv2d(input, self.weight, None, self.stride, self.padding, self.dilation, self.groups)\n",
        "    return output\n",
        "\n",
        "class binLinear(nn.Linear):\n",
        "  def __init__(self, *kargs, **kwargs):\n",
        "    super(binLinear, self).__init__(*kargs, **kwargs)\n",
        "    self.require_binarization = True\n",
        "  \n",
        "  def forward(self, input):\n",
        "    if not hasattr(self.weight, 'org'):\n",
        "      self.weight.org=self.weight.data.clone()\n",
        "    if self.training:\n",
        "      self.weight.data = binarize(self.weight.org, binary=\"stochastic\")\n",
        "    output = nn.functional.linear(input, self.weight, None)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kIHmjhpluxaQ"
      },
      "outputs": [],
      "source": [
        "class BinaryNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(BinaryNet, self).__init__()\n",
        "    self.features = nn.Sequential(\n",
        "        binConv2d(in_channels=3, out_channels=128, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(num_features=128, affine=False),\n",
        "        # nn.BatchNorm2d(num_features=128, affine=True),\n",
        "        nn.ReLU(),\n",
        "        binConv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(num_features=128, affine=False),\n",
        "        # nn.BatchNorm2d(num_features=128, affine=True),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
        "\n",
        "        binConv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(num_features=256, affine=False),\n",
        "        # nn.BatchNorm2d(num_features=256, affine=True),\n",
        "        nn.ReLU(),\n",
        "        binConv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(num_features=256, affine=False),\n",
        "        # nn.BatchNorm2d(num_features=256, affine=True),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
        "\n",
        "        binConv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(num_features=512, affine=False),\n",
        "        # nn.BatchNorm2d(num_features=512, affine=True),\n",
        "        nn.ReLU(),\n",
        "        binConv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(num_features=512, affine=False),\n",
        "        # nn.BatchNorm2d(num_features=512, affine=True),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
        "\n",
        "        binConv2d(in_channels=512, out_channels=1024, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(num_features=1024, affine=False),\n",
        "        # nn.BatchNorm2d(num_features=1024, affine=True),\n",
        "        nn.ReLU(),\n",
        "        binConv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(num_features=1024, affine=False),\n",
        "        # nn.BatchNorm2d(num_features=1024, affine=True),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
        "    )\n",
        "    self.classifiers = nn.Sequential(\n",
        "        binLinear(4096, 1024),\n",
        "        nn.BatchNorm1d(1024, affine=False),\n",
        "        # nn.BatchNorm1d(1024, affine=True),\n",
        "        binLinear(1024, 10),\n",
        "        nn.BatchNorm1d(10, affine=False),\n",
        "        # nn.BatchNorm1d(10, affine=True),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.features(x)\n",
        "    x = x.view(x.shape[0], -1)\n",
        "    x = self.classifiers(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaUH0eTu5qeP",
        "outputId": "24cf6785-63b6-4f32-deb1-79f0c52fa665"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_epochs: 500  learning_rate_start: 0.003  learning_rate_final: 2e-06  learning_rate_decay: 0.9854800059995851\n",
            "BinaryNet(\n",
            "  (features): Sequential(\n",
            "    (0): binConv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): binConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (5): ReLU()\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): binConv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (9): ReLU()\n",
            "    (10): binConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (12): ReLU()\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): binConv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (16): ReLU()\n",
            "    (17): binConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (19): ReLU()\n",
            "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (21): binConv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (23): ReLU()\n",
            "    (24): binConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (26): ReLU()\n",
            "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifiers): Sequential(\n",
            "    (0): binLinear(in_features=4096, out_features=1024, bias=True)\n",
            "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (2): binLinear(in_features=1024, out_features=10, bias=True)\n",
            "    (3): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# criterion = nn.HingeEmbeddingLoss(size_average=True)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "num_epochs = 500\n",
        "LR_start = 3 * 1e-3\n",
        "LR_fin = 2 * 1e-6\n",
        "LR_decay = (LR_fin/LR_start)**(1./num_epochs)\n",
        "LR = LR_start\n",
        "net = BinaryNet()\n",
        "print(\"num_epochs:\", num_epochs, \" learning_rate_start:\", LR_start, \" learning_rate_final:\", LR_fin, \" learning_rate_decay:\", LR_decay)\n",
        "print(net)\n",
        "net = net.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "eaC9y9jXBRGE"
      },
      "outputs": [],
      "source": [
        "def validate_model(model, dataloader, n = None):\n",
        "    \n",
        "    # Set to evaluation mode rather than training mode\n",
        "    model.eval()\n",
        "\n",
        "    top1 = 0\n",
        "    total = 0\n",
        "\n",
        "    # Iterate over data stopping early if n is set\n",
        "    for i, (inputs, labels) in enumerate(dataloader):\n",
        "        if (n is not None and i >= n):\n",
        "            break\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # Run the model and collect the top 1 outputs.\n",
        "        # print(model.features[0].weight.data)\n",
        "        outputs = model(inputs)\n",
        "        # print(model.features[0].weight.data)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        # Gather statistics\n",
        "        top1 += torch.sum(predicted == labels.data)\n",
        "        total += len(outputs)\n",
        "\n",
        "    top1_acc = 100 * top1.double() / total\n",
        "    model.train()\n",
        "    return top1_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "gDvu1d4yOeR4",
        "outputId": "e83a6e75-e15d-4fe1-a3d5-9ca740ddb51a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eopch:  1 , learning rate:  0.003\n",
            "eopch:  1 , training loss:  0.049302230114936826\n",
            "eopch:  1 , accuracy:  tensor(10., device='cuda:0', dtype=torch.float64)\n",
            "eopch:  2 , learning rate:  0.002956440017998755\n",
            "eopch:  2 , training loss:  0.044884957950115205\n",
            "eopch:  2 , accuracy:  tensor(10.0600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  3 , learning rate:  0.0029135125266748266\n",
            "eopch:  3 , training loss:  0.03844877072334289\n",
            "eopch:  3 , accuracy:  tensor(11.4800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  4 , learning rate:  0.0028712083422673743\n",
            "eopch:  4 , training loss:  0.035327272353172304\n",
            "eopch:  4 , accuracy:  tensor(19.5400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  5 , learning rate:  0.0028295184143637105\n",
            "eopch:  5 , training loss:  0.03337651978254318\n",
            "eopch:  5 , accuracy:  tensor(21.6100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  6 , learning rate:  0.002788433823963086\n",
            "eopch:  6 , training loss:  0.031594787750244144\n",
            "eopch:  6 , accuracy:  tensor(25.7500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  7 , learning rate:  0.002747945781568588\n",
            "eopch:  7 , training loss:  0.029828749969005586\n",
            "eopch:  7 , accuracy:  tensor(30.0500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  8 , learning rate:  0.0027080456253067466\n",
            "eopch:  8 , training loss:  0.02828107973098755\n",
            "eopch:  8 , accuracy:  tensor(41.7900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  9 , learning rate:  0.0026687248190744427\n",
            "eopch:  9 , training loss:  0.02670663489818573\n",
            "eopch:  9 , accuracy:  tensor(49.6000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  10 , learning rate:  0.0026299749507127236\n",
            "eopch:  10 , training loss:  0.025071993960142137\n",
            "eopch:  10 , accuracy:  tensor(58.1700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  11 , learning rate:  0.0025917877302071334\n",
            "eopch:  11 , training loss:  0.02363123168349266\n",
            "eopch:  11 , accuracy:  tensor(62.4400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  12 , learning rate:  0.002554154987914177\n",
            "eopch:  12 , training loss:  0.022454632169008254\n",
            "eopch:  12 , accuracy:  tensor(67.3900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  13 , learning rate:  0.002517068672813533\n",
            "eopch:  13 , training loss:  0.021375894594192504\n",
            "eopch:  13 , accuracy:  tensor(69.1000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  14 , learning rate:  0.002480520850785648\n",
            "eopch:  14 , training loss:  0.02035841586112976\n",
            "eopch:  14 , accuracy:  tensor(70.4800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  15 , learning rate:  0.0024445037029143363\n",
            "eopch:  15 , training loss:  0.019514741171598435\n",
            "eopch:  15 , accuracy:  tensor(74.5200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  16 , learning rate:  0.002409009523814028\n",
            "eopch:  16 , training loss:  0.018619782663583755\n",
            "eopch:  16 , accuracy:  tensor(74.8900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  17 , learning rate:  0.002374030719981306\n",
            "eopch:  17 , training loss:  0.01800492154121399\n",
            "eopch:  17 , accuracy:  tensor(76.6100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  18 , learning rate:  0.0023395598081703767\n",
            "eopch:  18 , training loss:  0.01730711917042732\n",
            "eopch:  18 , accuracy:  tensor(76.6900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  19 , learning rate:  0.002305589413792131\n",
            "eopch:  19 , training loss:  0.016684240761995317\n",
            "eopch:  19 , accuracy:  tensor(78.7000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  20 , learning rate:  0.002272112269336449\n",
            "eopch:  20 , training loss:  0.016165808403491973\n",
            "eopch:  20 , accuracy:  tensor(78.8600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  21 , learning rate:  0.002239121212817415\n",
            "eopch:  21 , training loss:  0.015746270170211792\n",
            "eopch:  21 , accuracy:  tensor(80.4300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  22 , learning rate:  0.002206609186241104\n",
            "eopch:  22 , training loss:  0.015308745225667953\n",
            "eopch:  22 , accuracy:  tensor(80.9600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  23 , learning rate:  0.002174569234095623\n",
            "eopch:  23 , training loss:  0.014904087188243867\n",
            "eopch:  23 , accuracy:  tensor(81.0100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  24 , learning rate:  0.0021429945018630677\n",
            "eopch:  24 , training loss:  0.014519267176389693\n",
            "eopch:  24 , accuracy:  tensor(81.0600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  25 , learning rate:  0.0021118782345530937\n",
            "eopch:  25 , training loss:  0.014150080342292785\n",
            "eopch:  25 , accuracy:  tensor(82.2100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  26 , learning rate:  0.002081213775257776\n",
            "eopch:  26 , training loss:  0.01385134564459324\n",
            "eopch:  26 , accuracy:  tensor(82.1600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  27 , learning rate:  0.0020509945637274523\n",
            "eopch:  27 , training loss:  0.013486267688274383\n",
            "eopch:  27 , accuracy:  tensor(82.8800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  28 , learning rate:  0.002021214134967246\n",
            "eopch:  28 , training loss:  0.013209320496916772\n",
            "eopch:  28 , accuracy:  tensor(83.2400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  29 , learning rate:  0.0019918661178539676\n",
            "eopch:  29 , training loss:  0.012991125265359879\n",
            "eopch:  29 , accuracy:  tensor(83.5600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  30 , learning rate:  0.0019629442337730984\n",
            "eopch:  30 , training loss:  0.012686188091039658\n",
            "eopch:  30 , accuracy:  tensor(83.3800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  31 , learning rate:  0.001934442295275564\n",
            "eopch:  31 , training loss:  0.01238743010044098\n",
            "eopch:  31 , accuracy:  tensor(83.5600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  32 , learning rate:  0.001906354204754014\n",
            "eopch:  32 , training loss:  0.012214331809878349\n",
            "eopch:  32 , accuracy:  tensor(83.6000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  33 , learning rate:  0.00187867395313832\n",
            "eopch:  33 , training loss:  0.011925218667984008\n",
            "eopch:  33 , accuracy:  tensor(83.7000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  34 , learning rate:  0.0018513956186100157\n",
            "eopch:  34 , training loss:  0.011718739350438118\n",
            "eopch:  34 , accuracy:  tensor(84.2600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  35 , learning rate:  0.0018245133653354037\n",
            "eopch:  35 , training loss:  0.011498466409444809\n",
            "eopch:  35 , accuracy:  tensor(83.9400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  36 , learning rate:  0.0017980214422170567\n",
            "eopch:  36 , training loss:  0.01140342635512352\n",
            "eopch:  36 , accuracy:  tensor(85.0700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  37 , learning rate:  0.0017719141816634476\n",
            "eopch:  37 , training loss:  0.011178074871897698\n",
            "eopch:  37 , accuracy:  tensor(84.2800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  38 , learning rate:  0.0017461859983764442\n",
            "eopch:  38 , training loss:  0.010987769384384156\n",
            "eopch:  38 , accuracy:  tensor(84.7200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  39 , learning rate:  0.0017208313881564097\n",
            "eopch:  39 , training loss:  0.010862579072117805\n",
            "eopch:  39 , accuracy:  tensor(84.5300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  40 , learning rate:  0.001695844926724653\n",
            "eopch:  40 , training loss:  0.010660254890918732\n",
            "eopch:  40 , accuracy:  tensor(84.6800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  41 , learning rate:  0.0016712212685629768\n",
            "eopch:  41 , training loss:  0.010532102999091148\n",
            "eopch:  41 , accuracy:  tensor(84.4500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  42 , learning rate:  0.0016469551457700766\n",
            "eopch:  42 , training loss:  0.010377049183249474\n",
            "eopch:  42 , accuracy:  tensor(85.3700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  43 , learning rate:  0.0016230413669345426\n",
            "eopch:  43 , training loss:  0.010248592230081559\n",
            "eopch:  43 , accuracy:  tensor(85.0800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  44 , learning rate:  0.0015994748160242278\n",
            "eopch:  44 , training loss:  0.010138353261947631\n",
            "eopch:  44 , accuracy:  tensor(84.3700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  45 , learning rate:  0.0015762504512917414\n",
            "eopch:  45 , training loss:  0.009994170412421226\n",
            "eopch:  45 , accuracy:  tensor(84.7700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  46 , learning rate:  0.001553363304195834\n",
            "eopch:  46 , training loss:  0.009920423245429993\n",
            "eopch:  46 , accuracy:  tensor(84.7500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  47 , learning rate:  0.0015308084783384457\n",
            "eopch:  47 , training loss:  0.009764476360678672\n",
            "eopch:  47 , accuracy:  tensor(84.7500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  48 , learning rate:  0.0015085811484171871\n",
            "eopch:  48 , training loss:  0.009681230812668801\n",
            "eopch:  48 , accuracy:  tensor(84.9300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  49 , learning rate:  0.0014866765591930306\n",
            "eopch:  49 , training loss:  0.00966595671415329\n",
            "eopch:  49 , accuracy:  tensor(85.3000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  50 , learning rate:  0.0014650900244729903\n",
            "eopch:  50 , training loss:  0.009425706970095635\n",
            "eopch:  50 , accuracy:  tensor(85.4900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  51 , learning rate:  0.0014438169261075746\n",
            "eopch:  51 , training loss:  0.009424166302084922\n",
            "eopch:  51 , accuracy:  tensor(85.2200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  52 , learning rate:  0.001422852713002795\n",
            "eopch:  52 , training loss:  0.009347531991004944\n",
            "eopch:  52 , accuracy:  tensor(85.2700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  53 , learning rate:  0.0014021929001465205\n",
            "eopch:  53 , training loss:  0.009275239289402961\n",
            "eopch:  53 , accuracy:  tensor(85.5600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  54 , learning rate:  0.0013818330676489685\n",
            "eopch:  54 , training loss:  0.009145986604094505\n",
            "eopch:  54 , accuracy:  tensor(85.2600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  55 , learning rate:  0.0013617688597971306\n",
            "eopch:  55 , training loss:  0.009167377597689628\n",
            "eopch:  55 , accuracy:  tensor(85.6900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  56 , learning rate:  0.0013419959841229243\n",
            "eopch:  56 , training loss:  0.009102538474798203\n",
            "eopch:  56 , accuracy:  tensor(85.7000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  57 , learning rate:  0.0013225102104848785\n",
            "eopch:  57 , training loss:  0.008995161304473876\n",
            "eopch:  57 , accuracy:  tensor(85.5800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  58 , learning rate:  0.0013033073701631506\n",
            "eopch:  58 , training loss:  0.008925097131729126\n",
            "eopch:  58 , accuracy:  tensor(85.5000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  59 , learning rate:  0.001284383354967685\n",
            "eopch:  59 , training loss:  0.008892065301537513\n",
            "eopch:  59 , accuracy:  tensor(85.3900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  60 , learning rate:  0.0012657341163593214\n",
            "eopch:  60 , training loss:  0.008816916298866271\n",
            "eopch:  60 , accuracy:  tensor(85.8800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  61 , learning rate:  0.0012473556645836636\n",
            "eopch:  61 , training loss:  0.008815184715986251\n",
            "eopch:  61 , accuracy:  tensor(85.4900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  62 , learning rate:  0.0012292440678175252\n",
            "eopch:  62 , training loss:  0.008782586625218391\n",
            "eopch:  62 , accuracy:  tensor(86.0400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  63 , learning rate:  0.001211395451327769\n",
            "eopch:  63 , training loss:  0.008663882096409798\n",
            "eopch:  63 , accuracy:  tensor(85.7200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  64 , learning rate:  0.00119380599664236\n",
            "eopch:  64 , training loss:  0.008627259407639504\n",
            "eopch:  64 , accuracy:  tensor(85.7600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  65 , learning rate:  0.0011764719407334537\n",
            "eopch:  65 , training loss:  0.008550378589630127\n",
            "eopch:  65 , accuracy:  tensor(85.4900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  66 , learning rate:  0.0011593895752123474\n",
            "eopch:  66 , training loss:  0.008554411785602569\n",
            "eopch:  66 , accuracy:  tensor(85.9000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  67 , learning rate:  0.0011425552455361205\n",
            "eopch:  67 , training loss:  0.008501955973505974\n",
            "eopch:  67 , accuracy:  tensor(86.1200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  68 , learning rate:  0.0011259653502257935\n",
            "eopch:  68 , training loss:  0.008524554060697555\n",
            "eopch:  68 , accuracy:  tensor(85.5000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  69 , learning rate:  0.0011096163400958398\n",
            "eopch:  69 , training loss:  0.00848541057765484\n",
            "eopch:  69 , accuracy:  tensor(86.2800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  70 , learning rate:  0.001093504717494886\n",
            "eopch:  70 , training loss:  0.008428681998252868\n",
            "eopch:  70 , accuracy:  tensor(85.9100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  71 , learning rate:  0.0010776270355574347\n",
            "eopch:  71 , training loss:  0.008377641246914863\n",
            "eopch:  71 , accuracy:  tensor(85.6700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  72 , learning rate:  0.0010619798974664558\n",
            "eopch:  72 , training loss:  0.008341461468338966\n",
            "eopch:  72 , accuracy:  tensor(85.9600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  73 , learning rate:  0.0010465599557266815\n",
            "eopch:  73 , training loss:  0.00833007524728775\n",
            "eopch:  73 , accuracy:  tensor(85.7900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  74 , learning rate:  0.0010313639114484555\n",
            "eopch:  74 , training loss:  0.00830259706735611\n",
            "eopch:  74 , accuracy:  tensor(86.2600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  75 , learning rate:  0.0010163885136419794\n",
            "eopch:  75 , training loss:  0.008291823679804801\n",
            "eopch:  75 , accuracy:  tensor(86.1700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  76 , learning rate:  0.0010016305585218072\n",
            "eopch:  76 , training loss:  0.008219175294041633\n",
            "eopch:  76 , accuracy:  tensor(86.2100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  77 , learning rate:  0.0009870868888214384\n",
            "eopch:  77 , training loss:  0.00820582516014576\n",
            "eopch:  77 , accuracy:  tensor(85.6700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  78 , learning rate:  0.0009727543931178629\n",
            "eopch:  78 , training loss:  0.00817109332561493\n",
            "eopch:  78 , accuracy:  tensor(85.7000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  79 , learning rate:  0.0009586300051659142\n",
            "eopch:  79 , training loss:  0.008137306424379348\n",
            "eopch:  79 , accuracy:  tensor(85.9700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  80 , learning rate:  0.0009447107032422874\n",
            "eopch:  80 , training loss:  0.008170466701984406\n",
            "eopch:  80 , accuracy:  tensor(86.1900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  81 , learning rate:  0.0009309935094990817\n",
            "eopch:  81 , training loss:  0.008157555865645408\n",
            "eopch:  81 , accuracy:  tensor(86.2900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  82 , learning rate:  0.0009174754893267298\n",
            "eopch:  82 , training loss:  0.008117381944656372\n",
            "eopch:  82 , accuracy:  tensor(86.2800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  83 , learning rate:  0.0009041537507261779\n",
            "eopch:  83 , training loss:  0.008068863475322723\n",
            "eopch:  83 , accuracy:  tensor(86.3100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  84 , learning rate:  0.0008910254436901812\n",
            "eopch:  84 , training loss:  0.008061687220335007\n",
            "eopch:  84 , accuracy:  tensor(86.4000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  85 , learning rate:  0.0008780877595935827\n",
            "eopch:  85 , training loss:  0.008016645793318749\n",
            "eopch:  85 , accuracy:  tensor(86.0600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  86 , learning rate:  0.0008653379305924462\n",
            "eopch:  86 , training loss:  0.008005648598074913\n",
            "eopch:  86 , accuracy:  tensor(85.9800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  87 , learning rate:  0.0008527732290319124\n",
            "eopch:  87 , training loss:  0.008054654225111008\n",
            "eopch:  87 , accuracy:  tensor(86.2000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  88 , learning rate:  0.0008403909668626546\n",
            "eopch:  88 , training loss:  0.008014218365550042\n",
            "eopch:  88 , accuracy:  tensor(86.2200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  89 , learning rate:  0.0008281884950658059\n",
            "eopch:  89 , training loss:  0.007985395650267601\n",
            "eopch:  89 , accuracy:  tensor(85.9600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  90 , learning rate:  0.0008161632030862378\n",
            "eopch:  90 , training loss:  0.007954493991732597\n",
            "eopch:  90 , accuracy:  tensor(86.5600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  91 , learning rate:  0.0008043125182740662\n",
            "eopch:  91 , training loss:  0.007948615976572036\n",
            "eopch:  91 , accuracy:  tensor(86.2200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  92 , learning rate:  0.0007926339053342681\n",
            "eopch:  92 , training loss:  0.007873171057105064\n",
            "eopch:  92 , accuracy:  tensor(86.6500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  93 , learning rate:  0.0007811248657842891\n",
            "eopch:  93 , training loss:  0.00788884308218956\n",
            "eopch:  93 , accuracy:  tensor(86.5000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  94 , learning rate:  0.0007697829374195263\n",
            "eopch:  94 , training loss:  0.00792611697435379\n",
            "eopch:  94 , accuracy:  tensor(86.4800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  95 , learning rate:  0.000758605693786573\n",
            "eopch:  95 , training loss:  0.007888974124193192\n",
            "eopch:  95 , accuracy:  tensor(86.6200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  96 , learning rate:  0.0007475907436641113\n",
            "eopch:  96 , training loss:  0.00788652067244053\n",
            "eopch:  96 , accuracy:  tensor(86.1600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  97 , learning rate:  0.0007367357305513427\n",
            "eopch:  97 , training loss:  0.007854392645955086\n",
            "eopch:  97 , accuracy:  tensor(86.5100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  98 , learning rate:  0.0007260383321638459\n",
            "eopch:  98 , training loss:  0.007850047916769982\n",
            "eopch:  98 , accuracy:  tensor(86.4000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  99 , learning rate:  0.0007154962599367556\n",
            "eopch:  99 , training loss:  0.007805478394031525\n",
            "eopch:  99 , accuracy:  tensor(86.4200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  100 , learning rate:  0.0007051072585351546\n",
            "eopch:  100 , training loss:  0.007811227355003357\n",
            "eopch:  100 , accuracy:  tensor(86.2600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  101 , learning rate:  0.0006948691053715752\n",
            "eopch:  101 , training loss:  0.007797457408308983\n",
            "eopch:  101 , accuracy:  tensor(86.3500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  102 , learning rate:  0.0006847796101305062\n",
            "eopch:  102 , training loss:  0.007822917775511742\n",
            "eopch:  102 , accuracy:  tensor(86.6500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  103 , learning rate:  0.0006748366142998048\n",
            "eopch:  103 , training loss:  0.007763074758052826\n",
            "eopch:  103 , accuracy:  tensor(86.4600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  104 , learning rate:  0.0006650379907089112\n",
            "eopch:  104 , training loss:  0.007800952553153038\n",
            "eopch:  104 , accuracy:  tensor(86.5000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  105 , learning rate:  0.0006553816430737698\n",
            "eopch:  105 , training loss:  0.007776348810195923\n",
            "eopch:  105 , accuracy:  tensor(86.4000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  106 , learning rate:  0.0006458655055483566\n",
            "eopch:  106 , training loss:  0.007750329266190529\n",
            "eopch:  106 , accuracy:  tensor(86.5000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  107 , learning rate:  0.0006364875422827195\n",
            "eopch:  107 , training loss:  0.0077423222780227665\n",
            "eopch:  107 , accuracy:  tensor(86.5000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  108 , learning rate:  0.0006272457469874356\n",
            "eopch:  108 , training loss:  0.007752769882678986\n",
            "eopch:  108 , accuracy:  tensor(86.5100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  109 , learning rate:  0.0006181381425043922\n",
            "eopch:  109 , training loss:  0.007696542150378227\n",
            "eopch:  109 , accuracy:  tensor(86.7700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  110 , learning rate:  0.0006091627803838009\n",
            "eopch:  110 , training loss:  0.007765656127333641\n",
            "eopch:  110 , accuracy:  tensor(86.4900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  111 , learning rate:  0.000600317740467352\n",
            "eopch:  111 , training loss:  0.007720919271111488\n",
            "eopch:  111 , accuracy:  tensor(86.5100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  112 , learning rate:  0.0005916011304774234\n",
            "eopch:  112 , training loss:  0.0076789172875881195\n",
            "eopch:  112 , accuracy:  tensor(86.4200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  113 , learning rate:  0.0005830110856122526\n",
            "eopch:  113 , training loss:  0.007680742733478546\n",
            "eopch:  113 , accuracy:  tensor(86.6600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  114 , learning rate:  0.0005745457681469873\n",
            "eopch:  114 , training loss:  0.007690830060243606\n",
            "eopch:  114 , accuracy:  tensor(86.6600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  115 , learning rate:  0.0005662033670405293\n",
            "eopch:  115 , training loss:  0.007692795134186745\n",
            "eopch:  115 , accuracy:  tensor(86.1400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  116 , learning rate:  0.0005579820975480861\n",
            "eopch:  116 , training loss:  0.007676545749306679\n",
            "eopch:  116 , accuracy:  tensor(86.4600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  117 , learning rate:  0.0005498802008393489\n",
            "eopch:  117 , training loss:  0.007678865950107574\n",
            "eopch:  117 , accuracy:  tensor(86.8700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  118 , learning rate:  0.0005418959436222147\n",
            "eopch:  118 , training loss:  0.007668281206488609\n",
            "eopch:  118 , accuracy:  tensor(86.3000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  119 , learning rate:  0.0005340276177719709\n",
            "eopch:  119 , training loss:  0.00766936361014843\n",
            "eopch:  119 , accuracy:  tensor(86.3300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  120 , learning rate:  0.000526273539965866\n",
            "eopch:  120 , training loss:  0.007664863558411598\n",
            "eopch:  120 , accuracy:  tensor(86.4100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  121 , learning rate:  0.0005186320513229845\n",
            "eopch:  121 , training loss:  0.0076287397253513335\n",
            "eopch:  121 , accuracy:  tensor(86.5900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  122 , learning rate:  0.0005111015170493518\n",
            "eopch:  122 , training loss:  0.007632318834662437\n",
            "eopch:  122 , accuracy:  tensor(86.4400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  123 , learning rate:  0.0005036803260881923\n",
            "eopch:  123 , training loss:  0.007592852385044098\n",
            "eopch:  123 , accuracy:  tensor(86.2400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  124 , learning rate:  0.0004963668907752647\n",
            "eopch:  124 , training loss:  0.007645737330913544\n",
            "eopch:  124 , accuracy:  tensor(86.6900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  125 , learning rate:  0.0004891596464992032\n",
            "eopch:  125 , training loss:  0.007675420880317688\n",
            "eopch:  125 , accuracy:  tensor(86.8000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  126 , learning rate:  0.0004820570513667897\n",
            "eopch:  126 , training loss:  0.007581428180932999\n",
            "eopch:  126 , accuracy:  tensor(86.7300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  127 , learning rate:  0.00047505758587308624\n",
            "eopch:  127 , training loss:  0.007605623428225517\n",
            "eopch:  127 , accuracy:  tensor(86.7100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  128 , learning rate:  0.0004681597525763574\n",
            "eopch:  128 , training loss:  0.007562310301661491\n",
            "eopch:  128 , accuracy:  tensor(86.8500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  129 , learning rate:  0.000461362075777713\n",
            "eopch:  129 , training loss:  0.007620132896900177\n",
            "eopch:  129 , accuracy:  tensor(86.7400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  130 , learning rate:  0.0004546631012054016\n",
            "eopch:  130 , training loss:  0.007635652748942375\n",
            "eopch:  130 , accuracy:  tensor(86.4700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  131 , learning rate:  0.00044806139570368914\n",
            "eopch:  131 , training loss:  0.007567898404598236\n",
            "eopch:  131 , accuracy:  tensor(86.8700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  132 , learning rate:  0.000441555546926254\n",
            "eopch:  132 , training loss:  0.007551434638500214\n",
            "eopch:  132 , accuracy:  tensor(86.7700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  133 , learning rate:  0.0004351441630340349\n",
            "eopch:  133 , training loss:  0.007577658051252365\n",
            "eopch:  133 , accuracy:  tensor(86.8400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  134 , learning rate:  0.0004288258723974651\n",
            "eopch:  134 , training loss:  0.007576875416636467\n",
            "eopch:  134 , accuracy:  tensor(86.7500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  135 , learning rate:  0.0004225993233030312\n",
            "eopch:  135 , training loss:  0.007582509957551956\n",
            "eopch:  135 , accuracy:  tensor(86.7400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  136 , learning rate:  0.0004164631836640918\n",
            "eopch:  136 , training loss:  0.007559105277061462\n",
            "eopch:  136 , accuracy:  tensor(86.6300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  137 , learning rate:  0.00041041614073589547\n",
            "eopch:  137 , training loss:  0.007519391732215881\n",
            "eopch:  137 , accuracy:  tensor(86.2200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  138 , learning rate:  0.0004044569008347368\n",
            "eopch:  138 , training loss:  0.00759715495467186\n",
            "eopch:  138 , accuracy:  tensor(86.7000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  139 , learning rate:  0.00039858418906119\n",
            "eopch:  139 , training loss:  0.0075498228377103805\n",
            "eopch:  139 , accuracy:  tensor(86.7100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  140 , learning rate:  0.0003927967490273613\n",
            "eopch:  140 , training loss:  0.007543511829972267\n",
            "eopch:  140 , accuracy:  tensor(86.8400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  141 , learning rate:  0.0003870933425881015\n",
            "eopch:  141 , training loss:  0.007485108985900879\n",
            "eopch:  141 , accuracy:  tensor(86.4300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  142 , learning rate:  0.0003814727495761217\n",
            "eopch:  142 , training loss:  0.007524295696020126\n",
            "eopch:  142 , accuracy:  tensor(86.6000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  143 , learning rate:  0.00037593376754095463\n",
            "eopch:  143 , training loss:  0.007498076867461205\n",
            "eopch:  143 , accuracy:  tensor(86.5300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  144 , learning rate:  0.0003704752114917066\n",
            "eopch:  144 , training loss:  0.007505588111877441\n",
            "eopch:  144 , accuracy:  tensor(86.6300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  145 , learning rate:  0.00036509591364354457\n",
            "eopch:  145 , training loss:  0.0075133747905492786\n",
            "eopch:  145 , accuracy:  tensor(86.8800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  146 , learning rate:  0.0003597947231678643\n",
            "eopch:  146 , training loss:  0.007532999231219291\n",
            "eopch:  146 , accuracy:  tensor(86.9800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  147 , learning rate:  0.00035457050594608593\n",
            "eopch:  147 , training loss:  0.007531776087284088\n",
            "eopch:  147 , accuracy:  tensor(86.7100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  148 , learning rate:  0.00034942214432702467\n",
            "eopch:  148 , training loss:  0.0074956964629888535\n",
            "eopch:  148 , accuracy:  tensor(86.7500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  149 , learning rate:  0.00034434853688778414\n",
            "eopch:  149 , training loss:  0.0075487912291288374\n",
            "eopch:  149 , accuracy:  tensor(86.8500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  150 , learning rate:  0.00033934859819812185\n",
            "eopch:  150 , training loss:  0.007479342512488365\n",
            "eopch:  150 , accuracy:  tensor(86.7600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  151 , learning rate:  0.0003344212585882359\n",
            "eopch:  151 , training loss:  0.00748616021156311\n",
            "eopch:  151 , accuracy:  tensor(86.7800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  152 , learning rate:  0.0003295654639199235\n",
            "eopch:  152 , training loss:  0.0074689743673801426\n",
            "eopch:  152 , accuracy:  tensor(86.8800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  153 , learning rate:  0.00032478017536106225\n",
            "eopch:  153 , training loss:  0.00750999339222908\n",
            "eopch:  153 , accuracy:  tensor(86.9700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  154 , learning rate:  0.0003200643691633659\n",
            "eopch:  154 , training loss:  0.007471606553196907\n",
            "eopch:  154 , accuracy:  tensor(86.7200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  155 , learning rate:  0.0003154170364433672\n",
            "eopch:  155 , training loss:  0.007457033321857452\n",
            "eopch:  155 , accuracy:  tensor(86.7100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  156 , learning rate:  0.00031083718296658086\n",
            "eopch:  156 , training loss:  0.007480332337021828\n",
            "eopch:  156 , accuracy:  tensor(86.9400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  157 , learning rate:  0.00030632382893480025\n",
            "eopch:  157 , training loss:  0.007468173459768295\n",
            "eopch:  157 , accuracy:  tensor(87.0400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  158 , learning rate:  0.0003018760087764828\n",
            "eopch:  158 , training loss:  0.00742536301612854\n",
            "eopch:  158 , accuracy:  tensor(86.8400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  159 , learning rate:  0.0002974927709401791\n",
            "eopch:  159 , training loss:  0.0074107168447971345\n",
            "eopch:  159 , accuracy:  tensor(86.8700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  160 , learning rate:  0.0002931731776909609\n",
            "eopch:  160 , training loss:  0.007455618361234665\n",
            "eopch:  160 , accuracy:  tensor(86.6800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  161 , learning rate:  0.00028891630490980553\n",
            "eopch:  161 , training loss:  0.007463692194819451\n",
            "eopch:  161 , accuracy:  tensor(86.8600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  162 , learning rate:  0.0002847212418958931\n",
            "eopch:  162 , training loss:  0.007441203964948654\n",
            "eopch:  162 , accuracy:  tensor(86.7700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  163 , learning rate:  0.00028058709117177407\n",
            "eopch:  163 , training loss:  0.007494790043234825\n",
            "eopch:  163 , accuracy:  tensor(87.0300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  164 , learning rate:  0.00027651296829136606\n",
            "eopch:  164 , training loss:  0.0074301299798488615\n",
            "eopch:  164 , accuracy:  tensor(87.1200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  165 , learning rate:  0.0002724980016507385\n",
            "eopch:  165 , training loss:  0.007384933255910873\n",
            "eopch:  165 , accuracy:  tensor(86.8900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  166 , learning rate:  0.0002685413323016447\n",
            "eopch:  166 , training loss:  0.007451089562177658\n",
            "eopch:  166 , accuracy:  tensor(86.5200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  167 , learning rate:  0.0002646421137677614\n",
            "eopch:  167 , training loss:  0.007412876232862473\n",
            "eopch:  167 , accuracy:  tensor(87.2400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  168 , learning rate:  0.0002607995118635964\n",
            "eopch:  168 , training loss:  0.007432335187792778\n",
            "eopch:  168 , accuracy:  tensor(86.9900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  169 , learning rate:  0.00025701270451602585\n",
            "eopch:  169 , training loss:  0.00741441270172596\n",
            "eopch:  169 , accuracy:  tensor(87.1200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  170 , learning rate:  0.00025328088158842275\n",
            "eopch:  170 , training loss:  0.007421284620165825\n",
            "eopch:  170 , accuracy:  tensor(87.0100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  171 , learning rate:  0.00024960324470733907\n",
            "eopch:  171 , training loss:  0.007435895729064942\n",
            "eopch:  171 , accuracy:  tensor(86.8100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  172 , learning rate:  0.0002459790070917044\n",
            "eopch:  172 , training loss:  0.007453280392289162\n",
            "eopch:  172 , accuracy:  tensor(87.2900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  173 , learning rate:  0.00024240739338450483\n",
            "eopch:  173 , training loss:  0.007412148649692535\n",
            "eopch:  173 , accuracy:  tensor(86.6500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  174 , learning rate:  0.00023888763948690561\n",
            "eopch:  174 , training loss:  0.007396554737687111\n",
            "eopch:  174 , accuracy:  tensor(87.1600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  175 , learning rate:  0.00023541899239478247\n",
            "eopch:  175 , training loss:  0.007479154511094093\n",
            "eopch:  175 , accuracy:  tensor(87.0600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  176 , learning rate:  0.0002320007100376265\n",
            "eopch:  176 , training loss:  0.007449688826799392\n",
            "eopch:  176 , accuracy:  tensor(87.1000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  177 , learning rate:  0.00022863206111978815\n",
            "eopch:  177 , training loss:  0.00740927239716053\n",
            "eopch:  177 , accuracy:  tensor(87.1300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  178 , learning rate:  0.00022531232496402634\n",
            "eopch:  178 , training loss:  0.0074086921048164365\n",
            "eopch:  178 , accuracy:  tensor(86.7800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  179 , learning rate:  0.00022204079135732915\n",
            "eopch:  179 , training loss:  0.007417723342180252\n",
            "eopch:  179 , accuracy:  tensor(87.0400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  180 , learning rate:  0.00021881676039897335\n",
            "eopch:  180 , training loss:  0.007409803255200386\n",
            "eopch:  180 , accuracy:  tensor(86.9300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  181 , learning rate:  0.00021563954235079\n",
            "eopch:  181 , training loss:  0.007377043136954308\n",
            "eopch:  181 , accuracy:  tensor(87.1700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  182 , learning rate:  0.0002125084574896043\n",
            "eopch:  182 , training loss:  0.007449695925712586\n",
            "eopch:  182 , accuracy:  tensor(86.9100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  183 , learning rate:  0.00020942283596181782\n",
            "eopch:  183 , training loss:  0.007351343620419502\n",
            "eopch:  183 , accuracy:  tensor(87.3000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  184 , learning rate:  0.00020638201764010234\n",
            "eopch:  184 , training loss:  0.007432713350653648\n",
            "eopch:  184 , accuracy:  tensor(87.0200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  185 , learning rate:  0.00020338535198217452\n",
            "eopch:  185 , training loss:  0.007395402185320854\n",
            "eopch:  185 , accuracy:  tensor(87.0500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  186 , learning rate:  0.00020043219789162107\n",
            "eopch:  186 , training loss:  0.0074643438321352\n",
            "eopch:  186 , accuracy:  tensor(86.9000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  187 , learning rate:  0.00019752192358074474\n",
            "eopch:  187 , training loss:  0.007389796018600464\n",
            "eopch:  187 , accuracy:  tensor(86.9900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  188 , learning rate:  0.00019465390643540192\n",
            "eopch:  188 , training loss:  0.007421986022591591\n",
            "eopch:  188 , accuracy:  tensor(87.1900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  189 , learning rate:  0.00019182753288180256\n",
            "eopch:  189 , training loss:  0.007401566199660301\n",
            "eopch:  189 , accuracy:  tensor(87.2000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  190 , learning rate:  0.00018904219825524439\n",
            "eopch:  190 , training loss:  0.0073501646709442136\n",
            "eopch:  190 , accuracy:  tensor(87.0600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  191 , learning rate:  0.00018629730667075298\n",
            "eopch:  191 , training loss:  0.007343787126541138\n",
            "eopch:  191 , accuracy:  tensor(87.0800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  192 , learning rate:  0.0001835922708956002\n",
            "eopch:  192 , training loss:  0.007385358030796051\n",
            "eopch:  192 , accuracy:  tensor(87.2200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  193 , learning rate:  0.00018092651222367353\n",
            "eopch:  193 , training loss:  0.00738868285536766\n",
            "eopch:  193 , accuracy:  tensor(86.9400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  194 , learning rate:  0.0001782994603516698\n",
            "eopch:  194 , training loss:  0.007389672394394874\n",
            "eopch:  194 , accuracy:  tensor(86.7400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  195 , learning rate:  0.00017571055325708634\n",
            "eopch:  195 , training loss:  0.007403634219765663\n",
            "eopch:  195 , accuracy:  tensor(87.2600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  196 , learning rate:  0.00017315923707798386\n",
            "eopch:  196 , training loss:  0.007402977768778801\n",
            "eopch:  196 , accuracy:  tensor(87.0500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  197 , learning rate:  0.0001706449659944951\n",
            "eopch:  197 , training loss:  0.0073307387369871135\n",
            "eopch:  197 , accuracy:  tensor(86.8500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  198 , learning rate:  0.00016816720211205403\n",
            "eopch:  198 , training loss:  0.007330113065838814\n",
            "eopch:  198 , accuracy:  tensor(86.5000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  199 , learning rate:  0.00016572541534632044\n",
            "eopch:  199 , training loss:  0.007401051228642464\n",
            "eopch:  199 , accuracy:  tensor(87.2100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  200 , learning rate:  0.0001633190833097756\n",
            "eopch:  200 , training loss:  0.007414293338060379\n",
            "eopch:  200 , accuracy:  tensor(87., device='cuda:0', dtype=torch.float64)\n",
            "eopch:  201 , learning rate:  0.0001609476911999644\n",
            "eopch:  201 , training loss:  0.007405313481092453\n",
            "eopch:  201 , accuracy:  tensor(87.0900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  202 , learning rate:  0.00015861073168936028\n",
            "eopch:  202 , training loss:  0.007359368755817414\n",
            "eopch:  202 , accuracy:  tensor(86.9300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  203 , learning rate:  0.00015630770481682934\n",
            "eopch:  203 , training loss:  0.007392640249729156\n",
            "eopch:  203 , accuracy:  tensor(87.2400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  204 , learning rate:  0.00015403811788067034\n",
            "eopch:  204 , training loss:  0.007430061192512512\n",
            "eopch:  204 , accuracy:  tensor(86.9000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  205 , learning rate:  0.0001518014853332078\n",
            "eopch:  205 , training loss:  0.007392747447490692\n",
            "eopch:  205 , accuracy:  tensor(87.2100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  206 , learning rate:  0.00014959732867691556\n",
            "eopch:  206 , training loss:  0.007376000170707703\n",
            "eopch:  206 , accuracy:  tensor(87.3400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  207 , learning rate:  0.00014742517636204865\n",
            "eopch:  207 , training loss:  0.007367542836070061\n",
            "eopch:  207 , accuracy:  tensor(87.1600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  208 , learning rate:  0.0001452845636857616\n",
            "eopch:  208 , training loss:  0.007343692371845245\n",
            "eopch:  208 , accuracy:  tensor(87.0300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  209 , learning rate:  0.00014317503269269143\n",
            "eopch:  209 , training loss:  0.007371081118583679\n",
            "eopch:  209 , accuracy:  tensor(87.0400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  210 , learning rate:  0.00014109613207698434\n",
            "eopch:  210 , training loss:  0.007367003166079521\n",
            "eopch:  210 , accuracy:  tensor(87.0200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  211 , learning rate:  0.00013904741708574477\n",
            "eopch:  211 , training loss:  0.00738789992928505\n",
            "eopch:  211 , accuracy:  tensor(86.8900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  212 , learning rate:  0.00013702844942388656\n",
            "eopch:  212 , training loss:  0.007340438876748085\n",
            "eopch:  212 , accuracy:  tensor(87.0600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  213 , learning rate:  0.00013503879716036558\n",
            "eopch:  213 , training loss:  0.00735888477742672\n",
            "eopch:  213 , accuracy:  tensor(86.8700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  214 , learning rate:  0.0001330780346357738\n",
            "eopch:  214 , training loss:  0.0073376057523489\n",
            "eopch:  214 , accuracy:  tensor(86.8700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  215 , learning rate:  0.00013114574237127537\n",
            "eopch:  215 , training loss:  0.00730381047129631\n",
            "eopch:  215 , accuracy:  tensor(87.0500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  216 , learning rate:  0.00012924150697886448\n",
            "eopch:  216 , training loss:  0.007311199448108673\n",
            "eopch:  216 , accuracy:  tensor(86.9100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  217 , learning rate:  0.0001273649210729268\n",
            "eopch:  217 , training loss:  0.007343511015176773\n",
            "eopch:  217 , accuracy:  tensor(86.7100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  218 , learning rate:  0.00012551558318308457\n",
            "eopch:  218 , training loss:  0.007353006425499916\n",
            "eopch:  218 , accuracy:  tensor(87.2200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  219 , learning rate:  0.0001236930976683076\n",
            "eopch:  219 , training loss:  0.007362582812905312\n",
            "eopch:  219 , accuracy:  tensor(86.8800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  220 , learning rate:  0.00012189707463227104\n",
            "eopch:  220 , training loss:  0.007332720422148705\n",
            "eopch:  220 , accuracy:  tensor(87.2400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  221 , learning rate:  0.00012012712983994233\n",
            "eopch:  221 , training loss:  0.007326987554430961\n",
            "eopch:  221 , accuracy:  tensor(86.8400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  222 , learning rate:  0.0001183828846353793\n",
            "eopch:  222 , training loss:  0.007322234234809876\n",
            "eopch:  222 , accuracy:  tensor(86.9700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  223 , learning rate:  0.00011666396586072178\n",
            "eopch:  223 , training loss:  0.007376034893393516\n",
            "eopch:  223 , accuracy:  tensor(87.1000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  224 , learning rate:  0.00011497000577635949\n",
            "eopch:  224 , training loss:  0.0073399503976106645\n",
            "eopch:  224 , accuracy:  tensor(87.1400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  225 , learning rate:  0.00011330064198225908\n",
            "eopch:  225 , training loss:  0.007331727786660194\n",
            "eopch:  225 , accuracy:  tensor(87.0700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  226 , learning rate:  0.00011165551734043351\n",
            "eopch:  226 , training loss:  0.00736053741812706\n",
            "eopch:  226 , accuracy:  tensor(86.8500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  227 , learning rate:  0.00011003427989853719\n",
            "eopch:  227 , training loss:  0.007320608260035515\n",
            "eopch:  227 , accuracy:  tensor(87.0700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  228 , learning rate:  0.00010843658281457045\n",
            "eopch:  228 , training loss:  0.0073337931722402576\n",
            "eopch:  228 , accuracy:  tensor(87.3600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  229 , learning rate:  0.00010686208428267739\n",
            "eopch:  229 , training loss:  0.007358792551755905\n",
            "eopch:  229 , accuracy:  tensor(87.3500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  230 , learning rate:  0.00010531044746002108\n",
            "eopch:  230 , training loss:  0.007286443464159966\n",
            "eopch:  230 , accuracy:  tensor(87.0200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  231 , learning rate:  0.00010378134039472056\n",
            "eopch:  231 , training loss:  0.007316782011389732\n",
            "eopch:  231 , accuracy:  tensor(87.2200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  232 , learning rate:  0.00010227443595483421\n",
            "eopch:  232 , training loss:  0.0073563605469465256\n",
            "eopch:  232 , accuracy:  tensor(86.7300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  233 , learning rate:  0.0001007894117583742\n",
            "eopch:  233 , training loss:  0.007319938615560532\n",
            "eopch:  233 , accuracy:  tensor(87.1000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  234 , learning rate:  9.932595010433725e-05\n",
            "eopch:  234 , training loss:  0.007294246655702591\n",
            "eopch:  234 , accuracy:  tensor(87.2800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  235 , learning rate:  9.788373790473676e-05\n",
            "eopch:  235 , training loss:  0.007359749580025673\n",
            "eopch:  235 , accuracy:  tensor(87.3500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  236 , learning rate:  9.646246661762179e-05\n",
            "eopch:  236 , training loss:  0.007310752668976784\n",
            "eopch:  236 , accuracy:  tensor(87.3600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  237 , learning rate:  9.50618321810687e-05\n",
            "eopch:  237 , training loss:  0.0073123457896709446\n",
            "eopch:  237 , accuracy:  tensor(86.9500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  238 , learning rate:  9.368153494813113e-05\n",
            "eopch:  238 , training loss:  0.007343478130102158\n",
            "eopch:  238 , accuracy:  tensor(87.0100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  239 , learning rate:  9.232127962273461e-05\n",
            "eopch:  239 , training loss:  0.007336619702577591\n",
            "eopch:  239 , accuracy:  tensor(86.7300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  240 , learning rate:  9.098077519650187e-05\n",
            "eopch:  240 , training loss:  0.007329603612422943\n",
            "eopch:  240 , accuracy:  tensor(86.9600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  241 , learning rate:  8.965973488649556e-05\n",
            "eopch:  241 , training loss:  0.007323113749623298\n",
            "eopch:  241 , accuracy:  tensor(87.2700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  242 , learning rate:  8.835787607386486e-05\n",
            "eopch:  242 , training loss:  0.007285026550292969\n",
            "eopch:  242 , accuracy:  tensor(87.0100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  243 , learning rate:  8.707492024338293e-05\n",
            "eopch:  243 , training loss:  0.007337556610703468\n",
            "eopch:  243 , accuracy:  tensor(87.3100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  244 , learning rate:  8.58105929238624e-05\n",
            "eopch:  244 , training loss:  0.007311049180030823\n",
            "eopch:  244 , accuracy:  tensor(87.1900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  245 , learning rate:  8.456462362943586e-05\n",
            "eopch:  245 , training loss:  0.007310453837513923\n",
            "eopch:  245 , accuracy:  tensor(87.1900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  246 , learning rate:  8.333674580168911e-05\n",
            "eopch:  246 , training loss:  0.007330107378363609\n",
            "eopch:  246 , accuracy:  tensor(86.7900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  247 , learning rate:  8.212669675263449e-05\n",
            "eopch:  247 , training loss:  0.007315073848366737\n",
            "eopch:  247 , accuracy:  tensor(86.9800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  248 , learning rate:  8.093421760851234e-05\n",
            "eopch:  248 , training loss:  0.007271901699900627\n",
            "eopch:  248 , accuracy:  tensor(87.1000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  249 , learning rate:  7.975905325440847e-05\n",
            "eopch:  249 , training loss:  0.007289342169761658\n",
            "eopch:  249 , accuracy:  tensor(86.9800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  250 , learning rate:  7.860095227967569e-05\n",
            "eopch:  250 , training loss:  0.007304280672073365\n",
            "eopch:  250 , accuracy:  tensor(87.1000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  251 , learning rate:  7.74596669241479e-05\n",
            "eopch:  251 , training loss:  0.0073300547569990155\n",
            "eopch:  251 , accuracy:  tensor(87.1800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  252 , learning rate:  7.633495302513513e-05\n",
            "eopch:  252 , training loss:  0.0072905811661481855\n",
            "eopch:  252 , accuracy:  tensor(87.1200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  253 , learning rate:  7.522656996518822e-05\n",
            "eopch:  253 , training loss:  0.007306024793982506\n",
            "eopch:  253 , accuracy:  tensor(87.1400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  254 , learning rate:  7.413428062062189e-05\n",
            "eopch:  254 , training loss:  0.007305095876455307\n",
            "eopch:  254 , accuracy:  tensor(87.0500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  255 , learning rate:  7.305785131078539e-05\n",
            "eopch:  255 , training loss:  0.007326350030303001\n",
            "eopch:  255 , accuracy:  tensor(87.0400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  256 , learning rate:  7.199705174806958e-05\n",
            "eopch:  256 , training loss:  0.007329930412769318\n",
            "eopch:  256 , accuracy:  tensor(87.4800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  257 , learning rate:  7.095165498864005e-05\n",
            "eopch:  257 , training loss:  0.00732809053003788\n",
            "eopch:  257 , accuracy:  tensor(87.0700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  258 , learning rate:  6.992143738388548e-05\n",
            "eopch:  258 , training loss:  0.007321852217316628\n",
            "eopch:  258 , accuracy:  tensor(86.8700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  259 , learning rate:  6.890617853257107e-05\n",
            "eopch:  259 , training loss:  0.007326060059666633\n",
            "eopch:  259 , accuracy:  tensor(86.8900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  260 , learning rate:  6.790566123368661e-05\n",
            "eopch:  260 , training loss:  0.0073244900816679\n",
            "eopch:  260 , accuracy:  tensor(86.9600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  261 , learning rate:  6.691967143997927e-05\n",
            "eopch:  261 , training loss:  0.007280733832120896\n",
            "eopch:  261 , accuracy:  tensor(87.1100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  262 , learning rate:  6.594799821216104e-05\n",
            "eopch:  262 , training loss:  0.007272133584022522\n",
            "eopch:  262 , accuracy:  tensor(87.1400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  263 , learning rate:  6.499043367378109e-05\n",
            "eopch:  263 , training loss:  0.00736334992647171\n",
            "eopch:  263 , accuracy:  tensor(86.9800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  264 , learning rate:  6.404677296675342e-05\n",
            "eopch:  264 , training loss:  0.007287989275455475\n",
            "eopch:  264 , accuracy:  tensor(86.9900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  265 , learning rate:  6.311681420753022e-05\n",
            "eopch:  265 , training loss:  0.0073095452773571015\n",
            "eopch:  265 , accuracy:  tensor(87.2400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  266 , learning rate:  6.220035844391158e-05\n",
            "eopch:  266 , training loss:  0.007314104157686234\n",
            "eopch:  266 , accuracy:  tensor(87.2800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  267 , learning rate:  6.129720961248233e-05\n",
            "eopch:  267 , training loss:  0.007308815914988518\n",
            "eopch:  267 , accuracy:  tensor(87.3100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  268 , learning rate:  6.0407174496666905e-05\n",
            "eopch:  268 , training loss:  0.007305223754048348\n",
            "eopch:  268 , accuracy:  tensor(87.2300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  269 , learning rate:  5.953006268539328e-05\n",
            "eopch:  269 , training loss:  0.007272349060177803\n",
            "eopch:  269 , accuracy:  tensor(87.2100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  270 , learning rate:  5.866568653235705e-05\n",
            "eopch:  270 , training loss:  0.007287094722390175\n",
            "eopch:  270 , accuracy:  tensor(86.9800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  271 , learning rate:  5.7813861115877e-05\n",
            "eopch:  271 , training loss:  0.007318086466789246\n",
            "eopch:  271 , accuracy:  tensor(87.2400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  272 , learning rate:  5.6974404199333645e-05\n",
            "eopch:  272 , training loss:  0.0073250825726985935\n",
            "eopch:  272 , accuracy:  tensor(86.9800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  273 , learning rate:  5.614713619218211e-05\n",
            "eopch:  273 , training loss:  0.0073177757608890535\n",
            "eopch:  273 , accuracy:  tensor(87.0300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  274 , learning rate:  5.533188011153114e-05\n",
            "eopch:  274 , training loss:  0.0072913203316926955\n",
            "eopch:  274 , accuracy:  tensor(87.0900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  275 , learning rate:  5.452846154428003e-05\n",
            "eopch:  275 , training loss:  0.007325726981759071\n",
            "eopch:  275 , accuracy:  tensor(87.0600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  276 , learning rate:  5.373670860980523e-05\n",
            "eopch:  276 , training loss:  0.007294599551558495\n",
            "eopch:  276 , accuracy:  tensor(87.0900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  277 , learning rate:  5.295645192318881e-05\n",
            "eopch:  277 , training loss:  0.007275755296349526\n",
            "eopch:  277 , accuracy:  tensor(86.8800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  278 , learning rate:  5.218752455898085e-05\n",
            "eopch:  278 , training loss:  0.00728966959297657\n",
            "eopch:  278 , accuracy:  tensor(87.1900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  279 , learning rate:  5.142976201548794e-05\n",
            "eopch:  279 , training loss:  0.007336269403100014\n",
            "eopch:  279 , accuracy:  tensor(87.0700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  280 , learning rate:  5.068300217958029e-05\n",
            "eopch:  280 , training loss:  0.00731081571161747\n",
            "eopch:  280 , accuracy:  tensor(86.9400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  281 , learning rate:  4.9947085292009764e-05\n",
            "eopch:  281 , training loss:  0.007328706319332123\n",
            "eopch:  281 , accuracy:  tensor(87.3100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  282 , learning rate:  4.922185391323157e-05\n",
            "eopch:  282 , training loss:  0.007303124722242356\n",
            "eopch:  282 , accuracy:  tensor(87.1900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  283 , learning rate:  4.8507152889722145e-05\n",
            "eopch:  283 , training loss:  0.007290987580418587\n",
            "eopch:  283 , accuracy:  tensor(86.9500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  284 , learning rate:  4.780282932078617e-05\n",
            "eopch:  284 , training loss:  0.0072795008850097655\n",
            "eopch:  284 , accuracy:  tensor(87.1700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  285 , learning rate:  4.71087325258455e-05\n",
            "eopch:  285 , training loss:  0.007302871146798134\n",
            "eopch:  285 , accuracy:  tensor(87.1700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  286 , learning rate:  4.642471401220307e-05\n",
            "eopch:  286 , training loss:  0.007298638854622841\n",
            "eopch:  286 , accuracy:  tensor(87.2000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  287 , learning rate:  4.57506274432749e-05\n",
            "eopch:  287 , training loss:  0.007266924576759338\n",
            "eopch:  287 , accuracy:  tensor(87.3000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  288 , learning rate:  4.508632860728333e-05\n",
            "eopch:  288 , training loss:  0.007277653050422668\n",
            "eopch:  288 , accuracy:  tensor(87.1400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  289 , learning rate:  4.4431675386404845e-05\n",
            "eopch:  289 , training loss:  0.007295045630335808\n",
            "eopch:  289 , accuracy:  tensor(86.9800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  290 , learning rate:  4.3786527726365866e-05\n",
            "eopch:  290 , training loss:  0.007334400658607483\n",
            "eopch:  290 , accuracy:  tensor(87.1900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  291 , learning rate:  4.315074760648003e-05\n",
            "eopch:  291 , training loss:  0.007272459211349488\n",
            "eopch:  291 , accuracy:  tensor(87.2700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  292 , learning rate:  4.2524199010120525e-05\n",
            "eopch:  292 , training loss:  0.00727502225458622\n",
            "eopch:  292 , accuracy:  tensor(87.0700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  293 , learning rate:  4.190674789562113e-05\n",
            "eopch:  293 , training loss:  0.007301891987323761\n",
            "eopch:  293 , accuracy:  tensor(87., device='cuda:0', dtype=torch.float64)\n",
            "eopch:  294 , learning rate:  4.129826216759981e-05\n",
            "eopch:  294 , training loss:  0.007303459810614586\n",
            "eopch:  294 , accuracy:  tensor(87.1800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  295 , learning rate:  4.069861164869869e-05\n",
            "eopch:  295 , training loss:  0.007264175167679787\n",
            "eopch:  295 , accuracy:  tensor(86.7000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  296 , learning rate:  4.010766805173437e-05\n",
            "eopch:  296 , training loss:  0.007294513428807259\n",
            "eopch:  296 , accuracy:  tensor(86.9000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  297 , learning rate:  3.952530495225255e-05\n",
            "eopch:  297 , training loss:  0.007307603640556336\n",
            "eopch:  297 , accuracy:  tensor(87.3200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  298 , learning rate:  3.895139776148127e-05\n",
            "eopch:  298 , training loss:  0.0072744650971889495\n",
            "eopch:  298 , accuracy:  tensor(87.4300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  299 , learning rate:  3.8385823699676784e-05\n",
            "eopch:  299 , training loss:  0.007299709512591362\n",
            "eopch:  299 , accuracy:  tensor(87.1400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  300 , learning rate:  3.7828461769856494e-05\n",
            "eopch:  300 , training loss:  0.007297078440785408\n",
            "eopch:  300 , accuracy:  tensor(87., device='cuda:0', dtype=torch.float64)\n",
            "eopch:  301 , learning rate:  3.7279192731913254e-05\n",
            "eopch:  301 , training loss:  0.007290474304556847\n",
            "eopch:  301 , accuracy:  tensor(87.0700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  302 , learning rate:  3.673789907710556e-05\n",
            "eopch:  302 , training loss:  0.007265044403672218\n",
            "eopch:  302 , accuracy:  tensor(86.8200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  303 , learning rate:  3.6204465002918137e-05\n",
            "eopch:  303 , training loss:  0.007351618525981903\n",
            "eopch:  303 , accuracy:  tensor(87.1600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  304 , learning rate:  3.5678776388287535e-05\n",
            "eopch:  304 , training loss:  0.00729140207707882\n",
            "eopch:  304 , accuracy:  tensor(87.0500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  305 , learning rate:  3.516072076918745e-05\n",
            "eopch:  305 , training loss:  0.007320958567857742\n",
            "eopch:  305 , accuracy:  tensor(87.2500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  306 , learning rate:  3.465018731456859e-05\n",
            "eopch:  306 , training loss:  0.007268697183728218\n",
            "eopch:  306 , accuracy:  tensor(87.1800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  307 , learning rate:  3.41470668026478e-05\n",
            "eopch:  307 , training loss:  0.007287448189258575\n",
            "eopch:  307 , accuracy:  tensor(87., device='cuda:0', dtype=torch.float64)\n",
            "eopch:  308 , learning rate:  3.365125159754159e-05\n",
            "eopch:  308 , training loss:  0.007279296676516533\n",
            "eopch:  308 , accuracy:  tensor(87.4600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  309 , learning rate:  3.316263562623883e-05\n",
            "eopch:  309 , training loss:  0.007299104568958282\n",
            "eopch:  309 , accuracy:  tensor(87.2000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  310 , learning rate:  3.2681114355907896e-05\n",
            "eopch:  310 , training loss:  0.0073159129685163495\n",
            "eopch:  310 , accuracy:  tensor(86.8300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  311 , learning rate:  3.220658477153324e-05\n",
            "eopch:  311 , training loss:  0.007289059685468674\n",
            "eopch:  311 , accuracy:  tensor(87.0400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  312 , learning rate:  3.173894535387672e-05\n",
            "eopch:  312 , training loss:  0.007294063912630081\n",
            "eopch:  312 , accuracy:  tensor(87.0500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  313 , learning rate:  3.1278096057758936e-05\n",
            "eopch:  313 , training loss:  0.007312641538381576\n",
            "eopch:  313 , accuracy:  tensor(87.2500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  314 , learning rate:  3.082393829065587e-05\n",
            "eopch:  314 , training loss:  0.007279952766895294\n",
            "eopch:  314 , accuracy:  tensor(86.9400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  315 , learning rate:  3.0376374891606387e-05\n",
            "eopch:  315 , training loss:  0.007250647009015084\n",
            "eopch:  315 , accuracy:  tensor(87.3700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  316 , learning rate:  2.993531011042591e-05\n",
            "eopch:  316 , training loss:  0.007295564044713974\n",
            "eopch:  316 , accuracy:  tensor(87.3600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  317 , learning rate:  2.9500649587221963e-05\n",
            "eopch:  317 , training loss:  0.007288928385972977\n",
            "eopch:  317 , accuracy:  tensor(87.2900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  318 , learning rate:  2.9072300332207158e-05\n",
            "eopch:  318 , training loss:  0.007303828026652336\n",
            "eopch:  318 , accuracy:  tensor(87.3300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  319 , learning rate:  2.865017070580525e-05\n",
            "eopch:  319 , training loss:  0.007249878739118576\n",
            "eopch:  319 , accuracy:  tensor(86.9700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  320 , learning rate:  2.8234170399046094e-05\n",
            "eopch:  320 , training loss:  0.007306448621153832\n",
            "eopch:  320 , accuracy:  tensor(86.9600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  321 , learning rate:  2.7824210414245252e-05\n",
            "eopch:  321 , training loss:  0.007277579996585846\n",
            "eopch:  321 , accuracy:  tensor(86.9900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  322 , learning rate:  2.7420203045964128e-05\n",
            "eopch:  322 , training loss:  0.007269095129966736\n",
            "eopch:  322 , accuracy:  tensor(87.0800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  323 , learning rate:  2.702206186224657e-05\n",
            "eopch:  323 , training loss:  0.007247156721353531\n",
            "eopch:  323 , accuracy:  tensor(87.3300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  324 , learning rate:  2.662970168612791e-05\n",
            "eopch:  324 , training loss:  0.007271585275530815\n",
            "eopch:  324 , accuracy:  tensor(87.0900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  325 , learning rate:  2.624303857741249e-05\n",
            "eopch:  325 , training loss:  0.007336561871767044\n",
            "eopch:  325 , accuracy:  tensor(87.0800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  326 , learning rate:  2.5861989814715805e-05\n",
            "eopch:  326 , training loss:  0.007286553195118904\n",
            "eopch:  326 , accuracy:  tensor(86.9900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  327 , learning rate:  2.5486473877767338e-05\n",
            "eopch:  327 , training loss:  0.007305904119610787\n",
            "eopch:  327 , accuracy:  tensor(87.2200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  328 , learning rate:  2.5116410429970424e-05\n",
            "eopch:  328 , training loss:  0.007255055876970291\n",
            "eopch:  328 , accuracy:  tensor(87.2700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  329 , learning rate:  2.4751720301215294e-05\n",
            "eopch:  329 , training loss:  0.0072611221879720685\n",
            "eopch:  329 , accuracy:  tensor(87.2200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  330 , learning rate:  2.43923254709417e-05\n",
            "eopch:  330 , training loss:  0.00727971413731575\n",
            "eopch:  330 , accuracy:  tensor(86.9100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  331 , learning rate:  2.403814905144746e-05\n",
            "eopch:  331 , training loss:  0.007255719024538994\n",
            "eopch:  331 , accuracy:  tensor(87.2600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  332 , learning rate:  2.3689115271439363e-05\n",
            "eopch:  332 , training loss:  0.007298444764018059\n",
            "eopch:  332 , accuracy:  tensor(87.0300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  333 , learning rate:  2.3345149459822927e-05\n",
            "eopch:  333 , training loss:  0.007332499173283577\n",
            "eopch:  333 , accuracy:  tensor(87.1600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  334 , learning rate:  2.300617802972751e-05\n",
            "eopch:  334 , training loss:  0.007274506477713585\n",
            "eopch:  334 , accuracy:  tensor(86.8200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  335 , learning rate:  2.267212846276339e-05\n",
            "eopch:  335 , training loss:  0.007232813124060631\n",
            "eopch:  335 , accuracy:  tensor(87.1800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  336 , learning rate:  2.2342929293507428e-05\n",
            "eopch:  336 , training loss:  0.007295279271602631\n",
            "eopch:  336 , accuracy:  tensor(87.0300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  337 , learning rate:  2.2018510094214004e-05\n",
            "eopch:  337 , training loss:  0.007310604658126831\n",
            "eopch:  337 , accuracy:  tensor(87.1100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  338 , learning rate:  2.169880145974794e-05\n",
            "eopch:  338 , training loss:  0.007322828822135925\n",
            "eopch:  338 , accuracy:  tensor(87.0200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  339 , learning rate:  2.1383734992736207e-05\n",
            "eopch:  339 , training loss:  0.007237402521967888\n",
            "eopch:  339 , accuracy:  tensor(87.2500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  340 , learning rate:  2.1073243288935215e-05\n",
            "eopch:  340 , training loss:  0.007268149745464325\n",
            "eopch:  340 , accuracy:  tensor(87.0700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  341 , learning rate:  2.076725992281059e-05\n",
            "eopch:  341 , training loss:  0.00729158881187439\n",
            "eopch:  341 , accuracy:  tensor(87.2600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  342 , learning rate:  2.0465719433326323e-05\n",
            "eopch:  342 , training loss:  0.007262496181726455\n",
            "eopch:  342 , accuracy:  tensor(87.1900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  343 , learning rate:  2.016855730994025e-05\n",
            "eopch:  343 , training loss:  0.007308878096938133\n",
            "eopch:  343 , accuracy:  tensor(87.0100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  344 , learning rate:  1.9875709978802893e-05\n",
            "eopch:  344 , training loss:  0.007240703639388084\n",
            "eopch:  344 , accuracy:  tensor(87.1000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  345 , learning rate:  1.958711478915669e-05\n",
            "eopch:  345 , training loss:  0.007306108375787735\n",
            "eopch:  345 , accuracy:  tensor(87.1800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  346 , learning rate:  1.9302709999932696e-05\n",
            "eopch:  346 , training loss:  0.007269506149888039\n",
            "eopch:  346 , accuracy:  tensor(86.9100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  347 , learning rate:  1.9022434766541923e-05\n",
            "eopch:  347 , training loss:  0.007235164217948914\n",
            "eopch:  347 , accuracy:  tensor(87.1400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  348 , learning rate:  1.874622912785845e-05\n",
            "eopch:  348 , training loss:  0.007279336821436882\n",
            "eopch:  348 , accuracy:  tensor(86.8000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  349 , learning rate:  1.8474033993391543e-05\n",
            "eopch:  349 , training loss:  0.0072645943105220795\n",
            "eopch:  349 , accuracy:  tensor(87.1000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  350 , learning rate:  1.8205791130644037e-05\n",
            "eopch:  350 , training loss:  0.007300829141736031\n",
            "eopch:  350 , accuracy:  tensor(86.9000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  351 , learning rate:  1.794144315265428e-05\n",
            "eopch:  351 , training loss:  0.007292503790259361\n",
            "eopch:  351 , accuracy:  tensor(86.9800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  352 , learning rate:  1.7680933505718953e-05\n",
            "eopch:  352 , training loss:  0.007299109431505203\n",
            "eopch:  352 , accuracy:  tensor(87.1100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  353 , learning rate:  1.742420645729418e-05\n",
            "eopch:  353 , training loss:  0.007309582204222679\n",
            "eopch:  353 , accuracy:  tensor(87.3900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  354 , learning rate:  1.7171207084072277e-05\n",
            "eopch:  354 , training loss:  0.007278271367549896\n",
            "eopch:  354 , accuracy:  tensor(87.0700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  355 , learning rate:  1.6921881260231665e-05\n",
            "eopch:  355 , training loss:  0.007293199400901795\n",
            "eopch:  355 , accuracy:  tensor(86.9900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  356 , learning rate:  1.6676175645857367e-05\n",
            "eopch:  356 , training loss:  0.007287205824851989\n",
            "eopch:  356 , accuracy:  tensor(87.3100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  357 , learning rate:  1.6434037675529653e-05\n",
            "eopch:  357 , training loss:  0.007267740389704704\n",
            "eopch:  357 , accuracy:  tensor(86.8000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  358 , learning rate:  1.619541554707837e-05\n",
            "eopch:  358 , training loss:  0.0072805023694038394\n",
            "eopch:  358 , accuracy:  tensor(87.3100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  359 , learning rate:  1.5960258210500564e-05\n",
            "eopch:  359 , training loss:  0.007307256079912186\n",
            "eopch:  359 , accuracy:  tensor(87.2000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  360 , learning rate:  1.5728515357039022e-05\n",
            "eopch:  360 , training loss:  0.00728425430059433\n",
            "eopch:  360 , accuracy:  tensor(86.8300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  361 , learning rate:  1.550013740841938e-05\n",
            "eopch:  361 , training loss:  0.007331351591348648\n",
            "eopch:  361 , accuracy:  tensor(86.7800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  362 , learning rate:  1.5275075506243526e-05\n",
            "eopch:  362 , training loss:  0.007316720164418221\n",
            "eopch:  362 , accuracy:  tensor(87.2700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  363 , learning rate:  1.5053281501536985e-05\n",
            "eopch:  363 , training loss:  0.007320967680811882\n",
            "eopch:  363 , accuracy:  tensor(87.0100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  364 , learning rate:  1.483470794444811e-05\n",
            "eopch:  364 , training loss:  0.007281796697378159\n",
            "eopch:  364 , accuracy:  tensor(87.3900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  365 , learning rate:  1.4619308074096817e-05\n",
            "eopch:  365 , training loss:  0.007294148280024528\n",
            "eopch:  365 , accuracy:  tensor(87.3100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  366 , learning rate:  1.4407035808570714e-05\n",
            "eopch:  366 , training loss:  0.007307561601400375\n",
            "eopch:  366 , accuracy:  tensor(87.1000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  367 , learning rate:  1.4197845735066504e-05\n",
            "eopch:  367 , training loss:  0.0072713628035783765\n",
            "eopch:  367 , accuracy:  tensor(87.1500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  368 , learning rate:  1.3991693100174522e-05\n",
            "eopch:  368 , training loss:  0.007261373618245125\n",
            "eopch:  368 , accuracy:  tensor(87.1600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  369 , learning rate:  1.378853380030434e-05\n",
            "eopch:  369 , training loss:  0.007267744196057319\n",
            "eopch:  369 , accuracy:  tensor(87.4700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  370 , learning rate:  1.3588324372249404e-05\n",
            "eopch:  370 , training loss:  0.007289508466720581\n",
            "eopch:  370 , accuracy:  tensor(87.2300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  371 , learning rate:  1.339102198388865e-05\n",
            "eopch:  371 , training loss:  0.007303935569524765\n",
            "eopch:  371 , accuracy:  tensor(87.0200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  372 , learning rate:  1.3196584425023162e-05\n",
            "eopch:  372 , training loss:  0.007293223883509636\n",
            "eopch:  372 , accuracy:  tensor(86.9300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  373 , learning rate:  1.3004970098345856e-05\n",
            "eopch:  373 , training loss:  0.0072664555233716965\n",
            "eopch:  373 , accuracy:  tensor(87.1600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  374 , learning rate:  1.2816138010542299e-05\n",
            "eopch:  374 , training loss:  0.007289615888595581\n",
            "eopch:  374 , accuracy:  tensor(87.1000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  375 , learning rate:  1.2630047763520735e-05\n",
            "eopch:  375 , training loss:  0.007294181590676308\n",
            "eopch:  375 , accuracy:  tensor(87.3300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  376 , learning rate:  1.2446659545769459e-05\n",
            "eopch:  376 , training loss:  0.00725033856511116\n",
            "eopch:  376 , accuracy:  tensor(86.8800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  377 , learning rate:  1.226593412383968e-05\n",
            "eopch:  377 , training loss:  0.007301444193720818\n",
            "eopch:  377 , accuracy:  tensor(86.8400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  378 , learning rate:  1.2087832833952044e-05\n",
            "eopch:  378 , training loss:  0.007314792784452438\n",
            "eopch:  378 , accuracy:  tensor(87.2500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  379 , learning rate:  1.1912317573725042e-05\n",
            "eopch:  379 , training loss:  0.007283708217144013\n",
            "eopch:  379 , accuracy:  tensor(86.9600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  380 , learning rate:  1.1739350794023518e-05\n",
            "eopch:  380 , training loss:  0.007273494079113006\n",
            "eopch:  380 , accuracy:  tensor(87.0900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  381 , learning rate:  1.156889549092553e-05\n",
            "eopch:  381 , training loss:  0.007276120183467865\n",
            "eopch:  381 , accuracy:  tensor(87.2900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  382 , learning rate:  1.1400915197805865e-05\n",
            "eopch:  382 , training loss:  0.007289342355728149\n",
            "eopch:  382 , accuracy:  tensor(86.9800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  383 , learning rate:  1.1235373977534484e-05\n",
            "eopch:  383 , training loss:  0.007303197920918465\n",
            "eopch:  383 , accuracy:  tensor(87.2500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  384 , learning rate:  1.1072236414788266e-05\n",
            "eopch:  384 , training loss:  0.0072427045828104015\n",
            "eopch:  384 , accuracy:  tensor(87.5400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  385 , learning rate:  1.0911467608474365e-05\n",
            "eopch:  385 , training loss:  0.007276477389335632\n",
            "eopch:  385 , accuracy:  tensor(87.1300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  386 , learning rate:  1.0753033164263596e-05\n",
            "eopch:  386 , training loss:  0.007268474158048629\n",
            "eopch:  386 , accuracy:  tensor(87.2400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  387 , learning rate:  1.0596899187232226e-05\n",
            "eopch:  387 , training loss:  0.007256503210067749\n",
            "eopch:  387 , accuracy:  tensor(87.1400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  388 , learning rate:  1.0443032274610611e-05\n",
            "eopch:  388 , training loss:  0.007297478883862496\n",
            "eopch:  388 , accuracy:  tensor(86.9600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  389 , learning rate:  1.0291399508637125e-05\n",
            "eopch:  389 , training loss:  0.007285065240263939\n",
            "eopch:  389 , accuracy:  tensor(87.3100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  390 , learning rate:  1.0141968449515841e-05\n",
            "eopch:  390 , training loss:  0.007287570052742958\n",
            "eopch:  390 , accuracy:  tensor(86.9100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  391 , learning rate:  9.994707128476474e-06\n",
            "eopch:  391 , training loss:  0.0072864770412445065\n",
            "eopch:  391 , accuracy:  tensor(86.9800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  392 , learning rate:  9.84958404093509e-06\n",
            "eopch:  392 , training loss:  0.007272766266465187\n",
            "eopch:  392 , accuracy:  tensor(87.0500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  393 , learning rate:  9.706568139754131e-06\n",
            "eopch:  393 , training loss:  0.007277597154974938\n",
            "eopch:  393 , accuracy:  tensor(87.3000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  394 , learning rate:  9.565628828600282e-06\n",
            "eopch:  394 , training loss:  0.007267030062675476\n",
            "eopch:  394 , accuracy:  tensor(87.2800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  395 , learning rate:  9.42673595539881e-06\n",
            "eopch:  395 , training loss:  0.007264316355586052\n",
            "eopch:  395 , accuracy:  tensor(87.2000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  396 , learning rate:  9.289859805882923e-06\n",
            "eopch:  396 , training loss:  0.007284740228652954\n",
            "eopch:  396 , accuracy:  tensor(87.3400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  397 , learning rate:  9.154971097236808e-06\n",
            "eopch:  397 , training loss:  0.007303335946202278\n",
            "eopch:  397 , accuracy:  tensor(86.8800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  398 , learning rate:  9.022040971830957e-06\n",
            "eopch:  398 , training loss:  0.007276269715428352\n",
            "eopch:  398 , accuracy:  tensor(87.2700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  399 , learning rate:  8.891040991048473e-06\n",
            "eopch:  399 , training loss:  0.0073185025674104695\n",
            "eopch:  399 , accuracy:  tensor(87.1900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  400 , learning rate:  8.761943129201006e-06\n",
            "eopch:  400 , training loss:  0.007268266425132752\n",
            "eopch:  400 , accuracy:  tensor(87.1100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  401 , learning rate:  8.634719767533031e-06\n",
            "eopch:  401 , training loss:  0.00727133418738842\n",
            "eopch:  401 , accuracy:  tensor(87.4100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  402 , learning rate:  8.509343688313187e-06\n",
            "eopch:  402 , training loss:  0.00727876123547554\n",
            "eopch:  402 , accuracy:  tensor(87.2200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  403 , learning rate:  8.38578806901141e-06\n",
            "eopch:  403 , training loss:  0.007278385785222053\n",
            "eopch:  403 , accuracy:  tensor(87.1600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  404 , learning rate:  8.264026476560613e-06\n",
            "eopch:  404 , training loss:  0.007266690147519112\n",
            "eopch:  404 , accuracy:  tensor(87.2600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  405 , learning rate:  8.144032861701682e-06\n",
            "eopch:  405 , training loss:  0.0072662491488456726\n",
            "eopch:  405 , accuracy:  tensor(87.1400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  406 , learning rate:  8.025781553410592e-06\n",
            "eopch:  406 , training loss:  0.007289209003448486\n",
            "eopch:  406 , accuracy:  tensor(87.1800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  407 , learning rate:  7.909247253406429e-06\n",
            "eopch:  407 , training loss:  0.007288901370167732\n",
            "eopch:  407 , accuracy:  tensor(86.9700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  408 , learning rate:  7.79440503073917e-06\n",
            "eopch:  408 , training loss:  0.007272434188723564\n",
            "eopch:  408 , accuracy:  tensor(87.2400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  409 , learning rate:  7.681230316456033e-06\n",
            "eopch:  409 , training loss:  0.007268023933172226\n",
            "eopch:  409 , accuracy:  tensor(87.0100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  410 , learning rate:  7.569698898345286e-06\n",
            "eopch:  410 , training loss:  0.00727706533908844\n",
            "eopch:  410 , accuracy:  tensor(87.2800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  411 , learning rate:  7.459786915756365e-06\n",
            "eopch:  411 , training loss:  0.0072830924898386\n",
            "eopch:  411 , accuracy:  tensor(87.0800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  412 , learning rate:  7.351470854495209e-06\n",
            "eopch:  412 , training loss:  0.007269304980039596\n",
            "eopch:  412 , accuracy:  tensor(87.0700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  413 , learning rate:  7.244727541793713e-06\n",
            "eopch:  413 , training loss:  0.007284006544947624\n",
            "eopch:  413 , accuracy:  tensor(86.9300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  414 , learning rate:  7.139534141352228e-06\n",
            "eopch:  414 , training loss:  0.007283828752636909\n",
            "eopch:  414 , accuracy:  tensor(87.2100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  415 , learning rate:  7.035868148454036e-06\n",
            "eopch:  415 , training loss:  0.007322559689879418\n",
            "eopch:  415 , accuracy:  tensor(87.2200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  416 , learning rate:  6.933707385150773e-06\n",
            "eopch:  416 , training loss:  0.007261211856603622\n",
            "eopch:  416 , accuracy:  tensor(87.1200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  417 , learning rate:  6.833029995517751e-06\n",
            "eopch:  417 , training loss:  0.0072500624454021455\n",
            "eopch:  417 , accuracy:  tensor(87.1300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  418 , learning rate:  6.733814440978178e-06\n",
            "eopch:  418 , training loss:  0.0072914836835861205\n",
            "eopch:  418 , accuracy:  tensor(86.9000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  419 , learning rate:  6.636039495695267e-06\n",
            "eopch:  419 , training loss:  0.0072975703430175785\n",
            "eopch:  419 , accuracy:  tensor(86.8400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  420 , learning rate:  6.539684242031255e-06\n",
            "eopch:  420 , training loss:  0.007286213322281837\n",
            "eopch:  420 , accuracy:  tensor(87.0600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  421 , learning rate:  6.444728066072353e-06\n",
            "eopch:  421 , training loss:  0.007241069991588593\n",
            "eopch:  421 , accuracy:  tensor(87.0900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  422 , learning rate:  6.351150653218677e-06\n",
            "eopch:  422 , training loss:  0.007290273218154907\n",
            "eopch:  422 , accuracy:  tensor(87.1500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  423 , learning rate:  6.25893198383821e-06\n",
            "eopch:  423 , training loss:  0.0072965043503046036\n",
            "eopch:  423 , accuracy:  tensor(86.9000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  424 , learning rate:  6.168052328983875e-06\n",
            "eopch:  424 , training loss:  0.007264143455028534\n",
            "eopch:  424 , accuracy:  tensor(87.0300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  425 , learning rate:  6.078492246172783e-06\n",
            "eopch:  425 , training loss:  0.007290914186835289\n",
            "eopch:  425 , accuracy:  tensor(87.2100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  426 , learning rate:  5.990232575226785e-06\n",
            "eopch:  426 , training loss:  0.007297068568468094\n",
            "eopch:  426 , accuracy:  tensor(87.2800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  427 , learning rate:  5.9032544341734024e-06\n",
            "eopch:  427 , training loss:  0.007256881223917007\n",
            "eopch:  427 , accuracy:  tensor(87.2400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  428 , learning rate:  5.817539215206282e-06\n",
            "eopch:  428 , training loss:  0.00722206026494503\n",
            "eopch:  428 , accuracy:  tensor(87.3800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  429 , learning rate:  5.733068580704308e-06\n",
            "eopch:  429 , training loss:  0.007237878515720367\n",
            "eopch:  429 , accuracy:  tensor(87.2000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  430 , learning rate:  5.649824459308514e-06\n",
            "eopch:  430 , training loss:  0.007299161838889122\n",
            "eopch:  430 , accuracy:  tensor(87.1000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  431 , learning rate:  5.567789042055957e-06\n",
            "eopch:  431 , training loss:  0.007237439185976982\n",
            "eopch:  431 , accuracy:  tensor(87.4100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  432 , learning rate:  5.486944778569728e-06\n",
            "eopch:  432 , training loss:  0.007304648007154465\n",
            "eopch:  432 , accuracy:  tensor(87.2300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  433 , learning rate:  5.407274373304288e-06\n",
            "eopch:  433 , training loss:  0.007312704471349716\n",
            "eopch:  433 , accuracy:  tensor(87.0800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  434 , learning rate:  5.328760781845312e-06\n",
            "eopch:  434 , training loss:  0.007269663916230202\n",
            "eopch:  434 , accuracy:  tensor(87.2500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  435 , learning rate:  5.251387207263272e-06\n",
            "eopch:  435 , training loss:  0.007284458892941475\n",
            "eopch:  435 , accuracy:  tensor(87.0600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  436 , learning rate:  5.175137096519954e-06\n",
            "eopch:  436 , training loss:  0.00724182694196701\n",
            "eopch:  436 , accuracy:  tensor(86.9900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  437 , learning rate:  5.09999413692716e-06\n",
            "eopch:  437 , training loss:  0.007263220939636231\n",
            "eopch:  437 , accuracy:  tensor(87.2300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  438 , learning rate:  5.025942252656827e-06\n",
            "eopch:  438 , training loss:  0.007226333709359169\n",
            "eopch:  438 , accuracy:  tensor(87.1600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  439 , learning rate:  4.952965601301817e-06\n",
            "eopch:  439 , training loss:  0.007300263773202896\n",
            "eopch:  439 , accuracy:  tensor(87.0700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  440 , learning rate:  4.881048570486654e-06\n",
            "eopch:  440 , training loss:  0.007279876718521118\n",
            "eopch:  440 , accuracy:  tensor(87.3000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  441 , learning rate:  4.810175774527454e-06\n",
            "eopch:  441 , training loss:  0.007266410957574844\n",
            "eopch:  441 , accuracy:  tensor(87.2900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  442 , learning rate:  4.740332051140374e-06\n",
            "eopch:  442 , training loss:  0.007291886199116707\n",
            "eopch:  442 , accuracy:  tensor(87.0600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  443 , learning rate:  4.671502458197841e-06\n",
            "eopch:  443 , training loss:  0.00729782322883606\n",
            "eopch:  443 , accuracy:  tensor(87.2700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  444 , learning rate:  4.603672270531885e-06\n",
            "eopch:  444 , training loss:  0.007310580298304558\n",
            "eopch:  444 , accuracy:  tensor(86.8200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  445 , learning rate:  4.536826976783886e-06\n",
            "eopch:  445 , training loss:  0.007296213835477829\n",
            "eopch:  445 , accuracy:  tensor(87.2100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  446 , learning rate:  4.470952276300063e-06\n",
            "eopch:  446 , training loss:  0.0072615951424837115\n",
            "eopch:  446 , accuracy:  tensor(87.0300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  447 , learning rate:  4.406034076072045e-06\n",
            "eopch:  447 , training loss:  0.0073246994543075565\n",
            "eopch:  447 , accuracy:  tensor(87.3400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  448 , learning rate:  4.342058487721854e-06\n",
            "eopch:  448 , training loss:  0.007274979913234711\n",
            "eopch:  448 , accuracy:  tensor(87.2400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  449 , learning rate:  4.279011824530682e-06\n",
            "eopch:  449 , training loss:  0.007258967735767364\n",
            "eopch:  449 , accuracy:  tensor(87.2700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  450 , learning rate:  4.216880598510792e-06\n",
            "eopch:  450 , training loss:  0.007297320175766945\n",
            "eopch:  450 , accuracy:  tensor(87.1000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  451 , learning rate:  4.155651517519949e-06\n",
            "eopch:  451 , training loss:  0.007303041868209839\n",
            "eopch:  451 , accuracy:  tensor(87.3400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  452 , learning rate:  4.0953114824177434e-06\n",
            "eopch:  452 , training loss:  0.007260835869312286\n",
            "eopch:  452 , accuracy:  tensor(87.3400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  453 , learning rate:  4.035847584263207e-06\n",
            "eopch:  453 , training loss:  0.007294664636254311\n",
            "eopch:  453 , accuracy:  tensor(87.2400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  454 , learning rate:  3.977247101553116e-06\n",
            "eopch:  454 , training loss:  0.007273832372426987\n",
            "eopch:  454 , accuracy:  tensor(87.2100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  455 , learning rate:  3.9194974975003975e-06\n",
            "eopch:  455 , training loss:  0.007251253180503845\n",
            "eopch:  455 , accuracy:  tensor(87.1800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  456 , learning rate:  3.86258641735205e-06\n",
            "eopch:  456 , training loss:  0.007271933599114418\n",
            "eopch:  456 , accuracy:  tensor(86.9500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  457 , learning rate:  3.806501685746014e-06\n",
            "eopch:  457 , training loss:  0.007249210333228112\n",
            "eopch:  457 , accuracy:  tensor(87.2600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  458 , learning rate:  3.7512313041064126e-06\n",
            "eopch:  458 , training loss:  0.007271427609324455\n",
            "eopch:  458 , accuracy:  tensor(87.4000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  459 , learning rate:  3.6967634480766187e-06\n",
            "eopch:  459 , training loss:  0.007242431056499481\n",
            "eopch:  459 , accuracy:  tensor(87.4300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  460 , learning rate:  3.643086464989593e-06\n",
            "eopch:  460 , training loss:  0.007250540115237236\n",
            "eopch:  460 , accuracy:  tensor(86.9100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  461 , learning rate:  3.5901888713749513e-06\n",
            "eopch:  461 , training loss:  0.007293980305194855\n",
            "eopch:  461 , accuracy:  tensor(87.2900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  462 , learning rate:  3.5380593505022306e-06\n",
            "eopch:  462 , training loss:  0.007272167916893959\n",
            "eopch:  462 , accuracy:  tensor(87.2000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  463 , learning rate:  3.486686749959826e-06\n",
            "eopch:  463 , training loss:  0.007233104518651962\n",
            "eopch:  463 , accuracy:  tensor(87.3200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  464 , learning rate:  3.436060079269083e-06\n",
            "eopch:  464 , training loss:  0.007285729478597641\n",
            "eopch:  464 , accuracy:  tensor(87.2200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  465 , learning rate:  3.3861685075330307e-06\n",
            "eopch:  465 , training loss:  0.007285201238393784\n",
            "eopch:  465 , accuracy:  tensor(87.0400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  466 , learning rate:  3.3370013611192573e-06\n",
            "eopch:  466 , training loss:  0.0072401180756092075\n",
            "eopch:  466 , accuracy:  tensor(86.9500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  467 , learning rate:  3.2885481213764294e-06\n",
            "eopch:  467 , training loss:  0.00729904232263565\n",
            "eopch:  467 , accuracy:  tensor(87.1300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  468 , learning rate:  3.240798422383968e-06\n",
            "eopch:  468 , training loss:  0.007281916743516922\n",
            "eopch:  468 , accuracy:  tensor(87.3800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  469 , learning rate:  3.193742048734399e-06\n",
            "eopch:  469 , training loss:  0.007279706502556801\n",
            "eopch:  469 , accuracy:  tensor(87.0700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  470 , learning rate:  3.1473689333479027e-06\n",
            "eopch:  470 , training loss:  0.007272721025943756\n",
            "eopch:  470 , accuracy:  tensor(86.8800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  471 , learning rate:  3.1016691553185986e-06\n",
            "eopch:  471 , training loss:  0.0072598035424947735\n",
            "eopch:  471 , accuracy:  tensor(87.1800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  472 , learning rate:  3.0566329377921004e-06\n",
            "eopch:  472 , training loss:  0.007287067802548408\n",
            "eopch:  472 , accuracy:  tensor(87.0200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  473 , learning rate:  3.0122506458738885e-06\n",
            "eopch:  473 , training loss:  0.007309481861591339\n",
            "eopch:  473 , accuracy:  tensor(87.2800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  474 , learning rate:  2.9685127845680536e-06\n",
            "eopch:  474 , training loss:  0.007277518971562385\n",
            "eopch:  474 , accuracy:  tensor(87.2600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  475 , learning rate:  2.9254099967459703e-06\n",
            "eopch:  475 , training loss:  0.007269406609535217\n",
            "eopch:  475 , accuracy:  tensor(87.1700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  476 , learning rate:  2.8829330611444648e-06\n",
            "eopch:  476 , training loss:  0.007268003899455071\n",
            "eopch:  476 , accuracy:  tensor(87.1400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  477 , learning rate:  2.8410728903930495e-06\n",
            "eopch:  477 , training loss:  0.007284102955460548\n",
            "eopch:  477 , accuracy:  tensor(87.2100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  478 , learning rate:  2.7998205290698007e-06\n",
            "eopch:  478 , training loss:  0.007272666438817978\n",
            "eopch:  478 , accuracy:  tensor(87.0300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  479 , learning rate:  2.7591671517854686e-06\n",
            "eopch:  479 , training loss:  0.007268051775693894\n",
            "eopch:  479 , accuracy:  tensor(86.9600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  480 , learning rate:  2.7191040612954016e-06\n",
            "eopch:  480 , training loss:  0.007284414700269699\n",
            "eopch:  480 , accuracy:  tensor(87.1200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  481 , learning rate:  2.6796226866388886e-06\n",
            "eopch:  481 , training loss:  0.007256380796432495\n",
            "eopch:  481 , accuracy:  tensor(87.3200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  482 , learning rate:  2.640714581305516e-06\n",
            "eopch:  482 , training loss:  0.007314566519260406\n",
            "eopch:  482 , accuracy:  tensor(86.9400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  483 , learning rate:  2.6023714214281517e-06\n",
            "eopch:  483 , training loss:  0.007268147336840629\n",
            "eopch:  483 , accuracy:  tensor(87., device='cuda:0', dtype=torch.float64)\n",
            "eopch:  484 , learning rate:  2.5645850040021635e-06\n",
            "eopch:  484 , training loss:  0.007286987433433533\n",
            "eopch:  484 , accuracy:  tensor(87.1500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  485 , learning rate:  2.5273472451304982e-06\n",
            "eopch:  485 , training loss:  0.007243208121657372\n",
            "eopch:  485 , accuracy:  tensor(87.4300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  486 , learning rate:  2.490650178294238e-06\n",
            "eopch:  486 , training loss:  0.007251785341501236\n",
            "eopch:  486 , accuracy:  tensor(87.0500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  487 , learning rate:  2.4544859526482735e-06\n",
            "eopch:  487 , training loss:  0.007299905950427055\n",
            "eopch:  487 , accuracy:  tensor(87.3800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  488 , learning rate:  2.418846831341718e-06\n",
            "eopch:  488 , training loss:  0.007265002393722534\n",
            "eopch:  488 , accuracy:  tensor(86.9400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  489 , learning rate:  2.3837251898627136e-06\n",
            "eopch:  489 , training loss:  0.007270215231776237\n",
            "eopch:  489 , accuracy:  tensor(86.9700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  490 , learning rate:  2.349113514407269e-06\n",
            "eopch:  490 , training loss:  0.00725341214299202\n",
            "eopch:  490 , accuracy:  tensor(87.1500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  491 , learning rate:  2.3150044002717817e-06\n",
            "eopch:  491 , training loss:  0.007292933515906334\n",
            "eopch:  491 , accuracy:  tensor(87.1800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  492 , learning rate:  2.2813905502689013e-06\n",
            "eopch:  492 , training loss:  0.0073369290816783905\n",
            "eopch:  492 , accuracy:  tensor(87.0200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  493 , learning rate:  2.2482647731663934e-06\n",
            "eopch:  493 , training loss:  0.007298596557378769\n",
            "eopch:  493 , accuracy:  tensor(86.9900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  494 , learning rate:  2.215619982148673e-06\n",
            "eopch:  494 , training loss:  0.007250427250862121\n",
            "eopch:  494 , accuracy:  tensor(87.1800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  495 , learning rate:  2.183449193300675e-06\n",
            "eopch:  495 , training loss:  0.007250002456307411\n",
            "eopch:  495 , accuracy:  tensor(87.3500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  496 , learning rate:  2.1517455241137384e-06\n",
            "eopch:  496 , training loss:  0.007297582812309265\n",
            "eopch:  496 , accuracy:  tensor(87.3400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  497 , learning rate:  2.1205021920131872e-06\n",
            "eopch:  497 , training loss:  0.007269605325460434\n",
            "eopch:  497 , accuracy:  tensor(87.0700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  498 , learning rate:  2.089712512907289e-06\n",
            "eopch:  498 , training loss:  0.007259628111720085\n",
            "eopch:  498 , accuracy:  tensor(87.2500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  499 , learning rate:  2.059369899757283e-06\n",
            "eopch:  499 , training loss:  0.007301760939359665\n",
            "eopch:  499 , accuracy:  tensor(87.2000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  500 , learning rate:  2.029467861168172e-06\n",
            "eopch:  500 , training loss:  0.007271017271876335\n",
            "eopch:  500 , accuracy:  tensor(86.7700, device='cuda:0', dtype=torch.float64)\n",
            "Finished Training. Saved network\n"
          ]
        }
      ],
      "source": [
        "if Path(net_fn).is_file():\n",
        "  net.load_state_dict(torch.load(net_fn)) # load file if previously executed\n",
        "  print(\"Skipped Training. Loaded network\")\n",
        "else:\n",
        "  train_loss_of_every_epoch = []\n",
        "  validation_accuracy_of_every_epoch = []\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    running_num = 0\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=LR)\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "      inputs, labels = data\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      outputs = net(inputs) # forward\n",
        "\n",
        "      loss = criterion(outputs, labels) # calculate loss.\n",
        "      loss.backward() # Use binarized weights to compute derivatives to speed up.\n",
        "\n",
        "      for p in list(net.parameters()):\n",
        "        if hasattr(p,'org'):\n",
        "          p.data.copy_(p.org)\n",
        "\n",
        "      optimizer.step() # Use derivatives to update original weights rather than binarized weights.\n",
        "\n",
        "      for p in list(net.parameters()):\n",
        "        if hasattr(p,'org'):\n",
        "          p.org.copy_(p.data.clamp_(-1, 1))\n",
        "\n",
        "      # for p in list(net.parameters()):\n",
        "      #   p.data = p.data.clamp_(-1, 1)\n",
        "\n",
        "      running_loss += loss.item()\n",
        "      running_num += batch_size\n",
        "\n",
        "    \n",
        "    # print(\"eopch: \", epoch+1, \", the magnitude of gradients: \", calculate_the_magnitude_of_gradients(model=net))\n",
        "      \n",
        "    print(\"eopch: \", epoch+1, \", learning rate: \", LR)\n",
        "    LR = LR * LR_decay\n",
        "    \n",
        "    print(\"eopch: \", epoch+1, \", training loss: \", running_loss / running_num)\n",
        "    train_loss_of_every_epoch.append(running_loss / running_num)\n",
        "\n",
        "    top1_acc = validate_model(net, testloader)\n",
        "    print(\"eopch: \", epoch+1, \", accuracy: \", top1_acc)\n",
        "    validation_accuracy_of_every_epoch.append(top1_acc.detach().cpu().numpy())\n",
        "    \n",
        "  torch.save(net.state_dict(), net_fn)\n",
        "  with open(os.path.join(folder, 'train_loss_and_validation_accuracy.csv'), 'w', encoding='UTF8') as f:\n",
        "    writer = csv.writer(f)\n",
        "\n",
        "    writer.writerow(train_loss_of_every_epoch)\n",
        "    writer.writerow(validation_accuracy_of_every_epoch)\n",
        "\n",
        "  print('Finished Training. Saved network')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "AHlw4nIYWId8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(train_loss_of_every_epoch)\n",
        "ax.set_xlabel('epoch')\n",
        "ax.set_ylabel('loss')\n",
        "ax.set_title('train loss vs epoch')\n",
        "fig.savefig(os.path.join(folder, 'train_loss_vs_epoch.png'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QNBdYSVjha_P"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(validation_accuracy_of_every_epoch)\n",
        "ax.set_xlabel('epoch')\n",
        "ax.set_ylabel('loss')\n",
        "ax.set_title('validation accuracy vs epoch')\n",
        "fig.savefig(os.path.join(folder, 'validation_accuracy_vs_epoch.png'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "4be457d9cd553d6c07be4d0c8ec34e07be5ade88f5aab9cc8f32b69b8d65c8ac"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
