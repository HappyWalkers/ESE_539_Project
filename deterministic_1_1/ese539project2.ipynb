{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvKyhdlTZvlM",
        "outputId": "73405d98-baf7-4e67-dfb2-af14dfd3ff1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch Version:  1.13.0\n",
            "Torchvision Version:  0.14.0\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parameter as Parameter\n",
        "import time\n",
        "import random\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import os\n",
        "print(\"PyTorch Version: \", torch.__version__)\n",
        "print(\"Torchvision Version: \", torchvision.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBgXUCr0Sb6d",
        "outputId": "ae75170e-5023-463d-adc7-abaaf76e7850"
      },
      "outputs": [],
      "source": [
        "folder = r'./'\n",
        "\n",
        "net_fn = os.path.join(folder, 'binarized_net.pt')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size = 50 # the original paper use batch size of 50 on CIFAR-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rl_CArykGs6L",
        "outputId": "2c392615-2394-4782-adce-c9aa8074013c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose(\n",
        "  [transforms.ToTensor(),\n",
        "  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "trainset = torchvision.datasets.CIFAR10(root='./../data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "testset = torchvision.datasets.CIFAR10(root='./../data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "w859n_WnZ6lQ"
      },
      "outputs": [],
      "source": [
        "def hard_sigmoid(x):\n",
        "  return torch.clamp((x+1)/2, 0, 1) # The clip function\n",
        "\n",
        "def binarize(W, binary=\"stochastic\"):\n",
        "  if binary == \"stochastic\": # Stochastic binarization\n",
        "    sigma = hard_sigmoid(W)\n",
        "    Wb = torch.distributions.binomial.Binomial(total_count=1, probs=sigma).sample()\n",
        "    Wb = torch.where(Wb==0, torch.tensor(-1., device=device), torch.tensor(1., device=device)) # If we want to binarize the network with 0 and 1, we can delete this line\n",
        "  elif binary == \"deterministic\": # Deterministic binarization with 1 and -1\n",
        "    Wb = torch.where(W >= 0, torch.tensor(1., device=device), torch.tensor(-1., device=device)) # https://pytorch.org/docs/stable/generated/torch.where.html\n",
        "    # Wb = torch.where(W >= 0.5, torch.tensor(1., device=device), torch.tensor(0, device=device)) # Deterministic binarization with 1 and 0\n",
        "  else:\n",
        "    Wb = W\n",
        "  return Wb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "SQEJumq9hZxd"
      },
      "outputs": [],
      "source": [
        "class binConv2d(nn.Conv2d):\n",
        "  def __init__(self, *kargs, **kwargs):\n",
        "    super(binConv2d, self).__init__(*kargs, **kwargs)\n",
        "    self.require_binarization = True\n",
        "  \n",
        "  def forward(self, input):\n",
        "    if not hasattr(self.weight, 'org'):\n",
        "      self.weight.org = self.weight.data.clone()\n",
        "    if True:\n",
        "      self.weight.data = binarize(self.weight.org, binary=\"deterministic\")\n",
        "    else:\n",
        "      self.weight.data.copy_(self.weight.org)\n",
        "    output = nn.functional.conv2d(input, self.weight, None, self.stride, self.padding, self.dilation, self.groups)\n",
        "    return output\n",
        "\n",
        "class binLinear(nn.Linear):\n",
        "  def __init__(self, *kargs, **kwargs):\n",
        "    super(binLinear, self).__init__(*kargs, **kwargs)\n",
        "    self.require_binarization = True\n",
        "  \n",
        "  def forward(self, input):\n",
        "    if not hasattr(self.weight, 'org'):\n",
        "      self.weight.org=self.weight.data.clone()\n",
        "    if True:\n",
        "      self.weight.data = binarize(self.weight.org, binary=\"deterministic\")\n",
        "    else:\n",
        "      self.weight.data.copy_(self.weight.org)\n",
        "    output = nn.functional.linear(input, self.weight, None)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "kIHmjhpluxaQ"
      },
      "outputs": [],
      "source": [
        "class BinaryNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(BinaryNet, self).__init__()\n",
        "    self.features = nn.Sequential(\n",
        "        binConv2d(in_channels=3, out_channels=128, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(num_features=128, affine=False),\n",
        "        # nn.BatchNorm2d(num_features=128, affine=True),\n",
        "        nn.ReLU(),\n",
        "        binConv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(num_features=128, affine=False),\n",
        "        # nn.BatchNorm2d(num_features=128, affine=True),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
        "\n",
        "        binConv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(num_features=256, affine=False),\n",
        "        # nn.BatchNorm2d(num_features=256, affine=True),\n",
        "        nn.ReLU(),\n",
        "        binConv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(num_features=256, affine=False),\n",
        "        # nn.BatchNorm2d(num_features=256, affine=True),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
        "\n",
        "        binConv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(num_features=512, affine=False),\n",
        "        # nn.BatchNorm2d(num_features=512, affine=True),\n",
        "        nn.ReLU(),\n",
        "        binConv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(num_features=512, affine=False),\n",
        "        # nn.BatchNorm2d(num_features=512, affine=True),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
        "\n",
        "        binConv2d(in_channels=512, out_channels=1024, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(num_features=1024, affine=False),\n",
        "        # nn.BatchNorm2d(num_features=1024, affine=True),\n",
        "        nn.ReLU(),\n",
        "        binConv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(num_features=1024, affine=False),\n",
        "        # nn.BatchNorm2d(num_features=1024, affine=True),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
        "    )\n",
        "    self.classifiers = nn.Sequential(\n",
        "        binLinear(4096, 1024),\n",
        "        nn.BatchNorm1d(1024, affine=False),\n",
        "        # nn.BatchNorm1d(1024, affine=True),\n",
        "        binLinear(1024, 10),\n",
        "        nn.BatchNorm1d(10, affine=False),\n",
        "        # nn.BatchNorm1d(10, affine=True),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.features(x)\n",
        "    x = x.view(x.shape[0], -1)\n",
        "    x = self.classifiers(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "l7_ecW8wnCdU"
      },
      "outputs": [],
      "source": [
        "def init_weight(layer): # https://pytorch.org/docs/stable/nn.init.html\n",
        "  if isinstance(layer, nn.Linear) or isinstance(layer, nn.Conv2d):\n",
        "    torch.nn.init.uniform_(layer.weight, a=0, b=1)\n",
        "    # torch.nn.init.normal_(tensor=layer.weight, mean=0.5, std=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaUH0eTu5qeP",
        "outputId": "24cf6785-63b6-4f32-deb1-79f0c52fa665"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_epochs: 500  learning_rate_start: 0.003  learning_rate_final: 2e-06  learning_rate_decay: 0.9854800059995851\n",
            "BinaryNet(\n",
            "  (features): Sequential(\n",
            "    (0): binConv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): binConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (5): ReLU()\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): binConv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (9): ReLU()\n",
            "    (10): binConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (12): ReLU()\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): binConv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (16): ReLU()\n",
            "    (17): binConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (19): ReLU()\n",
            "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (21): binConv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (23): ReLU()\n",
            "    (24): binConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (26): ReLU()\n",
            "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifiers): Sequential(\n",
            "    (0): binLinear(in_features=4096, out_features=1024, bias=True)\n",
            "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (2): binLinear(in_features=1024, out_features=10, bias=True)\n",
            "    (3): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# criterion = nn.HingeEmbeddingLoss(size_average=True)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "num_epochs = 500\n",
        "LR_start = 3 * 1e-3\n",
        "LR_fin = 2 * 1e-6\n",
        "LR_decay = (LR_fin/LR_start)**(1./num_epochs)\n",
        "LR = LR_start\n",
        "net = BinaryNet()\n",
        "# net.apply(fn=init_weight) # init weight for weight of +1 and 0\n",
        "print(\"num_epochs:\", num_epochs, \" learning_rate_start:\", LR_start, \" learning_rate_final:\", LR_fin, \" learning_rate_decay:\", LR_decay)\n",
        "print(net)\n",
        "net = net.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "eaC9y9jXBRGE"
      },
      "outputs": [],
      "source": [
        "def validate_model(model, dataloader, n = None):\n",
        "    \n",
        "    # Set to evaluation mode rather than training mode\n",
        "    model.eval()\n",
        "\n",
        "    top1 = 0\n",
        "    total = 0\n",
        "\n",
        "    # Iterate over data stopping early if n is set\n",
        "    for i, (inputs, labels) in enumerate(dataloader):\n",
        "        if (n is not None and i >= n):\n",
        "            break\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # Run the model and collect the top 1 outputs.\n",
        "        # print(model.features[0].weight.data)\n",
        "        outputs = model(inputs)\n",
        "        # print(model.features[0].weight.data)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        # Gather statistics\n",
        "        top1 += torch.sum(predicted == labels.data)\n",
        "        total += len(outputs)\n",
        "\n",
        "    top1_acc = 100 * top1.double() / total\n",
        "    model.train()\n",
        "    return top1_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "gDvu1d4yOeR4",
        "outputId": "e83a6e75-e15d-4fe1-a3d5-9ca740ddb51a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eopch:  1 , learning rate:  0.003\n",
            "eopch:  1 , training loss:  0.027402911903858185\n",
            "eopch:  1 , accuracy:  tensor(63.5500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  2 , learning rate:  0.002956440017998755\n",
            "eopch:  2 , training loss:  0.02054666643500328\n",
            "eopch:  2 , accuracy:  tensor(71.7200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  3 , learning rate:  0.0029135125266748266\n",
            "eopch:  3 , training loss:  0.016986862452030183\n",
            "eopch:  3 , accuracy:  tensor(78.4900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  4 , learning rate:  0.0028712083422673743\n",
            "eopch:  4 , training loss:  0.015053604744672775\n",
            "eopch:  4 , accuracy:  tensor(80.7900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  5 , learning rate:  0.0028295184143637105\n",
            "eopch:  5 , training loss:  0.013584635640978813\n",
            "eopch:  5 , accuracy:  tensor(82.3300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  6 , learning rate:  0.002788433823963086\n",
            "eopch:  6 , training loss:  0.012419073668718339\n",
            "eopch:  6 , accuracy:  tensor(84.1600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  7 , learning rate:  0.002747945781568588\n",
            "eopch:  7 , training loss:  0.011329538934230804\n",
            "eopch:  7 , accuracy:  tensor(83.8700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  8 , learning rate:  0.0027080456253067466\n",
            "eopch:  8 , training loss:  0.010588940811157226\n",
            "eopch:  8 , accuracy:  tensor(82.5200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  9 , learning rate:  0.0026687248190744427\n",
            "eopch:  9 , training loss:  0.009835596366524696\n",
            "eopch:  9 , accuracy:  tensor(86.0700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  10 , learning rate:  0.0026299749507127236\n",
            "eopch:  10 , training loss:  0.009273664758205414\n",
            "eopch:  10 , accuracy:  tensor(84.7200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  11 , learning rate:  0.0025917877302071334\n",
            "eopch:  11 , training loss:  0.008881684252023696\n",
            "eopch:  11 , accuracy:  tensor(85.5500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  12 , learning rate:  0.002554154987914177\n",
            "eopch:  12 , training loss:  0.008562331442832947\n",
            "eopch:  12 , accuracy:  tensor(86.3600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  13 , learning rate:  0.002517068672813533\n",
            "eopch:  13 , training loss:  0.008280312432646751\n",
            "eopch:  13 , accuracy:  tensor(84.7000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  14 , learning rate:  0.002480520850785648\n",
            "eopch:  14 , training loss:  0.008046445071697234\n",
            "eopch:  14 , accuracy:  tensor(84.4000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  15 , learning rate:  0.0024445037029143363\n",
            "eopch:  15 , training loss:  0.007956251016259193\n",
            "eopch:  15 , accuracy:  tensor(85.7600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  16 , learning rate:  0.002409009523814028\n",
            "eopch:  16 , training loss:  0.007850200034379959\n",
            "eopch:  16 , accuracy:  tensor(85.0700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  17 , learning rate:  0.002374030719981306\n",
            "eopch:  17 , training loss:  0.00773813399374485\n",
            "eopch:  17 , accuracy:  tensor(86.3600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  18 , learning rate:  0.0023395598081703767\n",
            "eopch:  18 , training loss:  0.007622810806632042\n",
            "eopch:  18 , accuracy:  tensor(85.7900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  19 , learning rate:  0.002305589413792131\n",
            "eopch:  19 , training loss:  0.007560670108795166\n",
            "eopch:  19 , accuracy:  tensor(86.4300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  20 , learning rate:  0.002272112269336449\n",
            "eopch:  20 , training loss:  0.00745322627902031\n",
            "eopch:  20 , accuracy:  tensor(86.8900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  21 , learning rate:  0.002239121212817415\n",
            "eopch:  21 , training loss:  0.007408053178787231\n",
            "eopch:  21 , accuracy:  tensor(86.2200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  22 , learning rate:  0.002206609186241104\n",
            "eopch:  22 , training loss:  0.007385367727279663\n",
            "eopch:  22 , accuracy:  tensor(87.0600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  23 , learning rate:  0.002174569234095623\n",
            "eopch:  23 , training loss:  0.0073494118475914\n",
            "eopch:  23 , accuracy:  tensor(86.6800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  24 , learning rate:  0.0021429945018630677\n",
            "eopch:  24 , training loss:  0.007344007924795151\n",
            "eopch:  24 , accuracy:  tensor(86.3700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  25 , learning rate:  0.0021118782345530937\n",
            "eopch:  25 , training loss:  0.007260456103086472\n",
            "eopch:  25 , accuracy:  tensor(86.6300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  26 , learning rate:  0.002081213775257776\n",
            "eopch:  26 , training loss:  0.007229082937836647\n",
            "eopch:  26 , accuracy:  tensor(85.8000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  27 , learning rate:  0.0020509945637274523\n",
            "eopch:  27 , training loss:  0.007195143234729767\n",
            "eopch:  27 , accuracy:  tensor(86.4600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  28 , learning rate:  0.002021214134967246\n",
            "eopch:  28 , training loss:  0.007258038262724876\n",
            "eopch:  28 , accuracy:  tensor(87.0200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  29 , learning rate:  0.0019918661178539676\n",
            "eopch:  29 , training loss:  0.00716439452111721\n",
            "eopch:  29 , accuracy:  tensor(86.6900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  30 , learning rate:  0.0019629442337730984\n",
            "eopch:  30 , training loss:  0.007097110733389854\n",
            "eopch:  30 , accuracy:  tensor(87.5800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  31 , learning rate:  0.001934442295275564\n",
            "eopch:  31 , training loss:  0.00710438683629036\n",
            "eopch:  31 , accuracy:  tensor(88.1300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  32 , learning rate:  0.001906354204754014\n",
            "eopch:  32 , training loss:  0.007119831072688103\n",
            "eopch:  32 , accuracy:  tensor(87.5800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  33 , learning rate:  0.00187867395313832\n",
            "eopch:  33 , training loss:  0.007127929630279541\n",
            "eopch:  33 , accuracy:  tensor(87.3400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  34 , learning rate:  0.0018513956186100157\n",
            "eopch:  34 , training loss:  0.007103837563991547\n",
            "eopch:  34 , accuracy:  tensor(86.8700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  35 , learning rate:  0.0018245133653354037\n",
            "eopch:  35 , training loss:  0.007066017632484436\n",
            "eopch:  35 , accuracy:  tensor(87.2400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  36 , learning rate:  0.0017980214422170567\n",
            "eopch:  36 , training loss:  0.0071173100113868714\n",
            "eopch:  36 , accuracy:  tensor(86.8300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  37 , learning rate:  0.0017719141816634476\n",
            "eopch:  37 , training loss:  0.007060008540153503\n",
            "eopch:  37 , accuracy:  tensor(86.5400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  38 , learning rate:  0.0017461859983764442\n",
            "eopch:  38 , training loss:  0.007055180578231812\n",
            "eopch:  38 , accuracy:  tensor(87.4000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  39 , learning rate:  0.0017208313881564097\n",
            "eopch:  39 , training loss:  0.007073444727063179\n",
            "eopch:  39 , accuracy:  tensor(87.5300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  40 , learning rate:  0.001695844926724653\n",
            "eopch:  40 , training loss:  0.007017084499001503\n",
            "eopch:  40 , accuracy:  tensor(87.7900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  41 , learning rate:  0.0016712212685629768\n",
            "eopch:  41 , training loss:  0.007011368633508683\n",
            "eopch:  41 , accuracy:  tensor(86.4400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  42 , learning rate:  0.0016469551457700766\n",
            "eopch:  42 , training loss:  0.007011296008229256\n",
            "eopch:  42 , accuracy:  tensor(86.9900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  43 , learning rate:  0.0016230413669345426\n",
            "eopch:  43 , training loss:  0.007015426487326622\n",
            "eopch:  43 , accuracy:  tensor(87.3100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  44 , learning rate:  0.0015994748160242278\n",
            "eopch:  44 , training loss:  0.006959688509702682\n",
            "eopch:  44 , accuracy:  tensor(84.4700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  45 , learning rate:  0.0015762504512917414\n",
            "eopch:  45 , training loss:  0.007020212243795395\n",
            "eopch:  45 , accuracy:  tensor(87.1600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  46 , learning rate:  0.001553363304195834\n",
            "eopch:  46 , training loss:  0.006985481603145599\n",
            "eopch:  46 , accuracy:  tensor(87.5800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  47 , learning rate:  0.0015308084783384457\n",
            "eopch:  47 , training loss:  0.006966221908330917\n",
            "eopch:  47 , accuracy:  tensor(87.3000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  48 , learning rate:  0.0015085811484171871\n",
            "eopch:  48 , training loss:  0.006950936300754547\n",
            "eopch:  48 , accuracy:  tensor(87.0200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  49 , learning rate:  0.0014866765591930306\n",
            "eopch:  49 , training loss:  0.006996517477035522\n",
            "eopch:  49 , accuracy:  tensor(88.0600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  50 , learning rate:  0.0014650900244729903\n",
            "eopch:  50 , training loss:  0.006889437801837922\n",
            "eopch:  50 , accuracy:  tensor(88.0400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  51 , learning rate:  0.0014438169261075746\n",
            "eopch:  51 , training loss:  0.006924054062962532\n",
            "eopch:  51 , accuracy:  tensor(88.3400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  52 , learning rate:  0.001422852713002795\n",
            "eopch:  52 , training loss:  0.00692525820851326\n",
            "eopch:  52 , accuracy:  tensor(87.1000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  53 , learning rate:  0.0014021929001465205\n",
            "eopch:  53 , training loss:  0.0069308440291881565\n",
            "eopch:  53 , accuracy:  tensor(87.3800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  54 , learning rate:  0.0013818330676489685\n",
            "eopch:  54 , training loss:  0.0069129485738277435\n",
            "eopch:  54 , accuracy:  tensor(87.6100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  55 , learning rate:  0.0013617688597971306\n",
            "eopch:  55 , training loss:  0.006938191325068474\n",
            "eopch:  55 , accuracy:  tensor(86.5200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  56 , learning rate:  0.0013419959841229243\n",
            "eopch:  56 , training loss:  0.006941623540520668\n",
            "eopch:  56 , accuracy:  tensor(86.8200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  57 , learning rate:  0.0013225102104848785\n",
            "eopch:  57 , training loss:  0.0069310996061563495\n",
            "eopch:  57 , accuracy:  tensor(87.7200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  58 , learning rate:  0.0013033073701631506\n",
            "eopch:  58 , training loss:  0.006897718257904053\n",
            "eopch:  58 , accuracy:  tensor(87.8200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  59 , learning rate:  0.001284383354967685\n",
            "eopch:  59 , training loss:  0.006875961097478867\n",
            "eopch:  59 , accuracy:  tensor(88.2200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  60 , learning rate:  0.0012657341163593214\n",
            "eopch:  60 , training loss:  0.006924691290259361\n",
            "eopch:  60 , accuracy:  tensor(88.4000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  61 , learning rate:  0.0012473556645836636\n",
            "eopch:  61 , training loss:  0.006877139295935631\n",
            "eopch:  61 , accuracy:  tensor(87.9500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  62 , learning rate:  0.0012292440678175252\n",
            "eopch:  62 , training loss:  0.00685872518658638\n",
            "eopch:  62 , accuracy:  tensor(85.3300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  63 , learning rate:  0.001211395451327769\n",
            "eopch:  63 , training loss:  0.0069215044784545895\n",
            "eopch:  63 , accuracy:  tensor(87.2300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  64 , learning rate:  0.00119380599664236\n",
            "eopch:  64 , training loss:  0.006885579985380173\n",
            "eopch:  64 , accuracy:  tensor(87.6100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  65 , learning rate:  0.0011764719407334537\n",
            "eopch:  65 , training loss:  0.006903490903377533\n",
            "eopch:  65 , accuracy:  tensor(87.1100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  66 , learning rate:  0.0011593895752123474\n",
            "eopch:  66 , training loss:  0.0068886751979589465\n",
            "eopch:  66 , accuracy:  tensor(87.9900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  67 , learning rate:  0.0011425552455361205\n",
            "eopch:  67 , training loss:  0.006858352572321892\n",
            "eopch:  67 , accuracy:  tensor(86.5500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  68 , learning rate:  0.0011259653502257935\n",
            "eopch:  68 , training loss:  0.006854485682845116\n",
            "eopch:  68 , accuracy:  tensor(88.1000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  69 , learning rate:  0.0011096163400958398\n",
            "eopch:  69 , training loss:  0.00685331014752388\n",
            "eopch:  69 , accuracy:  tensor(88.4000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  70 , learning rate:  0.001093504717494886\n",
            "eopch:  70 , training loss:  0.006841331987380982\n",
            "eopch:  70 , accuracy:  tensor(88.3300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  71 , learning rate:  0.0010776270355574347\n",
            "eopch:  71 , training loss:  0.006855195739269257\n",
            "eopch:  71 , accuracy:  tensor(87.9800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  72 , learning rate:  0.0010619798974664558\n",
            "eopch:  72 , training loss:  0.006868667246103286\n",
            "eopch:  72 , accuracy:  tensor(88.5400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  73 , learning rate:  0.0010465599557266815\n",
            "eopch:  73 , training loss:  0.006830932131409645\n",
            "eopch:  73 , accuracy:  tensor(88.8700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  74 , learning rate:  0.0010313639114484555\n",
            "eopch:  74 , training loss:  0.00683853338599205\n",
            "eopch:  74 , accuracy:  tensor(88.6000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  75 , learning rate:  0.0010163885136419794\n",
            "eopch:  75 , training loss:  0.0068824736815691\n",
            "eopch:  75 , accuracy:  tensor(87.8600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  76 , learning rate:  0.0010016305585218072\n",
            "eopch:  76 , training loss:  0.006841373592019081\n",
            "eopch:  76 , accuracy:  tensor(87.8100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  77 , learning rate:  0.0009870868888214384\n",
            "eopch:  77 , training loss:  0.006859258862137794\n",
            "eopch:  77 , accuracy:  tensor(88.2500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  78 , learning rate:  0.0009727543931178629\n",
            "eopch:  78 , training loss:  0.006843112536668777\n",
            "eopch:  78 , accuracy:  tensor(87.7400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  79 , learning rate:  0.0009586300051659142\n",
            "eopch:  79 , training loss:  0.006872799184918403\n",
            "eopch:  79 , accuracy:  tensor(88.4000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  80 , learning rate:  0.0009447107032422874\n",
            "eopch:  80 , training loss:  0.006856166080832482\n",
            "eopch:  80 , accuracy:  tensor(88.4900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  81 , learning rate:  0.0009309935094990817\n",
            "eopch:  81 , training loss:  0.00685534574508667\n",
            "eopch:  81 , accuracy:  tensor(88.1500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  82 , learning rate:  0.0009174754893267298\n",
            "eopch:  82 , training loss:  0.006826868976950645\n",
            "eopch:  82 , accuracy:  tensor(87.2200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  83 , learning rate:  0.0009041537507261779\n",
            "eopch:  83 , training loss:  0.006837220807671547\n",
            "eopch:  83 , accuracy:  tensor(88.0600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  84 , learning rate:  0.0008910254436901812\n",
            "eopch:  84 , training loss:  0.006831723690032959\n",
            "eopch:  84 , accuracy:  tensor(88.3200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  85 , learning rate:  0.0008780877595935827\n",
            "eopch:  85 , training loss:  0.006836792554855347\n",
            "eopch:  85 , accuracy:  tensor(87.9600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  86 , learning rate:  0.0008653379305924462\n",
            "eopch:  86 , training loss:  0.006802454274296761\n",
            "eopch:  86 , accuracy:  tensor(87.6800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  87 , learning rate:  0.0008527732290319124\n",
            "eopch:  87 , training loss:  0.006820724006891251\n",
            "eopch:  87 , accuracy:  tensor(88.0700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  88 , learning rate:  0.0008403909668626546\n",
            "eopch:  88 , training loss:  0.006811701176166534\n",
            "eopch:  88 , accuracy:  tensor(88.4100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  89 , learning rate:  0.0008281884950658059\n",
            "eopch:  89 , training loss:  0.006827764066457748\n",
            "eopch:  89 , accuracy:  tensor(88.6500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  90 , learning rate:  0.0008161632030862378\n",
            "eopch:  90 , training loss:  0.006828380154371262\n",
            "eopch:  90 , accuracy:  tensor(87.0900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  91 , learning rate:  0.0008043125182740662\n",
            "eopch:  91 , training loss:  0.006843227745294571\n",
            "eopch:  91 , accuracy:  tensor(88.4400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  92 , learning rate:  0.0007926339053342681\n",
            "eopch:  92 , training loss:  0.006848790925145149\n",
            "eopch:  92 , accuracy:  tensor(88.9000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  93 , learning rate:  0.0007811248657842891\n",
            "eopch:  93 , training loss:  0.006817673015594482\n",
            "eopch:  93 , accuracy:  tensor(89.0800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  94 , learning rate:  0.0007697829374195263\n",
            "eopch:  94 , training loss:  0.0068263490831851955\n",
            "eopch:  94 , accuracy:  tensor(88.7900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  95 , learning rate:  0.000758605693786573\n",
            "eopch:  95 , training loss:  0.006815141899585724\n",
            "eopch:  95 , accuracy:  tensor(88.5100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  96 , learning rate:  0.0007475907436641113\n",
            "eopch:  96 , training loss:  0.006839407088756562\n",
            "eopch:  96 , accuracy:  tensor(88.3500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  97 , learning rate:  0.0007367357305513427\n",
            "eopch:  97 , training loss:  0.006807592138051987\n",
            "eopch:  97 , accuracy:  tensor(87.1500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  98 , learning rate:  0.0007260383321638459\n",
            "eopch:  98 , training loss:  0.006824813051819801\n",
            "eopch:  98 , accuracy:  tensor(89.0900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  99 , learning rate:  0.0007154962599367556\n",
            "eopch:  99 , training loss:  0.006819260925650597\n",
            "eopch:  99 , accuracy:  tensor(87.5500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  100 , learning rate:  0.0007051072585351546\n",
            "eopch:  100 , training loss:  0.006817377042770386\n",
            "eopch:  100 , accuracy:  tensor(88.6800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  101 , learning rate:  0.0006948691053715752\n",
            "eopch:  101 , training loss:  0.0068229395216703416\n",
            "eopch:  101 , accuracy:  tensor(86.8200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  102 , learning rate:  0.0006847796101305062\n",
            "eopch:  102 , training loss:  0.006806914196014404\n",
            "eopch:  102 , accuracy:  tensor(88.3700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  103 , learning rate:  0.0006748366142998048\n",
            "eopch:  103 , training loss:  0.006855631355643273\n",
            "eopch:  103 , accuracy:  tensor(88.6600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  104 , learning rate:  0.0006650379907089112\n",
            "eopch:  104 , training loss:  0.006828051126003265\n",
            "eopch:  104 , accuracy:  tensor(87.8500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  105 , learning rate:  0.0006553816430737698\n",
            "eopch:  105 , training loss:  0.0067834055441617965\n",
            "eopch:  105 , accuracy:  tensor(88.6100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  106 , learning rate:  0.0006458655055483566\n",
            "eopch:  106 , training loss:  0.006827453510761261\n",
            "eopch:  106 , accuracy:  tensor(88.7500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  107 , learning rate:  0.0006364875422827195\n",
            "eopch:  107 , training loss:  0.006787363396286964\n",
            "eopch:  107 , accuracy:  tensor(88.6500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  108 , learning rate:  0.0006272457469874356\n",
            "eopch:  108 , training loss:  0.006824625341892243\n",
            "eopch:  108 , accuracy:  tensor(88.8300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  109 , learning rate:  0.0006181381425043922\n",
            "eopch:  109 , training loss:  0.006816482607126236\n",
            "eopch:  109 , accuracy:  tensor(88.6100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  110 , learning rate:  0.0006091627803838009\n",
            "eopch:  110 , training loss:  0.006836786517500877\n",
            "eopch:  110 , accuracy:  tensor(88.7200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  111 , learning rate:  0.000600317740467352\n",
            "eopch:  111 , training loss:  0.00679760585129261\n",
            "eopch:  111 , accuracy:  tensor(89.0400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  112 , learning rate:  0.0005916011304774234\n",
            "eopch:  112 , training loss:  0.006787823901176453\n",
            "eopch:  112 , accuracy:  tensor(88.7300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  113 , learning rate:  0.0005830110856122526\n",
            "eopch:  113 , training loss:  0.0068036971575021745\n",
            "eopch:  113 , accuracy:  tensor(89.0600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  114 , learning rate:  0.0005745457681469873\n",
            "eopch:  114 , training loss:  0.006814390454292297\n",
            "eopch:  114 , accuracy:  tensor(89.1200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  115 , learning rate:  0.0005662033670405293\n",
            "eopch:  115 , training loss:  0.006812207752466202\n",
            "eopch:  115 , accuracy:  tensor(89.0500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  116 , learning rate:  0.0005579820975480861\n",
            "eopch:  116 , training loss:  0.00681801846563816\n",
            "eopch:  116 , accuracy:  tensor(88.5600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  117 , learning rate:  0.0005498802008393489\n",
            "eopch:  117 , training loss:  0.006812365238070488\n",
            "eopch:  117 , accuracy:  tensor(89.0700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  118 , learning rate:  0.0005418959436222147\n",
            "eopch:  118 , training loss:  0.006811613940596581\n",
            "eopch:  118 , accuracy:  tensor(88.1200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  119 , learning rate:  0.0005340276177719709\n",
            "eopch:  119 , training loss:  0.006812859886884689\n",
            "eopch:  119 , accuracy:  tensor(88.7200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  120 , learning rate:  0.000526273539965866\n",
            "eopch:  120 , training loss:  0.006786309140324593\n",
            "eopch:  120 , accuracy:  tensor(88.7800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  121 , learning rate:  0.0005186320513229845\n",
            "eopch:  121 , training loss:  0.006801756685376167\n",
            "eopch:  121 , accuracy:  tensor(89.3000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  122 , learning rate:  0.0005111015170493518\n",
            "eopch:  122 , training loss:  0.006836216394305229\n",
            "eopch:  122 , accuracy:  tensor(89.1900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  123 , learning rate:  0.0005036803260881923\n",
            "eopch:  123 , training loss:  0.00679320539534092\n",
            "eopch:  123 , accuracy:  tensor(89.3800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  124 , learning rate:  0.0004963668907752647\n",
            "eopch:  124 , training loss:  0.006791057989001274\n",
            "eopch:  124 , accuracy:  tensor(89.2400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  125 , learning rate:  0.0004891596464992032\n",
            "eopch:  125 , training loss:  0.006802939839959145\n",
            "eopch:  125 , accuracy:  tensor(89., device='cuda:0', dtype=torch.float64)\n",
            "eopch:  126 , learning rate:  0.0004820570513667897\n",
            "eopch:  126 , training loss:  0.006822169010043145\n",
            "eopch:  126 , accuracy:  tensor(89.0300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  127 , learning rate:  0.00047505758587308624\n",
            "eopch:  127 , training loss:  0.006813834484219551\n",
            "eopch:  127 , accuracy:  tensor(89.2200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  128 , learning rate:  0.0004681597525763574\n",
            "eopch:  128 , training loss:  0.006802870385050773\n",
            "eopch:  128 , accuracy:  tensor(88.6700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  129 , learning rate:  0.000461362075777713\n",
            "eopch:  129 , training loss:  0.006788018552064895\n",
            "eopch:  129 , accuracy:  tensor(89.1500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  130 , learning rate:  0.0004546631012054016\n",
            "eopch:  130 , training loss:  0.006789510802030563\n",
            "eopch:  130 , accuracy:  tensor(89.1900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  131 , learning rate:  0.00044806139570368914\n",
            "eopch:  131 , training loss:  0.006814846668839455\n",
            "eopch:  131 , accuracy:  tensor(89.1600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  132 , learning rate:  0.000441555546926254\n",
            "eopch:  132 , training loss:  0.00682145292699337\n",
            "eopch:  132 , accuracy:  tensor(89.1000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  133 , learning rate:  0.0004351441630340349\n",
            "eopch:  133 , training loss:  0.0068226787042617795\n",
            "eopch:  133 , accuracy:  tensor(89.0300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  134 , learning rate:  0.0004288258723974651\n",
            "eopch:  134 , training loss:  0.006782628173828125\n",
            "eopch:  134 , accuracy:  tensor(88.6100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  135 , learning rate:  0.0004225993233030312\n",
            "eopch:  135 , training loss:  0.006782612401247025\n",
            "eopch:  135 , accuracy:  tensor(89.0900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  136 , learning rate:  0.0004164631836640918\n",
            "eopch:  136 , training loss:  0.006786891583204269\n",
            "eopch:  136 , accuracy:  tensor(88.5400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  137 , learning rate:  0.00041041614073589547\n",
            "eopch:  137 , training loss:  0.006808039113879204\n",
            "eopch:  137 , accuracy:  tensor(89.4700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  138 , learning rate:  0.0004044569008347368\n",
            "eopch:  138 , training loss:  0.00679450132727623\n",
            "eopch:  138 , accuracy:  tensor(89.1800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  139 , learning rate:  0.00039858418906119\n",
            "eopch:  139 , training loss:  0.006790938044190406\n",
            "eopch:  139 , accuracy:  tensor(89.3000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  140 , learning rate:  0.0003927967490273613\n",
            "eopch:  140 , training loss:  0.006797914960980415\n",
            "eopch:  140 , accuracy:  tensor(89.2500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  141 , learning rate:  0.0003870933425881015\n",
            "eopch:  141 , training loss:  0.00678871653676033\n",
            "eopch:  141 , accuracy:  tensor(89.3800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  142 , learning rate:  0.0003814727495761217\n",
            "eopch:  142 , training loss:  0.00678247189283371\n",
            "eopch:  142 , accuracy:  tensor(89.6000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  143 , learning rate:  0.00037593376754095463\n",
            "eopch:  143 , training loss:  0.006806687175035477\n",
            "eopch:  143 , accuracy:  tensor(89.0400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  144 , learning rate:  0.0003704752114917066\n",
            "eopch:  144 , training loss:  0.006802977399230003\n",
            "eopch:  144 , accuracy:  tensor(89.2900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  145 , learning rate:  0.00036509591364354457\n",
            "eopch:  145 , training loss:  0.00680179660320282\n",
            "eopch:  145 , accuracy:  tensor(89.1600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  146 , learning rate:  0.0003597947231678643\n",
            "eopch:  146 , training loss:  0.006805655639767647\n",
            "eopch:  146 , accuracy:  tensor(89.1300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  147 , learning rate:  0.00035457050594608593\n",
            "eopch:  147 , training loss:  0.006787913087010384\n",
            "eopch:  147 , accuracy:  tensor(89.2900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  148 , learning rate:  0.00034942214432702467\n",
            "eopch:  148 , training loss:  0.006812912279963493\n",
            "eopch:  148 , accuracy:  tensor(88.5600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  149 , learning rate:  0.00034434853688778414\n",
            "eopch:  149 , training loss:  0.006816831361055374\n",
            "eopch:  149 , accuracy:  tensor(89.0300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  150 , learning rate:  0.00033934859819812185\n",
            "eopch:  150 , training loss:  0.006782800166010856\n",
            "eopch:  150 , accuracy:  tensor(89.3600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  151 , learning rate:  0.0003344212585882359\n",
            "eopch:  151 , training loss:  0.006817377310395241\n",
            "eopch:  151 , accuracy:  tensor(89.2200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  152 , learning rate:  0.0003295654639199235\n",
            "eopch:  152 , training loss:  0.006799470353722572\n",
            "eopch:  152 , accuracy:  tensor(88.6500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  153 , learning rate:  0.00032478017536106225\n",
            "eopch:  153 , training loss:  0.006804063752293587\n",
            "eopch:  153 , accuracy:  tensor(89.2000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  154 , learning rate:  0.0003200643691633659\n",
            "eopch:  154 , training loss:  0.0068060279607772825\n",
            "eopch:  154 , accuracy:  tensor(89.0100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  155 , learning rate:  0.0003154170364433672\n",
            "eopch:  155 , training loss:  0.006812390739917755\n",
            "eopch:  155 , accuracy:  tensor(88.8100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  156 , learning rate:  0.00031083718296658086\n",
            "eopch:  156 , training loss:  0.006826149837374687\n",
            "eopch:  156 , accuracy:  tensor(89.3500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  157 , learning rate:  0.00030632382893480025\n",
            "eopch:  157 , training loss:  0.006796247510910034\n",
            "eopch:  157 , accuracy:  tensor(89.4800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  158 , learning rate:  0.0003018760087764828\n",
            "eopch:  158 , training loss:  0.006778747172355652\n",
            "eopch:  158 , accuracy:  tensor(89.3900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  159 , learning rate:  0.0002974927709401791\n",
            "eopch:  159 , training loss:  0.006791380835175514\n",
            "eopch:  159 , accuracy:  tensor(89.1100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  160 , learning rate:  0.0002931731776909609\n",
            "eopch:  160 , training loss:  0.0068309703820943835\n",
            "eopch:  160 , accuracy:  tensor(88.9700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  161 , learning rate:  0.00028891630490980553\n",
            "eopch:  161 , training loss:  0.006806324727535248\n",
            "eopch:  161 , accuracy:  tensor(89.3900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  162 , learning rate:  0.0002847212418958931\n",
            "eopch:  162 , training loss:  0.006785501748323441\n",
            "eopch:  162 , accuracy:  tensor(89.2300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  163 , learning rate:  0.00028058709117177407\n",
            "eopch:  163 , training loss:  0.006802404326796531\n",
            "eopch:  163 , accuracy:  tensor(89.3300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  164 , learning rate:  0.00027651296829136606\n",
            "eopch:  164 , training loss:  0.006815000960826874\n",
            "eopch:  164 , accuracy:  tensor(89.4400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  165 , learning rate:  0.0002724980016507385\n",
            "eopch:  165 , training loss:  0.006805351614952088\n",
            "eopch:  165 , accuracy:  tensor(89.4400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  166 , learning rate:  0.0002685413323016447\n",
            "eopch:  166 , training loss:  0.006800465357303619\n",
            "eopch:  166 , accuracy:  tensor(89.2600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  167 , learning rate:  0.0002646421137677614\n",
            "eopch:  167 , training loss:  0.0068142448675632475\n",
            "eopch:  167 , accuracy:  tensor(89.1600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  168 , learning rate:  0.0002607995118635964\n",
            "eopch:  168 , training loss:  0.0067702321076393126\n",
            "eopch:  168 , accuracy:  tensor(89.1700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  169 , learning rate:  0.00025701270451602585\n",
            "eopch:  169 , training loss:  0.006804779577255249\n",
            "eopch:  169 , accuracy:  tensor(89.0300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  170 , learning rate:  0.00025328088158842275\n",
            "eopch:  170 , training loss:  0.0067984919214248655\n",
            "eopch:  170 , accuracy:  tensor(89.3000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  171 , learning rate:  0.00024960324470733907\n",
            "eopch:  171 , training loss:  0.006806489968299865\n",
            "eopch:  171 , accuracy:  tensor(89.4200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  172 , learning rate:  0.0002459790070917044\n",
            "eopch:  172 , training loss:  0.006804784340262413\n",
            "eopch:  172 , accuracy:  tensor(89.1900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  173 , learning rate:  0.00024240739338450483\n",
            "eopch:  173 , training loss:  0.006780738354921341\n",
            "eopch:  173 , accuracy:  tensor(89.2500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  174 , learning rate:  0.00023888763948690561\n",
            "eopch:  174 , training loss:  0.006803937584161758\n",
            "eopch:  174 , accuracy:  tensor(89.2300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  175 , learning rate:  0.00023541899239478247\n",
            "eopch:  175 , training loss:  0.0067758185994625094\n",
            "eopch:  175 , accuracy:  tensor(89.1700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  176 , learning rate:  0.0002320007100376265\n",
            "eopch:  176 , training loss:  0.0067732654941082\n",
            "eopch:  176 , accuracy:  tensor(89.4700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  177 , learning rate:  0.00022863206111978815\n",
            "eopch:  177 , training loss:  0.00676547794342041\n",
            "eopch:  177 , accuracy:  tensor(89.4500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  178 , learning rate:  0.00022531232496402634\n",
            "eopch:  178 , training loss:  0.006785402374267578\n",
            "eopch:  178 , accuracy:  tensor(89.5200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  179 , learning rate:  0.00022204079135732915\n",
            "eopch:  179 , training loss:  0.006775278933644295\n",
            "eopch:  179 , accuracy:  tensor(89.1800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  180 , learning rate:  0.00021881676039897335\n",
            "eopch:  180 , training loss:  0.006779990378022194\n",
            "eopch:  180 , accuracy:  tensor(89.3500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  181 , learning rate:  0.00021563954235079\n",
            "eopch:  181 , training loss:  0.006808793939352036\n",
            "eopch:  181 , accuracy:  tensor(89.2900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  182 , learning rate:  0.0002125084574896043\n",
            "eopch:  182 , training loss:  0.0067723197299242015\n",
            "eopch:  182 , accuracy:  tensor(89.5500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  183 , learning rate:  0.00020942283596181782\n",
            "eopch:  183 , training loss:  0.006778459397554398\n",
            "eopch:  183 , accuracy:  tensor(89.3200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  184 , learning rate:  0.00020638201764010234\n",
            "eopch:  184 , training loss:  0.0068128884381055835\n",
            "eopch:  184 , accuracy:  tensor(89.2700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  185 , learning rate:  0.00020338535198217452\n",
            "eopch:  185 , training loss:  0.00682659585416317\n",
            "eopch:  185 , accuracy:  tensor(89.4800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  186 , learning rate:  0.00020043219789162107\n",
            "eopch:  186 , training loss:  0.006833987142443657\n",
            "eopch:  186 , accuracy:  tensor(89.5100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  187 , learning rate:  0.00019752192358074474\n",
            "eopch:  187 , training loss:  0.0067563693070411684\n",
            "eopch:  187 , accuracy:  tensor(89.3400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  188 , learning rate:  0.00019465390643540192\n",
            "eopch:  188 , training loss:  0.006775295324921608\n",
            "eopch:  188 , accuracy:  tensor(89.3900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  189 , learning rate:  0.00019182753288180256\n",
            "eopch:  189 , training loss:  0.006830158665180206\n",
            "eopch:  189 , accuracy:  tensor(89.1800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  190 , learning rate:  0.00018904219825524439\n",
            "eopch:  190 , training loss:  0.006759548172950745\n",
            "eopch:  190 , accuracy:  tensor(89.3100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  191 , learning rate:  0.00018629730667075298\n",
            "eopch:  191 , training loss:  0.006804180186390877\n",
            "eopch:  191 , accuracy:  tensor(89.3800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  192 , learning rate:  0.0001835922708956002\n",
            "eopch:  192 , training loss:  0.006775277618169784\n",
            "eopch:  192 , accuracy:  tensor(89.4200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  193 , learning rate:  0.00018092651222367353\n",
            "eopch:  193 , training loss:  0.006788906926512718\n",
            "eopch:  193 , accuracy:  tensor(89.2700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  194 , learning rate:  0.0001782994603516698\n",
            "eopch:  194 , training loss:  0.006790985414385796\n",
            "eopch:  194 , accuracy:  tensor(89.5200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  195 , learning rate:  0.00017571055325708634\n",
            "eopch:  195 , training loss:  0.006792469737529755\n",
            "eopch:  195 , accuracy:  tensor(89.5700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  196 , learning rate:  0.00017315923707798386\n",
            "eopch:  196 , training loss:  0.006807593117356301\n",
            "eopch:  196 , accuracy:  tensor(89.5900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  197 , learning rate:  0.0001706449659944951\n",
            "eopch:  197 , training loss:  0.0068053979277610775\n",
            "eopch:  197 , accuracy:  tensor(89.4600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  198 , learning rate:  0.00016816720211205403\n",
            "eopch:  198 , training loss:  0.006800265064835548\n",
            "eopch:  198 , accuracy:  tensor(89.5200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  199 , learning rate:  0.00016572541534632044\n",
            "eopch:  199 , training loss:  0.006780782058238983\n",
            "eopch:  199 , accuracy:  tensor(89.4200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  200 , learning rate:  0.0001633190833097756\n",
            "eopch:  200 , training loss:  0.00680923342525959\n",
            "eopch:  200 , accuracy:  tensor(88.9600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  201 , learning rate:  0.0001609476911999644\n",
            "eopch:  201 , training loss:  0.006795067169666291\n",
            "eopch:  201 , accuracy:  tensor(89.3200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  202 , learning rate:  0.00015861073168936028\n",
            "eopch:  202 , training loss:  0.006786902530789375\n",
            "eopch:  202 , accuracy:  tensor(89.6200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  203 , learning rate:  0.00015630770481682934\n",
            "eopch:  203 , training loss:  0.006768210723400116\n",
            "eopch:  203 , accuracy:  tensor(89.5700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  204 , learning rate:  0.00015403811788067034\n",
            "eopch:  204 , training loss:  0.006808319928646087\n",
            "eopch:  204 , accuracy:  tensor(89.6800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  205 , learning rate:  0.0001518014853332078\n",
            "eopch:  205 , training loss:  0.00677114181637764\n",
            "eopch:  205 , accuracy:  tensor(89.6000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  206 , learning rate:  0.00014959732867691556\n",
            "eopch:  206 , training loss:  0.0068019881576299665\n",
            "eopch:  206 , accuracy:  tensor(89.5700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  207 , learning rate:  0.00014742517636204865\n",
            "eopch:  207 , training loss:  0.0068215065443515775\n",
            "eopch:  207 , accuracy:  tensor(89.5600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  208 , learning rate:  0.0001452845636857616\n",
            "eopch:  208 , training loss:  0.006774447433948517\n",
            "eopch:  208 , accuracy:  tensor(89.4400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  209 , learning rate:  0.00014317503269269143\n",
            "eopch:  209 , training loss:  0.006794293658137321\n",
            "eopch:  209 , accuracy:  tensor(89.5400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  210 , learning rate:  0.00014109613207698434\n",
            "eopch:  210 , training loss:  0.006785638099908829\n",
            "eopch:  210 , accuracy:  tensor(89.4800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  211 , learning rate:  0.00013904741708574477\n",
            "eopch:  211 , training loss:  0.006813026988506317\n",
            "eopch:  211 , accuracy:  tensor(89.4400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  212 , learning rate:  0.00013702844942388656\n",
            "eopch:  212 , training loss:  0.006819055625200272\n",
            "eopch:  212 , accuracy:  tensor(89.3500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  213 , learning rate:  0.00013503879716036558\n",
            "eopch:  213 , training loss:  0.0067997940808534624\n",
            "eopch:  213 , accuracy:  tensor(89.6100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  214 , learning rate:  0.0001330780346357738\n",
            "eopch:  214 , training loss:  0.006794318763613701\n",
            "eopch:  214 , accuracy:  tensor(89.4600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  215 , learning rate:  0.00013114574237127537\n",
            "eopch:  215 , training loss:  0.006784018745422363\n",
            "eopch:  215 , accuracy:  tensor(89.5600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  216 , learning rate:  0.00012924150697886448\n",
            "eopch:  216 , training loss:  0.006762221811413765\n",
            "eopch:  216 , accuracy:  tensor(89.6600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  217 , learning rate:  0.0001273649210729268\n",
            "eopch:  217 , training loss:  0.006816320568919182\n",
            "eopch:  217 , accuracy:  tensor(89.6800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  218 , learning rate:  0.00012551558318308457\n",
            "eopch:  218 , training loss:  0.006762245248556137\n",
            "eopch:  218 , accuracy:  tensor(89.4100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  219 , learning rate:  0.0001236930976683076\n",
            "eopch:  219 , training loss:  0.00676878145635128\n",
            "eopch:  219 , accuracy:  tensor(89.8200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  220 , learning rate:  0.00012189707463227104\n",
            "eopch:  220 , training loss:  0.00680388057410717\n",
            "eopch:  220 , accuracy:  tensor(89.6200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  221 , learning rate:  0.00012012712983994233\n",
            "eopch:  221 , training loss:  0.006786476568579673\n",
            "eopch:  221 , accuracy:  tensor(89.5900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  222 , learning rate:  0.0001183828846353793\n",
            "eopch:  222 , training loss:  0.0068089092588424684\n",
            "eopch:  222 , accuracy:  tensor(89.3700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  223 , learning rate:  0.00011666396586072178\n",
            "eopch:  223 , training loss:  0.0068228203839063644\n",
            "eopch:  223 , accuracy:  tensor(89.5800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  224 , learning rate:  0.00011497000577635949\n",
            "eopch:  224 , training loss:  0.006791606621742248\n",
            "eopch:  224 , accuracy:  tensor(89.6500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  225 , learning rate:  0.00011330064198225908\n",
            "eopch:  225 , training loss:  0.006826609428524971\n",
            "eopch:  225 , accuracy:  tensor(89.7100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  226 , learning rate:  0.00011165551734043351\n",
            "eopch:  226 , training loss:  0.006822885845303535\n",
            "eopch:  226 , accuracy:  tensor(89.2500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  227 , learning rate:  0.00011003427989853719\n",
            "eopch:  227 , training loss:  0.006807316524386406\n",
            "eopch:  227 , accuracy:  tensor(89.2600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  228 , learning rate:  0.00010843658281457045\n",
            "eopch:  228 , training loss:  0.006769753893017769\n",
            "eopch:  228 , accuracy:  tensor(89.2900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  229 , learning rate:  0.00010686208428267739\n",
            "eopch:  229 , training loss:  0.006790183420777321\n",
            "eopch:  229 , accuracy:  tensor(89.3800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  230 , learning rate:  0.00010531044746002108\n",
            "eopch:  230 , training loss:  0.0067912002545595165\n",
            "eopch:  230 , accuracy:  tensor(89.5800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  231 , learning rate:  0.00010378134039472056\n",
            "eopch:  231 , training loss:  0.0068246771991252895\n",
            "eopch:  231 , accuracy:  tensor(89.3500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  232 , learning rate:  0.00010227443595483421\n",
            "eopch:  232 , training loss:  0.006803977110385895\n",
            "eopch:  232 , accuracy:  tensor(89.3800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  233 , learning rate:  0.0001007894117583742\n",
            "eopch:  233 , training loss:  0.0067853737133741375\n",
            "eopch:  233 , accuracy:  tensor(89.7500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  234 , learning rate:  9.932595010433725e-05\n",
            "eopch:  234 , training loss:  0.006788858949542046\n",
            "eopch:  234 , accuracy:  tensor(89.1300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  235 , learning rate:  9.788373790473676e-05\n",
            "eopch:  235 , training loss:  0.006782954944372177\n",
            "eopch:  235 , accuracy:  tensor(89.4000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  236 , learning rate:  9.646246661762179e-05\n",
            "eopch:  236 , training loss:  0.006764667759537697\n",
            "eopch:  236 , accuracy:  tensor(89.4700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  237 , learning rate:  9.50618321810687e-05\n",
            "eopch:  237 , training loss:  0.006794315077066421\n",
            "eopch:  237 , accuracy:  tensor(89.6700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  238 , learning rate:  9.368153494813113e-05\n",
            "eopch:  238 , training loss:  0.006799869113564491\n",
            "eopch:  238 , accuracy:  tensor(89.6100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  239 , learning rate:  9.232127962273461e-05\n",
            "eopch:  239 , training loss:  0.006802994773983956\n",
            "eopch:  239 , accuracy:  tensor(89.4400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  240 , learning rate:  9.098077519650187e-05\n",
            "eopch:  240 , training loss:  0.006793171375989914\n",
            "eopch:  240 , accuracy:  tensor(89.4600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  241 , learning rate:  8.965973488649556e-05\n",
            "eopch:  241 , training loss:  0.006809547975063324\n",
            "eopch:  241 , accuracy:  tensor(89.2900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  242 , learning rate:  8.835787607386486e-05\n",
            "eopch:  242 , training loss:  0.006801149304509163\n",
            "eopch:  242 , accuracy:  tensor(89.5200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  243 , learning rate:  8.707492024338293e-05\n",
            "eopch:  243 , training loss:  0.006782250584959984\n",
            "eopch:  243 , accuracy:  tensor(89.3600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  244 , learning rate:  8.58105929238624e-05\n",
            "eopch:  244 , training loss:  0.0067705302649736405\n",
            "eopch:  244 , accuracy:  tensor(89.4100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  245 , learning rate:  8.456462362943586e-05\n",
            "eopch:  245 , training loss:  0.006759921416640282\n",
            "eopch:  245 , accuracy:  tensor(89.3900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  246 , learning rate:  8.333674580168911e-05\n",
            "eopch:  246 , training loss:  0.0067923395001888275\n",
            "eopch:  246 , accuracy:  tensor(89.4200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  247 , learning rate:  8.212669675263449e-05\n",
            "eopch:  247 , training loss:  0.006768703101277351\n",
            "eopch:  247 , accuracy:  tensor(89.4500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  248 , learning rate:  8.093421760851234e-05\n",
            "eopch:  248 , training loss:  0.006796219421625138\n",
            "eopch:  248 , accuracy:  tensor(89.4200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  249 , learning rate:  7.975905325440847e-05\n",
            "eopch:  249 , training loss:  0.0068116581946611405\n",
            "eopch:  249 , accuracy:  tensor(89.5100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  250 , learning rate:  7.860095227967569e-05\n",
            "eopch:  250 , training loss:  0.006793400678038597\n",
            "eopch:  250 , accuracy:  tensor(89.5100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  251 , learning rate:  7.74596669241479e-05\n",
            "eopch:  251 , training loss:  0.006794704660177231\n",
            "eopch:  251 , accuracy:  tensor(89.4100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  252 , learning rate:  7.633495302513513e-05\n",
            "eopch:  252 , training loss:  0.006770112468600273\n",
            "eopch:  252 , accuracy:  tensor(89.5800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  253 , learning rate:  7.522656996518822e-05\n",
            "eopch:  253 , training loss:  0.006794686512351036\n",
            "eopch:  253 , accuracy:  tensor(89.4800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  254 , learning rate:  7.413428062062189e-05\n",
            "eopch:  254 , training loss:  0.006785603129863739\n",
            "eopch:  254 , accuracy:  tensor(89.4600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  255 , learning rate:  7.305785131078539e-05\n",
            "eopch:  255 , training loss:  0.00679644413113594\n",
            "eopch:  255 , accuracy:  tensor(89.4400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  256 , learning rate:  7.199705174806958e-05\n",
            "eopch:  256 , training loss:  0.006782537860870361\n",
            "eopch:  256 , accuracy:  tensor(89.4800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  257 , learning rate:  7.095165498864005e-05\n",
            "eopch:  257 , training loss:  0.006769428822994232\n",
            "eopch:  257 , accuracy:  tensor(89.4900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  258 , learning rate:  6.992143738388548e-05\n",
            "eopch:  258 , training loss:  0.006816120674610138\n",
            "eopch:  258 , accuracy:  tensor(89.4000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  259 , learning rate:  6.890617853257107e-05\n",
            "eopch:  259 , training loss:  0.006773973157405853\n",
            "eopch:  259 , accuracy:  tensor(89.4800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  260 , learning rate:  6.790566123368661e-05\n",
            "eopch:  260 , training loss:  0.006801587748527527\n",
            "eopch:  260 , accuracy:  tensor(89.4900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  261 , learning rate:  6.691967143997927e-05\n",
            "eopch:  261 , training loss:  0.006782545072436333\n",
            "eopch:  261 , accuracy:  tensor(89.5500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  262 , learning rate:  6.594799821216104e-05\n",
            "eopch:  262 , training loss:  0.006785609042048454\n",
            "eopch:  262 , accuracy:  tensor(89.4700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  263 , learning rate:  6.499043367378109e-05\n",
            "eopch:  263 , training loss:  0.00679818390071392\n",
            "eopch:  263 , accuracy:  tensor(89.6500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  264 , learning rate:  6.404677296675342e-05\n",
            "eopch:  264 , training loss:  0.006809398978352547\n",
            "eopch:  264 , accuracy:  tensor(89.5900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  265 , learning rate:  6.311681420753022e-05\n",
            "eopch:  265 , training loss:  0.006816217344403267\n",
            "eopch:  265 , accuracy:  tensor(89.5800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  266 , learning rate:  6.220035844391158e-05\n",
            "eopch:  266 , training loss:  0.006794530657529831\n",
            "eopch:  266 , accuracy:  tensor(89.5300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  267 , learning rate:  6.129720961248233e-05\n",
            "eopch:  267 , training loss:  0.006814005321860313\n",
            "eopch:  267 , accuracy:  tensor(89.3200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  268 , learning rate:  6.0407174496666905e-05\n",
            "eopch:  268 , training loss:  0.006786570386886597\n",
            "eopch:  268 , accuracy:  tensor(89.4100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  269 , learning rate:  5.953006268539328e-05\n",
            "eopch:  269 , training loss:  0.006795037027597427\n",
            "eopch:  269 , accuracy:  tensor(89.7200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  270 , learning rate:  5.866568653235705e-05\n",
            "eopch:  270 , training loss:  0.006784293454885483\n",
            "eopch:  270 , accuracy:  tensor(89.6700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  271 , learning rate:  5.7813861115877e-05\n",
            "eopch:  271 , training loss:  0.0068271410673856735\n",
            "eopch:  271 , accuracy:  tensor(89.6400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  272 , learning rate:  5.6974404199333645e-05\n",
            "eopch:  272 , training loss:  0.006804291048645973\n",
            "eopch:  272 , accuracy:  tensor(89.3600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  273 , learning rate:  5.614713619218211e-05\n",
            "eopch:  273 , training loss:  0.006792632777690887\n",
            "eopch:  273 , accuracy:  tensor(89.5100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  274 , learning rate:  5.533188011153114e-05\n",
            "eopch:  274 , training loss:  0.006785339457988739\n",
            "eopch:  274 , accuracy:  tensor(89.5000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  275 , learning rate:  5.452846154428003e-05\n",
            "eopch:  275 , training loss:  0.0068093660873174665\n",
            "eopch:  275 , accuracy:  tensor(89.1800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  276 , learning rate:  5.373670860980523e-05\n",
            "eopch:  276 , training loss:  0.006824827876091003\n",
            "eopch:  276 , accuracy:  tensor(89.6400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  277 , learning rate:  5.295645192318881e-05\n",
            "eopch:  277 , training loss:  0.006795580757856369\n",
            "eopch:  277 , accuracy:  tensor(89.4800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  278 , learning rate:  5.218752455898085e-05\n",
            "eopch:  278 , training loss:  0.006792760312557221\n",
            "eopch:  278 , accuracy:  tensor(89.6600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  279 , learning rate:  5.142976201548794e-05\n",
            "eopch:  279 , training loss:  0.006818320055007935\n",
            "eopch:  279 , accuracy:  tensor(89.5900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  280 , learning rate:  5.068300217958029e-05\n",
            "eopch:  280 , training loss:  0.006810161361694336\n",
            "eopch:  280 , accuracy:  tensor(89.5000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  281 , learning rate:  4.9947085292009764e-05\n",
            "eopch:  281 , training loss:  0.006809383043646812\n",
            "eopch:  281 , accuracy:  tensor(89.4000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  282 , learning rate:  4.922185391323157e-05\n",
            "eopch:  282 , training loss:  0.006809500800967217\n",
            "eopch:  282 , accuracy:  tensor(89.3000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  283 , learning rate:  4.8507152889722145e-05\n",
            "eopch:  283 , training loss:  0.006804575855135918\n",
            "eopch:  283 , accuracy:  tensor(89.7900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  284 , learning rate:  4.780282932078617e-05\n",
            "eopch:  284 , training loss:  0.006769339327216148\n",
            "eopch:  284 , accuracy:  tensor(89.7000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  285 , learning rate:  4.71087325258455e-05\n",
            "eopch:  285 , training loss:  0.006796391508579254\n",
            "eopch:  285 , accuracy:  tensor(89.5100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  286 , learning rate:  4.642471401220307e-05\n",
            "eopch:  286 , training loss:  0.006780641419887543\n",
            "eopch:  286 , accuracy:  tensor(89.6100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  287 , learning rate:  4.57506274432749e-05\n",
            "eopch:  287 , training loss:  0.006766439802646637\n",
            "eopch:  287 , accuracy:  tensor(89.4800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  288 , learning rate:  4.508632860728333e-05\n",
            "eopch:  288 , training loss:  0.006824172319173813\n",
            "eopch:  288 , accuracy:  tensor(89.4800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  289 , learning rate:  4.4431675386404845e-05\n",
            "eopch:  289 , training loss:  0.006799385091662407\n",
            "eopch:  289 , accuracy:  tensor(89.6300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  290 , learning rate:  4.3786527726365866e-05\n",
            "eopch:  290 , training loss:  0.006798845946192742\n",
            "eopch:  290 , accuracy:  tensor(89.5800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  291 , learning rate:  4.315074760648003e-05\n",
            "eopch:  291 , training loss:  0.006771636861562729\n",
            "eopch:  291 , accuracy:  tensor(89.4900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  292 , learning rate:  4.2524199010120525e-05\n",
            "eopch:  292 , training loss:  0.006780773542523384\n",
            "eopch:  292 , accuracy:  tensor(89.5200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  293 , learning rate:  4.190674789562113e-05\n",
            "eopch:  293 , training loss:  0.006815891546607018\n",
            "eopch:  293 , accuracy:  tensor(89.6300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  294 , learning rate:  4.129826216759981e-05\n",
            "eopch:  294 , training loss:  0.006797832537293434\n",
            "eopch:  294 , accuracy:  tensor(89.4800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  295 , learning rate:  4.069861164869869e-05\n",
            "eopch:  295 , training loss:  0.006801733677983284\n",
            "eopch:  295 , accuracy:  tensor(89.6200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  296 , learning rate:  4.010766805173437e-05\n",
            "eopch:  296 , training loss:  0.006786606347560883\n",
            "eopch:  296 , accuracy:  tensor(89.6900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  297 , learning rate:  3.952530495225255e-05\n",
            "eopch:  297 , training loss:  0.006792443144917488\n",
            "eopch:  297 , accuracy:  tensor(89.4800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  298 , learning rate:  3.895139776148127e-05\n",
            "eopch:  298 , training loss:  0.006793669927716255\n",
            "eopch:  298 , accuracy:  tensor(89.3400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  299 , learning rate:  3.8385823699676784e-05\n",
            "eopch:  299 , training loss:  0.006805725179314613\n",
            "eopch:  299 , accuracy:  tensor(89.5800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  300 , learning rate:  3.7828461769856494e-05\n",
            "eopch:  300 , training loss:  0.006756235001683235\n",
            "eopch:  300 , accuracy:  tensor(89.4900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  301 , learning rate:  3.7279192731913254e-05\n",
            "eopch:  301 , training loss:  0.006798721585869789\n",
            "eopch:  301 , accuracy:  tensor(89.4900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  302 , learning rate:  3.673789907710556e-05\n",
            "eopch:  302 , training loss:  0.006800778170228005\n",
            "eopch:  302 , accuracy:  tensor(89.5100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  303 , learning rate:  3.6204465002918137e-05\n",
            "eopch:  303 , training loss:  0.006769663927555084\n",
            "eopch:  303 , accuracy:  tensor(89.7000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  304 , learning rate:  3.5678776388287535e-05\n",
            "eopch:  304 , training loss:  0.006801272423863411\n",
            "eopch:  304 , accuracy:  tensor(89.4700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  305 , learning rate:  3.516072076918745e-05\n",
            "eopch:  305 , training loss:  0.006773974699378013\n",
            "eopch:  305 , accuracy:  tensor(89.6500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  306 , learning rate:  3.465018731456859e-05\n",
            "eopch:  306 , training loss:  0.006801863886713982\n",
            "eopch:  306 , accuracy:  tensor(89.6600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  307 , learning rate:  3.41470668026478e-05\n",
            "eopch:  307 , training loss:  0.006767185724377632\n",
            "eopch:  307 , accuracy:  tensor(89.5500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  308 , learning rate:  3.365125159754159e-05\n",
            "eopch:  308 , training loss:  0.006807752649784088\n",
            "eopch:  308 , accuracy:  tensor(89.6300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  309 , learning rate:  3.316263562623883e-05\n",
            "eopch:  309 , training loss:  0.0067883151668310165\n",
            "eopch:  309 , accuracy:  tensor(89.7300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  310 , learning rate:  3.2681114355907896e-05\n",
            "eopch:  310 , training loss:  0.006796206622719765\n",
            "eopch:  310 , accuracy:  tensor(89.6700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  311 , learning rate:  3.220658477153324e-05\n",
            "eopch:  311 , training loss:  0.006807838249206543\n",
            "eopch:  311 , accuracy:  tensor(89.6700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  312 , learning rate:  3.173894535387672e-05\n",
            "eopch:  312 , training loss:  0.006803529942035675\n",
            "eopch:  312 , accuracy:  tensor(89.5900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  313 , learning rate:  3.1278096057758936e-05\n",
            "eopch:  313 , training loss:  0.006786649116277695\n",
            "eopch:  313 , accuracy:  tensor(89.4500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  314 , learning rate:  3.082393829065587e-05\n",
            "eopch:  314 , training loss:  0.006798504647016525\n",
            "eopch:  314 , accuracy:  tensor(89.7000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  315 , learning rate:  3.0376374891606387e-05\n",
            "eopch:  315 , training loss:  0.006818456282019615\n",
            "eopch:  315 , accuracy:  tensor(89.6000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  316 , learning rate:  2.993531011042591e-05\n",
            "eopch:  316 , training loss:  0.00680243492782116\n",
            "eopch:  316 , accuracy:  tensor(89.4600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  317 , learning rate:  2.9500649587221963e-05\n",
            "eopch:  317 , training loss:  0.00679324919462204\n",
            "eopch:  317 , accuracy:  tensor(89.5000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  318 , learning rate:  2.9072300332207158e-05\n",
            "eopch:  318 , training loss:  0.006799806125760079\n",
            "eopch:  318 , accuracy:  tensor(89.6000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  319 , learning rate:  2.865017070580525e-05\n",
            "eopch:  319 , training loss:  0.006827232791185379\n",
            "eopch:  319 , accuracy:  tensor(89.5900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  320 , learning rate:  2.8234170399046094e-05\n",
            "eopch:  320 , training loss:  0.006785344143509865\n",
            "eopch:  320 , accuracy:  tensor(89.6700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  321 , learning rate:  2.7824210414245252e-05\n",
            "eopch:  321 , training loss:  0.0068042041939496995\n",
            "eopch:  321 , accuracy:  tensor(89.4500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  322 , learning rate:  2.7420203045964128e-05\n",
            "eopch:  322 , training loss:  0.006769152104854584\n",
            "eopch:  322 , accuracy:  tensor(89.6700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  323 , learning rate:  2.702206186224657e-05\n",
            "eopch:  323 , training loss:  0.00679982478916645\n",
            "eopch:  323 , accuracy:  tensor(89.4000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  324 , learning rate:  2.662970168612791e-05\n",
            "eopch:  324 , training loss:  0.0067884800034761425\n",
            "eopch:  324 , accuracy:  tensor(89.5600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  325 , learning rate:  2.624303857741249e-05\n",
            "eopch:  325 , training loss:  0.00680732982635498\n",
            "eopch:  325 , accuracy:  tensor(89.4900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  326 , learning rate:  2.5861989814715805e-05\n",
            "eopch:  326 , training loss:  0.006775492146611214\n",
            "eopch:  326 , accuracy:  tensor(89.5200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  327 , learning rate:  2.5486473877767338e-05\n",
            "eopch:  327 , training loss:  0.006797293118238449\n",
            "eopch:  327 , accuracy:  tensor(89.6400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  328 , learning rate:  2.5116410429970424e-05\n",
            "eopch:  328 , training loss:  0.006817778283953667\n",
            "eopch:  328 , accuracy:  tensor(89.7100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  329 , learning rate:  2.4751720301215294e-05\n",
            "eopch:  329 , training loss:  0.0067796183305978775\n",
            "eopch:  329 , accuracy:  tensor(89.7400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  330 , learning rate:  2.43923254709417e-05\n",
            "eopch:  330 , training loss:  0.006812463277578354\n",
            "eopch:  330 , accuracy:  tensor(89.5300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  331 , learning rate:  2.403814905144746e-05\n",
            "eopch:  331 , training loss:  0.006761257280111313\n",
            "eopch:  331 , accuracy:  tensor(89.6200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  332 , learning rate:  2.3689115271439363e-05\n",
            "eopch:  332 , training loss:  0.0067981537067890166\n",
            "eopch:  332 , accuracy:  tensor(89.5100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  333 , learning rate:  2.3345149459822927e-05\n",
            "eopch:  333 , training loss:  0.006796395661830902\n",
            "eopch:  333 , accuracy:  tensor(89.4100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  334 , learning rate:  2.300617802972751e-05\n",
            "eopch:  334 , training loss:  0.006775009416341782\n",
            "eopch:  334 , accuracy:  tensor(89.7300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  335 , learning rate:  2.267212846276339e-05\n",
            "eopch:  335 , training loss:  0.006796741305589676\n",
            "eopch:  335 , accuracy:  tensor(89.4000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  336 , learning rate:  2.2342929293507428e-05\n",
            "eopch:  336 , training loss:  0.006782371159791947\n",
            "eopch:  336 , accuracy:  tensor(89.4600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  337 , learning rate:  2.2018510094214004e-05\n",
            "eopch:  337 , training loss:  0.006780840656757355\n",
            "eopch:  337 , accuracy:  tensor(89.5100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  338 , learning rate:  2.169880145974794e-05\n",
            "eopch:  338 , training loss:  0.0067929221057891846\n",
            "eopch:  338 , accuracy:  tensor(89.6900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  339 , learning rate:  2.1383734992736207e-05\n",
            "eopch:  339 , training loss:  0.00678610611140728\n",
            "eopch:  339 , accuracy:  tensor(89.6800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  340 , learning rate:  2.1073243288935215e-05\n",
            "eopch:  340 , training loss:  0.006772739589810371\n",
            "eopch:  340 , accuracy:  tensor(89.3900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  341 , learning rate:  2.076725992281059e-05\n",
            "eopch:  341 , training loss:  0.006818619168400764\n",
            "eopch:  341 , accuracy:  tensor(89.4200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  342 , learning rate:  2.0465719433326323e-05\n",
            "eopch:  342 , training loss:  0.006766121766567231\n",
            "eopch:  342 , accuracy:  tensor(89.6100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  343 , learning rate:  2.016855730994025e-05\n",
            "eopch:  343 , training loss:  0.0067546409451961515\n",
            "eopch:  343 , accuracy:  tensor(89.6800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  344 , learning rate:  1.9875709978802893e-05\n",
            "eopch:  344 , training loss:  0.006820956881642342\n",
            "eopch:  344 , accuracy:  tensor(89.6300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  345 , learning rate:  1.958711478915669e-05\n",
            "eopch:  345 , training loss:  0.006795421491861344\n",
            "eopch:  345 , accuracy:  tensor(89.5000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  346 , learning rate:  1.9302709999932696e-05\n",
            "eopch:  346 , training loss:  0.006791388722062111\n",
            "eopch:  346 , accuracy:  tensor(89.4900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  347 , learning rate:  1.9022434766541923e-05\n",
            "eopch:  347 , training loss:  0.006823085190653801\n",
            "eopch:  347 , accuracy:  tensor(89.6500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  348 , learning rate:  1.874622912785845e-05\n",
            "eopch:  348 , training loss:  0.006796809913516045\n",
            "eopch:  348 , accuracy:  tensor(89.5000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  349 , learning rate:  1.8474033993391543e-05\n",
            "eopch:  349 , training loss:  0.006789997062683105\n",
            "eopch:  349 , accuracy:  tensor(89.5400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  350 , learning rate:  1.8205791130644037e-05\n",
            "eopch:  350 , training loss:  0.0067769488859176635\n",
            "eopch:  350 , accuracy:  tensor(89.6100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  351 , learning rate:  1.794144315265428e-05\n",
            "eopch:  351 , training loss:  0.006770653422474861\n",
            "eopch:  351 , accuracy:  tensor(89.4800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  352 , learning rate:  1.7680933505718953e-05\n",
            "eopch:  352 , training loss:  0.0067641844516992565\n",
            "eopch:  352 , accuracy:  tensor(89.3400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  353 , learning rate:  1.742420645729418e-05\n",
            "eopch:  353 , training loss:  0.0067850787729024885\n",
            "eopch:  353 , accuracy:  tensor(89.5100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  354 , learning rate:  1.7171207084072277e-05\n",
            "eopch:  354 , training loss:  0.006792688102126122\n",
            "eopch:  354 , accuracy:  tensor(89.6100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  355 , learning rate:  1.6921881260231665e-05\n",
            "eopch:  355 , training loss:  0.0067694311773777004\n",
            "eopch:  355 , accuracy:  tensor(89.5100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  356 , learning rate:  1.6676175645857367e-05\n",
            "eopch:  356 , training loss:  0.006806423129439354\n",
            "eopch:  356 , accuracy:  tensor(89.4500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  357 , learning rate:  1.6434037675529653e-05\n",
            "eopch:  357 , training loss:  0.006791087428331375\n",
            "eopch:  357 , accuracy:  tensor(89.7000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  358 , learning rate:  1.619541554707837e-05\n",
            "eopch:  358 , training loss:  0.006771557745337486\n",
            "eopch:  358 , accuracy:  tensor(89.4200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  359 , learning rate:  1.5960258210500564e-05\n",
            "eopch:  359 , training loss:  0.006778956639766693\n",
            "eopch:  359 , accuracy:  tensor(89.5500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  360 , learning rate:  1.5728515357039022e-05\n",
            "eopch:  360 , training loss:  0.006763250430822373\n",
            "eopch:  360 , accuracy:  tensor(89.7100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  361 , learning rate:  1.550013740841938e-05\n",
            "eopch:  361 , training loss:  0.006766132152080536\n",
            "eopch:  361 , accuracy:  tensor(89.4300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  362 , learning rate:  1.5275075506243526e-05\n",
            "eopch:  362 , training loss:  0.006815649851560593\n",
            "eopch:  362 , accuracy:  tensor(89.6600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  363 , learning rate:  1.5053281501536985e-05\n",
            "eopch:  363 , training loss:  0.006802450090050698\n",
            "eopch:  363 , accuracy:  tensor(89.6700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  364 , learning rate:  1.483470794444811e-05\n",
            "eopch:  364 , training loss:  0.006794129015803337\n",
            "eopch:  364 , accuracy:  tensor(89.6300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  365 , learning rate:  1.4619308074096817e-05\n",
            "eopch:  365 , training loss:  0.00678306760430336\n",
            "eopch:  365 , accuracy:  tensor(89.3200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  366 , learning rate:  1.4407035808570714e-05\n",
            "eopch:  366 , training loss:  0.006790712775588036\n",
            "eopch:  366 , accuracy:  tensor(89.5300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  367 , learning rate:  1.4197845735066504e-05\n",
            "eopch:  367 , training loss:  0.006803713758587837\n",
            "eopch:  367 , accuracy:  tensor(89.4100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  368 , learning rate:  1.3991693100174522e-05\n",
            "eopch:  368 , training loss:  0.006779204837083817\n",
            "eopch:  368 , accuracy:  tensor(89.5700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  369 , learning rate:  1.378853380030434e-05\n",
            "eopch:  369 , training loss:  0.006813066809773445\n",
            "eopch:  369 , accuracy:  tensor(89.4500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  370 , learning rate:  1.3588324372249404e-05\n",
            "eopch:  370 , training loss:  0.006792049008607864\n",
            "eopch:  370 , accuracy:  tensor(89.7300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  371 , learning rate:  1.339102198388865e-05\n",
            "eopch:  371 , training loss:  0.006784395161271095\n",
            "eopch:  371 , accuracy:  tensor(89.5400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  372 , learning rate:  1.3196584425023162e-05\n",
            "eopch:  372 , training loss:  0.006775520651340484\n",
            "eopch:  372 , accuracy:  tensor(89.5700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  373 , learning rate:  1.3004970098345856e-05\n",
            "eopch:  373 , training loss:  0.006803677017092705\n",
            "eopch:  373 , accuracy:  tensor(89.5900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  374 , learning rate:  1.2816138010542299e-05\n",
            "eopch:  374 , training loss:  0.006761697343587876\n",
            "eopch:  374 , accuracy:  tensor(89.7100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  375 , learning rate:  1.2630047763520735e-05\n",
            "eopch:  375 , training loss:  0.006765555753111839\n",
            "eopch:  375 , accuracy:  tensor(89.7500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  376 , learning rate:  1.2446659545769459e-05\n",
            "eopch:  376 , training loss:  0.00682242483317852\n",
            "eopch:  376 , accuracy:  tensor(89.4900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  377 , learning rate:  1.226593412383968e-05\n",
            "eopch:  377 , training loss:  0.006775223201513291\n",
            "eopch:  377 , accuracy:  tensor(89.6700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  378 , learning rate:  1.2087832833952044e-05\n",
            "eopch:  378 , training loss:  0.006768844847679138\n",
            "eopch:  378 , accuracy:  tensor(89.4700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  379 , learning rate:  1.1912317573725042e-05\n",
            "eopch:  379 , training loss:  0.006800424836874008\n",
            "eopch:  379 , accuracy:  tensor(89.4700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  380 , learning rate:  1.1739350794023518e-05\n",
            "eopch:  380 , training loss:  0.006753339328169823\n",
            "eopch:  380 , accuracy:  tensor(89.6800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  381 , learning rate:  1.156889549092553e-05\n",
            "eopch:  381 , training loss:  0.006800502455234528\n",
            "eopch:  381 , accuracy:  tensor(89.5500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  382 , learning rate:  1.1400915197805865e-05\n",
            "eopch:  382 , training loss:  0.006786628377437592\n",
            "eopch:  382 , accuracy:  tensor(89.5100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  383 , learning rate:  1.1235373977534484e-05\n",
            "eopch:  383 , training loss:  0.0067832736909389495\n",
            "eopch:  383 , accuracy:  tensor(89.7100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  384 , learning rate:  1.1072236414788266e-05\n",
            "eopch:  384 , training loss:  0.00678635504424572\n",
            "eopch:  384 , accuracy:  tensor(89.4600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  385 , learning rate:  1.0911467608474365e-05\n",
            "eopch:  385 , training loss:  0.0067692300397157665\n",
            "eopch:  385 , accuracy:  tensor(89.8200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  386 , learning rate:  1.0753033164263596e-05\n",
            "eopch:  386 , training loss:  0.0067750254791975025\n",
            "eopch:  386 , accuracy:  tensor(89.5500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  387 , learning rate:  1.0596899187232226e-05\n",
            "eopch:  387 , training loss:  0.006788262483477593\n",
            "eopch:  387 , accuracy:  tensor(89.5200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  388 , learning rate:  1.0443032274610611e-05\n",
            "eopch:  388 , training loss:  0.006796904292702675\n",
            "eopch:  388 , accuracy:  tensor(89.6800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  389 , learning rate:  1.0291399508637125e-05\n",
            "eopch:  389 , training loss:  0.0068199704819917675\n",
            "eopch:  389 , accuracy:  tensor(89.4000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  390 , learning rate:  1.0141968449515841e-05\n",
            "eopch:  390 , training loss:  0.006791341518759727\n",
            "eopch:  390 , accuracy:  tensor(89.3500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  391 , learning rate:  9.994707128476474e-06\n",
            "eopch:  391 , training loss:  0.006768563992381096\n",
            "eopch:  391 , accuracy:  tensor(89.5300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  392 , learning rate:  9.84958404093509e-06\n",
            "eopch:  392 , training loss:  0.006772547565698624\n",
            "eopch:  392 , accuracy:  tensor(89.4800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  393 , learning rate:  9.706568139754131e-06\n",
            "eopch:  393 , training loss:  0.006807856373190879\n",
            "eopch:  393 , accuracy:  tensor(89.3600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  394 , learning rate:  9.565628828600282e-06\n",
            "eopch:  394 , training loss:  0.006779527171850205\n",
            "eopch:  394 , accuracy:  tensor(89.4700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  395 , learning rate:  9.42673595539881e-06\n",
            "eopch:  395 , training loss:  0.006778745760917663\n",
            "eopch:  395 , accuracy:  tensor(89.4300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  396 , learning rate:  9.289859805882923e-06\n",
            "eopch:  396 , training loss:  0.006806020660996437\n",
            "eopch:  396 , accuracy:  tensor(89.4500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  397 , learning rate:  9.154971097236808e-06\n",
            "eopch:  397 , training loss:  0.006789608233571052\n",
            "eopch:  397 , accuracy:  tensor(89.5700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  398 , learning rate:  9.022040971830957e-06\n",
            "eopch:  398 , training loss:  0.006795784537792206\n",
            "eopch:  398 , accuracy:  tensor(89.5000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  399 , learning rate:  8.891040991048473e-06\n",
            "eopch:  399 , training loss:  0.006795937203764916\n",
            "eopch:  399 , accuracy:  tensor(89.5100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  400 , learning rate:  8.761943129201006e-06\n",
            "eopch:  400 , training loss:  0.006808820080757141\n",
            "eopch:  400 , accuracy:  tensor(89.4900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  401 , learning rate:  8.634719767533031e-06\n",
            "eopch:  401 , training loss:  0.006761356784105301\n",
            "eopch:  401 , accuracy:  tensor(89.6500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  402 , learning rate:  8.509343688313187e-06\n",
            "eopch:  402 , training loss:  0.006798643069863319\n",
            "eopch:  402 , accuracy:  tensor(89.3300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  403 , learning rate:  8.38578806901141e-06\n",
            "eopch:  403 , training loss:  0.006786002093553543\n",
            "eopch:  403 , accuracy:  tensor(89.4300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  404 , learning rate:  8.264026476560613e-06\n",
            "eopch:  404 , training loss:  0.0067856074088811875\n",
            "eopch:  404 , accuracy:  tensor(89.5200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  405 , learning rate:  8.144032861701682e-06\n",
            "eopch:  405 , training loss:  0.0068117944639921185\n",
            "eopch:  405 , accuracy:  tensor(89.5700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  406 , learning rate:  8.025781553410592e-06\n",
            "eopch:  406 , training loss:  0.0068077200400829315\n",
            "eopch:  406 , accuracy:  tensor(89.5800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  407 , learning rate:  7.909247253406429e-06\n",
            "eopch:  407 , training loss:  0.006773524721860886\n",
            "eopch:  407 , accuracy:  tensor(89.3500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  408 , learning rate:  7.79440503073917e-06\n",
            "eopch:  408 , training loss:  0.006796954268217087\n",
            "eopch:  408 , accuracy:  tensor(89.5100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  409 , learning rate:  7.681230316456033e-06\n",
            "eopch:  409 , training loss:  0.0067675752234458925\n",
            "eopch:  409 , accuracy:  tensor(89.5000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  410 , learning rate:  7.569698898345286e-06\n",
            "eopch:  410 , training loss:  0.00679465887606144\n",
            "eopch:  410 , accuracy:  tensor(89.3800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  411 , learning rate:  7.459786915756365e-06\n",
            "eopch:  411 , training loss:  0.006818495463728905\n",
            "eopch:  411 , accuracy:  tensor(89.3700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  412 , learning rate:  7.351470854495209e-06\n",
            "eopch:  412 , training loss:  0.006795465620756149\n",
            "eopch:  412 , accuracy:  tensor(89.5700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  413 , learning rate:  7.244727541793713e-06\n",
            "eopch:  413 , training loss:  0.006796882065534591\n",
            "eopch:  413 , accuracy:  tensor(89.4600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  414 , learning rate:  7.139534141352228e-06\n",
            "eopch:  414 , training loss:  0.0067987685108184814\n",
            "eopch:  414 , accuracy:  tensor(89.5000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  415 , learning rate:  7.035868148454036e-06\n",
            "eopch:  415 , training loss:  0.006793963004946709\n",
            "eopch:  415 , accuracy:  tensor(89.4800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  416 , learning rate:  6.933707385150773e-06\n",
            "eopch:  416 , training loss:  0.006784399545788765\n",
            "eopch:  416 , accuracy:  tensor(89.5300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  417 , learning rate:  6.833029995517751e-06\n",
            "eopch:  417 , training loss:  0.006802010770440101\n",
            "eopch:  417 , accuracy:  tensor(89.4900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  418 , learning rate:  6.733814440978178e-06\n",
            "eopch:  418 , training loss:  0.0067650958013534546\n",
            "eopch:  418 , accuracy:  tensor(89.5300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  419 , learning rate:  6.636039495695267e-06\n",
            "eopch:  419 , training loss:  0.006798004824519158\n",
            "eopch:  419 , accuracy:  tensor(89.4700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  420 , learning rate:  6.539684242031255e-06\n",
            "eopch:  420 , training loss:  0.006799016805887222\n",
            "eopch:  420 , accuracy:  tensor(89.4800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  421 , learning rate:  6.444728066072353e-06\n",
            "eopch:  421 , training loss:  0.00677563634455204\n",
            "eopch:  421 , accuracy:  tensor(89.4500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  422 , learning rate:  6.351150653218677e-06\n",
            "eopch:  422 , training loss:  0.006785735043883323\n",
            "eopch:  422 , accuracy:  tensor(89.6400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  423 , learning rate:  6.25893198383821e-06\n",
            "eopch:  423 , training loss:  0.006789257697463035\n",
            "eopch:  423 , accuracy:  tensor(89.5200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  424 , learning rate:  6.168052328983875e-06\n",
            "eopch:  424 , training loss:  0.0067819069039821624\n",
            "eopch:  424 , accuracy:  tensor(89.6900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  425 , learning rate:  6.078492246172783e-06\n",
            "eopch:  425 , training loss:  0.006795560914874077\n",
            "eopch:  425 , accuracy:  tensor(89.4500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  426 , learning rate:  5.990232575226785e-06\n",
            "eopch:  426 , training loss:  0.006791226589083672\n",
            "eopch:  426 , accuracy:  tensor(89.6200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  427 , learning rate:  5.9032544341734024e-06\n",
            "eopch:  427 , training loss:  0.006780207872390747\n",
            "eopch:  427 , accuracy:  tensor(89.5700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  428 , learning rate:  5.817539215206282e-06\n",
            "eopch:  428 , training loss:  0.00680476751089096\n",
            "eopch:  428 , accuracy:  tensor(89.5900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  429 , learning rate:  5.733068580704308e-06\n",
            "eopch:  429 , training loss:  0.006769552532434464\n",
            "eopch:  429 , accuracy:  tensor(89.5500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  430 , learning rate:  5.649824459308514e-06\n",
            "eopch:  430 , training loss:  0.0068139577728509905\n",
            "eopch:  430 , accuracy:  tensor(89.5300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  431 , learning rate:  5.567789042055957e-06\n",
            "eopch:  431 , training loss:  0.006778983027935028\n",
            "eopch:  431 , accuracy:  tensor(89.6600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  432 , learning rate:  5.486944778569728e-06\n",
            "eopch:  432 , training loss:  0.006794450151324272\n",
            "eopch:  432 , accuracy:  tensor(89.7300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  433 , learning rate:  5.407274373304288e-06\n",
            "eopch:  433 , training loss:  0.0067827534806728365\n",
            "eopch:  433 , accuracy:  tensor(89.4000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  434 , learning rate:  5.328760781845312e-06\n",
            "eopch:  434 , training loss:  0.0068107504588365555\n",
            "eopch:  434 , accuracy:  tensor(89.5700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  435 , learning rate:  5.251387207263272e-06\n",
            "eopch:  435 , training loss:  0.006785842644572258\n",
            "eopch:  435 , accuracy:  tensor(89.6200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  436 , learning rate:  5.175137096519954e-06\n",
            "eopch:  436 , training loss:  0.006794978489875794\n",
            "eopch:  436 , accuracy:  tensor(89.4400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  437 , learning rate:  5.09999413692716e-06\n",
            "eopch:  437 , training loss:  0.006775450565218925\n",
            "eopch:  437 , accuracy:  tensor(89.6200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  438 , learning rate:  5.025942252656827e-06\n",
            "eopch:  438 , training loss:  0.006764263076782227\n",
            "eopch:  438 , accuracy:  tensor(89.4400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  439 , learning rate:  4.952965601301817e-06\n",
            "eopch:  439 , training loss:  0.006759083378911018\n",
            "eopch:  439 , accuracy:  tensor(89.5900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  440 , learning rate:  4.881048570486654e-06\n",
            "eopch:  440 , training loss:  0.006796885004639625\n",
            "eopch:  440 , accuracy:  tensor(89.5800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  441 , learning rate:  4.810175774527454e-06\n",
            "eopch:  441 , training loss:  0.006766006294488907\n",
            "eopch:  441 , accuracy:  tensor(89.3600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  442 , learning rate:  4.740332051140374e-06\n",
            "eopch:  442 , training loss:  0.006775289145708084\n",
            "eopch:  442 , accuracy:  tensor(89.4800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  443 , learning rate:  4.671502458197841e-06\n",
            "eopch:  443 , training loss:  0.006769111236929894\n",
            "eopch:  443 , accuracy:  tensor(89.4800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  444 , learning rate:  4.603672270531885e-06\n",
            "eopch:  444 , training loss:  0.006791319041252136\n",
            "eopch:  444 , accuracy:  tensor(89.2800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  445 , learning rate:  4.536826976783886e-06\n",
            "eopch:  445 , training loss:  0.0068048418247699735\n",
            "eopch:  445 , accuracy:  tensor(89.5500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  446 , learning rate:  4.470952276300063e-06\n",
            "eopch:  446 , training loss:  0.006773325187563896\n",
            "eopch:  446 , accuracy:  tensor(89.4900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  447 , learning rate:  4.406034076072045e-06\n",
            "eopch:  447 , training loss:  0.006801472806334496\n",
            "eopch:  447 , accuracy:  tensor(89.5900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  448 , learning rate:  4.342058487721854e-06\n",
            "eopch:  448 , training loss:  0.006765849969983101\n",
            "eopch:  448 , accuracy:  tensor(89.4800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  449 , learning rate:  4.279011824530682e-06\n",
            "eopch:  449 , training loss:  0.006785642100572586\n",
            "eopch:  449 , accuracy:  tensor(89.4200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  450 , learning rate:  4.216880598510792e-06\n",
            "eopch:  450 , training loss:  0.006822218586206436\n",
            "eopch:  450 , accuracy:  tensor(89.8000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  451 , learning rate:  4.155651517519949e-06\n",
            "eopch:  451 , training loss:  0.006761088941693306\n",
            "eopch:  451 , accuracy:  tensor(89.5400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  452 , learning rate:  4.0953114824177434e-06\n",
            "eopch:  452 , training loss:  0.006788048565387726\n",
            "eopch:  452 , accuracy:  tensor(89.7500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  453 , learning rate:  4.035847584263207e-06\n",
            "eopch:  453 , training loss:  0.006803529990911484\n",
            "eopch:  453 , accuracy:  tensor(89.4500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  454 , learning rate:  3.977247101553116e-06\n",
            "eopch:  454 , training loss:  0.006797352399826049\n",
            "eopch:  454 , accuracy:  tensor(89.4100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  455 , learning rate:  3.9194974975003975e-06\n",
            "eopch:  455 , training loss:  0.006775130170583725\n",
            "eopch:  455 , accuracy:  tensor(89.3700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  456 , learning rate:  3.86258641735205e-06\n",
            "eopch:  456 , training loss:  0.0067990013056993485\n",
            "eopch:  456 , accuracy:  tensor(89.5600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  457 , learning rate:  3.806501685746014e-06\n",
            "eopch:  457 , training loss:  0.006791524848341942\n",
            "eopch:  457 , accuracy:  tensor(89.6800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  458 , learning rate:  3.7512313041064126e-06\n",
            "eopch:  458 , training loss:  0.006816920663714409\n",
            "eopch:  458 , accuracy:  tensor(89.6500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  459 , learning rate:  3.6967634480766187e-06\n",
            "eopch:  459 , training loss:  0.006767607135176658\n",
            "eopch:  459 , accuracy:  tensor(89.5900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  460 , learning rate:  3.643086464989593e-06\n",
            "eopch:  460 , training loss:  0.006819206340312958\n",
            "eopch:  460 , accuracy:  tensor(89.6000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  461 , learning rate:  3.5901888713749513e-06\n",
            "eopch:  461 , training loss:  0.006793110243678093\n",
            "eopch:  461 , accuracy:  tensor(89.7000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  462 , learning rate:  3.5380593505022306e-06\n",
            "eopch:  462 , training loss:  0.006805268322825432\n",
            "eopch:  462 , accuracy:  tensor(89.6200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  463 , learning rate:  3.486686749959826e-06\n",
            "eopch:  463 , training loss:  0.006800157853960991\n",
            "eopch:  463 , accuracy:  tensor(89.6200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  464 , learning rate:  3.436060079269083e-06\n",
            "eopch:  464 , training loss:  0.0067921411210298535\n",
            "eopch:  464 , accuracy:  tensor(89.5600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  465 , learning rate:  3.3861685075330307e-06\n",
            "eopch:  465 , training loss:  0.006776052825450897\n",
            "eopch:  465 , accuracy:  tensor(89.4600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  466 , learning rate:  3.3370013611192573e-06\n",
            "eopch:  466 , training loss:  0.0068059220468997955\n",
            "eopch:  466 , accuracy:  tensor(89.6600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  467 , learning rate:  3.2885481213764294e-06\n",
            "eopch:  467 , training loss:  0.006794324021935463\n",
            "eopch:  467 , accuracy:  tensor(89.5700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  468 , learning rate:  3.240798422383968e-06\n",
            "eopch:  468 , training loss:  0.006764867374897003\n",
            "eopch:  468 , accuracy:  tensor(89.5600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  469 , learning rate:  3.193742048734399e-06\n",
            "eopch:  469 , training loss:  0.006778673837780952\n",
            "eopch:  469 , accuracy:  tensor(89.6600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  470 , learning rate:  3.1473689333479027e-06\n",
            "eopch:  470 , training loss:  0.006789785105586052\n",
            "eopch:  470 , accuracy:  tensor(89.5200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  471 , learning rate:  3.1016691553185986e-06\n",
            "eopch:  471 , training loss:  0.006760336066484451\n",
            "eopch:  471 , accuracy:  tensor(89.5000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  472 , learning rate:  3.0566329377921004e-06\n",
            "eopch:  472 , training loss:  0.006764139544963837\n",
            "eopch:  472 , accuracy:  tensor(89.5900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  473 , learning rate:  3.0122506458738885e-06\n",
            "eopch:  473 , training loss:  0.0067935443061590195\n",
            "eopch:  473 , accuracy:  tensor(89.5700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  474 , learning rate:  2.9685127845680536e-06\n",
            "eopch:  474 , training loss:  0.006787270877361298\n",
            "eopch:  474 , accuracy:  tensor(89.5600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  475 , learning rate:  2.9254099967459703e-06\n",
            "eopch:  475 , training loss:  0.0067781205296516414\n",
            "eopch:  475 , accuracy:  tensor(89.5700, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  476 , learning rate:  2.8829330611444648e-06\n",
            "eopch:  476 , training loss:  0.006803089479804039\n",
            "eopch:  476 , accuracy:  tensor(89.6000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  477 , learning rate:  2.8410728903930495e-06\n",
            "eopch:  477 , training loss:  0.0068048304152488704\n",
            "eopch:  477 , accuracy:  tensor(89.5200, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  478 , learning rate:  2.7998205290698007e-06\n",
            "eopch:  478 , training loss:  0.006766055896878243\n",
            "eopch:  478 , accuracy:  tensor(89.6900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  479 , learning rate:  2.7591671517854686e-06\n",
            "eopch:  479 , training loss:  0.006790819061994553\n",
            "eopch:  479 , accuracy:  tensor(89.5800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  480 , learning rate:  2.7191040612954016e-06\n",
            "eopch:  480 , training loss:  0.006780929886102676\n",
            "eopch:  480 , accuracy:  tensor(89.4600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  481 , learning rate:  2.6796226866388886e-06\n",
            "eopch:  481 , training loss:  0.006819325761198997\n",
            "eopch:  481 , accuracy:  tensor(89.7400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  482 , learning rate:  2.640714581305516e-06\n",
            "eopch:  482 , training loss:  0.006827348292469978\n",
            "eopch:  482 , accuracy:  tensor(89.5400, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  483 , learning rate:  2.6023714214281517e-06\n",
            "eopch:  483 , training loss:  0.006781282930970192\n",
            "eopch:  483 , accuracy:  tensor(89.4300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  484 , learning rate:  2.5645850040021635e-06\n",
            "eopch:  484 , training loss:  0.006788569130897522\n",
            "eopch:  484 , accuracy:  tensor(89.5500, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  485 , learning rate:  2.5273472451304982e-06\n",
            "eopch:  485 , training loss:  0.006770667844414711\n",
            "eopch:  485 , accuracy:  tensor(89.6000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  486 , learning rate:  2.490650178294238e-06\n",
            "eopch:  486 , training loss:  0.0068098081415891645\n",
            "eopch:  486 , accuracy:  tensor(89.2600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  487 , learning rate:  2.4544859526482735e-06\n",
            "eopch:  487 , training loss:  0.006795906718969345\n",
            "eopch:  487 , accuracy:  tensor(89.6100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  488 , learning rate:  2.418846831341718e-06\n",
            "eopch:  488 , training loss:  0.00677814129114151\n",
            "eopch:  488 , accuracy:  tensor(89.6300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  489 , learning rate:  2.3837251898627136e-06\n",
            "eopch:  489 , training loss:  0.006778504610657692\n",
            "eopch:  489 , accuracy:  tensor(89.6600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  490 , learning rate:  2.349113514407269e-06\n",
            "eopch:  490 , training loss:  0.006795303921103477\n",
            "eopch:  490 , accuracy:  tensor(89.6000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  491 , learning rate:  2.3150044002717817e-06\n",
            "eopch:  491 , training loss:  0.006773837207555771\n",
            "eopch:  491 , accuracy:  tensor(89.4800, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  492 , learning rate:  2.2813905502689013e-06\n",
            "eopch:  492 , training loss:  0.006829377902746201\n",
            "eopch:  492 , accuracy:  tensor(89.6600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  493 , learning rate:  2.2482647731663934e-06\n",
            "eopch:  493 , training loss:  0.006768738126754761\n",
            "eopch:  493 , accuracy:  tensor(89.5600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  494 , learning rate:  2.215619982148673e-06\n",
            "eopch:  494 , training loss:  0.006777632910013199\n",
            "eopch:  494 , accuracy:  tensor(89.4300, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  495 , learning rate:  2.183449193300675e-06\n",
            "eopch:  495 , training loss:  0.006763564469814301\n",
            "eopch:  495 , accuracy:  tensor(89.3900, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  496 , learning rate:  2.1517455241137384e-06\n",
            "eopch:  496 , training loss:  0.006792272377014161\n",
            "eopch:  496 , accuracy:  tensor(89.6600, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  497 , learning rate:  2.1205021920131872e-06\n",
            "eopch:  497 , training loss:  0.006805174633264541\n",
            "eopch:  497 , accuracy:  tensor(89.5000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  498 , learning rate:  2.089712512907289e-06\n",
            "eopch:  498 , training loss:  0.0068040628987550734\n",
            "eopch:  498 , accuracy:  tensor(89.5100, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  499 , learning rate:  2.059369899757283e-06\n",
            "eopch:  499 , training loss:  0.0068071765458583835\n",
            "eopch:  499 , accuracy:  tensor(89.5000, device='cuda:0', dtype=torch.float64)\n",
            "eopch:  500 , learning rate:  2.029467861168172e-06\n",
            "eopch:  500 , training loss:  0.006795721554160118\n",
            "eopch:  500 , accuracy:  tensor(89.5200, device='cuda:0', dtype=torch.float64)\n",
            "Finished Training. Saved network\n"
          ]
        }
      ],
      "source": [
        "if Path(net_fn).is_file():\n",
        "  net.load_state_dict(torch.load(net_fn)) # load file if previously executed\n",
        "  print(\"Skipped Training. Loaded network\")\n",
        "else:\n",
        "  train_loss_of_every_epoch = []\n",
        "  validation_accuracy_of_every_epoch = []\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    running_num = 0\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=LR)\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "      inputs, labels = data\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      outputs = net(inputs) # forward\n",
        "\n",
        "      loss = criterion(outputs, labels) # calculate loss.\n",
        "      loss.backward() # Use binarized weights to compute derivatives to speed up.\n",
        "\n",
        "      for p in list(net.parameters()):\n",
        "        if hasattr(p,'org'):\n",
        "          p.data.copy_(p.org)\n",
        "\n",
        "      optimizer.step() # Use derivatives to update original weights rather than binarized weights.\n",
        "\n",
        "      for p in list(net.parameters()):\n",
        "        if hasattr(p,'org'):\n",
        "          p.org.copy_(p.data.clamp_(-1, 1))\n",
        "\n",
        "      # for p in list(net.parameters()):\n",
        "      #   p.data = p.data.clamp_(-1, 1)\n",
        "\n",
        "      running_loss += loss.item()\n",
        "      running_num += batch_size\n",
        "\n",
        "    \n",
        "    # print(\"eopch: \", epoch+1, \", the magnitude of gradients: \", calculate_the_magnitude_of_gradients(model=net))\n",
        "      \n",
        "    print(\"eopch: \", epoch+1, \", learning rate: \", LR)\n",
        "    LR = LR * LR_decay\n",
        "    \n",
        "    print(\"eopch: \", epoch+1, \", training loss: \", running_loss / running_num)\n",
        "    train_loss_of_every_epoch.append(running_loss / running_num)\n",
        "\n",
        "    top1_acc = validate_model(net, testloader)\n",
        "    print(\"eopch: \", epoch+1, \", accuracy: \", top1_acc)\n",
        "    validation_accuracy_of_every_epoch.append(top1_acc.detach().cpu().numpy())\n",
        "    \n",
        "  torch.save(net.state_dict(), net_fn)\n",
        "  with open(os.path.join(folder, 'train_loss_and_validation_accuracy.csv'), 'w', encoding='UTF8') as f:\n",
        "    writer = csv.writer(f)\n",
        "\n",
        "    writer.writerow(train_loss_of_every_epoch)\n",
        "    writer.writerow(validation_accuracy_of_every_epoch)\n",
        "\n",
        "  print('Finished Training. Saved network')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "AHlw4nIYWId8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkkAAAHFCAYAAADmGm0KAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABHRUlEQVR4nO3deXxV1b3///eZT+aRTAwhgAzKUAmKoJQqiAXR2upVuW3F9tr+aGutoK2KtaL2Wyy1rUWmq8Wptg63UK8tVMUKqBdEgYAIkUGmAAkhIfN8zlm/P0KOpjkgxiR7B17Px+M8JPusvfc6O8G8+ay113YYY4wAAADQitPqDgAAANgRIQkAACACQhIAAEAEhCQAAIAICEkAAAAREJIAAAAiICQBAABEQEgCAACIgJAEAAAQASEJOAusW7dOc+bMUXl5eacc/+abb1bfvn077Hj79++Xw+HQ008/3WHHxBd38803KzY21upuAF2GkAScBdatW6cHHnig00LSfffdp7/97W+dcmwAsIrb6g4AsJ+6ujpFRUWddvv+/ft3Ym8AwBpUkoAz3Jw5c/TTn/5UkpSTkyOHwyGHw6E1a9ZIkvr27aupU6dq+fLlOv/88+X3+/XAAw9IkhYuXKgvf/nLSktLU0xMjIYNG6Z58+apqamp1TkiDbc5HA7deuut+tOf/qQhQ4YoOjpaI0aM0D/+8Y92f5Z33nlHEyZMUFxcnKKjozV27FitWLGiVZva2lrdeeedysnJkd/vV3JyskaNGqXnn38+3Gbv3r268cYblZWVJZ/Pp/T0dE2YMEFbtmw56bkfffRRORwO7dmzp817d911l7xer0pKSiRJeXl5mjp1qtLS0uTz+ZSVlaUrr7xShw4d+szP+MYbb2jChAmKj49XdHS0Lr74Yv3rX/9q1WbOnDlyOBzKy8vTN77xDcXHxyshIUHf+ta3dOzYsVZtQ6GQ5s2bp8GDB8vn8yktLU033XRTxL68+uqrmjBhghISEhQdHa0hQ4Zo7ty5bdrt2bNHU6ZMUWxsrHr37q077rhDDQ0Nn/nZgO6GShJwhrvlllt0/PhxPfbYY1q+fLkyMzMlSeeee264zebNm5Wfn6+f//znysnJUUxMjCTp448/1n/+538qJydHXq9XW7du1f/7f/9PH330kZ588snPPPeKFSv0/vvv68EHH1RsbKzmzZunr3/969q5c6f69ev3uT7H2rVrdfnll2v48OFaunSpfD6fFi1apKuuukrPP/+8brjhBknSrFmz9Kc//Um//OUvdf7556umpkYffvihSktLw8eaMmWKgsGg5s2bpz59+qikpETr1q075XDkt771Ld111116+umn9ctf/jK8PRgM6rnnntNVV12l1NRU1dTU6PLLL1dOTo4WLlyo9PR0FRUVafXq1aqqqjrlZ3zuued000036Wtf+5qeeeYZeTwe/fd//7euuOIKvfbaa5owYUKr9l//+td1/fXXa8aMGdq+fbvuu+8+7dixQxs2bJDH45Ek/eAHP9Djjz+uW2+9VVOnTtX+/ft13333ac2aNdq8ebNSU1MlSUuXLtX3vvc9jR8/XkuWLFFaWpp27dqlDz/8sNU5m5qadPXVV+u//uu/dMcdd+itt97SQw89pISEBP3iF7/47G8k0J0YAGe83/zmN0aS2bdvX5v3srOzjcvlMjt37jzlMYLBoGlqajLPPvuscblc5vjx4+H3pk+fbrKzs1u1l2TS09NNZWVleFtRUZFxOp1m7ty5pzzXvn37jCTz1FNPhbdddNFFJi0tzVRVVYW3BQIBM3ToUNOrVy8TCoWMMcYMHTrUXHPNNSc9dklJiZFkHn300VP2IZJvfOMbplevXiYYDIa3rVy50kgyf//7340xxmzcuNFIMi+//PLnOnZNTY1JTk42V111VavtwWDQjBgxwlx44YXhbffff7+RZGbOnNmq7Z///GcjyTz33HPGGGPy8/ONJPPDH/6wVbsNGzYYSWb27NnGGGOqqqpMfHy8ueSSS8LXMZLp06cbSeall15qtX3KlClm0KBBn+vzAt0Bw20ANHz4cA0cOLDN9ry8PF199dVKSUmRy+WSx+PRTTfdpGAwqF27dn3mcS+99FLFxcWFv05PT1daWpoOHDjwufpXU1OjDRs26Lrrrmt1d5XL5dK3v/1tHTp0SDt37pQkXXjhhfrnP/+pu+++W2vWrFFdXV2rYyUnJ6t///76zW9+o9/97nfKy8tTKBQ6rX585zvf0aFDh/TGG2+Etz311FPKyMjQ5MmTJUkDBgxQUlKS7rrrLi1ZskQ7duw4rWOvW7dOx48f1/Tp0xUIBMKvUCikr371q3r//fdVU1PTap9vfvObrb6+/vrr5Xa7tXr1akkK//fmm29u1e7CCy/UkCFDwsN469atU2VlpX74wx/K4XCcsp8Oh0NXXXVVq23Dhw//3N9ToDsgJAEID8F92sGDBzVu3DgdPnxYf/jDH/T222/r/fff18KFCyWpTfiIJCUlpc02n893Wvt+WllZmYwxEfuZlZUlSeHhtPnz5+uuu+7Syy+/rEsvvVTJycm65pprtHv3bknNv+T/9a9/6YorrtC8efM0cuRI9ejRQ7fddttnDodNnjxZmZmZeuqpp8L9euWVV3TTTTfJ5XJJkhISErR27Vp96Utf0uzZs3XeeecpKytL999/f5u5XJ929OhRSdJ1110nj8fT6vXrX/9axhgdP3681T4ZGRmtvna73UpJSQlfi5b/nuy6tbzfMo+pV69ep/z8khQdHS2/399qm8/nU319/WfuC3Q3zEkCELF68PLLL6umpkbLly9XdnZ2ePupJjd3lqSkJDmdThUWFrZ578iRI5IUnlsTExOjBx54QA888ICOHj0aripdddVV+uijjyRJ2dnZWrp0qSRp165deumllzRnzhw1NjZqyZIlJ+1HS+Vq/vz5Ki8v11/+8hc1NDToO9/5Tqt2w4YN0wsvvCBjjD744AM9/fTTevDBBxUVFaW777474rFb+v/YY4/poosuitgmPT291ddFRUXq2bNn+OtAIKDS0tJwOG35b2FhYZsAdOTIkfA5e/ToIUmnNbEcOJtQSQLOAj6fT9LpVX9atASnln0lyRijJ554omM7dxpiYmI0evRoLV++vNVnCIVCeu6559SrV6+Iw4Xp6em6+eabNW3aNO3cuVO1tbVt2gwcOFA///nPNWzYMG3evPkz+/Kd73xH9fX1ev755/X0009rzJgxGjx4cMS2DodDI0aM0O9//3slJiae8vgXX3yxEhMTtWPHDo0aNSriy+v1ttrnz3/+c6uvX3rpJQUCAX3lK1+RJF122WWSmieEf9r777+v/Pz88ETwsWPHKiEhQUuWLJEx5jOvAXC2oJIEnAWGDRsmSfrDH/6g6dOny+PxaNCgQa3mC/27yy+/XF6vV9OmTdPPfvYz1dfXa/HixSorK+uqbrcyd+5cXX755br00kt15513yuv1atGiRfrwww/1/PPPh0Pd6NGjNXXqVA0fPlxJSUnKz8/Xn/70J40ZM0bR0dH64IMPdOutt+o//uM/dM4558jr9erNN9/UBx98cNIqz6cNHjxYY8aM0dy5c1VQUKDHH3+81fv/+Mc/tGjRIl1zzTXq16+fjDFavny5ysvLdfnll5/0uLGxsXrsscc0ffp0HT9+XNddd53S0tJ07Ngxbd26VceOHdPixYtb7bN8+XK53W5dfvnl4bvbRowYoeuvv16SNGjQIH3/+9/XY489JqfTqcmTJ4fvbuvdu7dmzpwZPvdvf/tb3XLLLZo4caK+973vKT09XXv27NHWrVu1YMGCz/W9As4YVs4aB9B17rnnHpOVlWWcTqeRZFavXm2Mab677corr4y4z9///nczYsQI4/f7Tc+ePc1Pf/pT889//rPV/sac/O62H/3oR22OmZ2dbaZPn37Kvka6u80YY95++21z2WWXmZiYGBMVFWUuuuii8F1lLe6++24zatQok5SUZHw+n+nXr5+ZOXOmKSkpMcYYc/ToUXPzzTebwYMHm5iYGBMbG2uGDx9ufv/735tAIHDKfrV4/PHHjSQTFRVlKioqWr330UcfmWnTppn+/fubqKgok5CQYC688ELz9NNPn9ax165da6688kqTnJxsPB6P6dmzp7nyyivN//zP/4TbtNzdtmnTJnPVVVeZ2NhYExcXZ6ZNm2aOHj3a6njBYND8+te/NgMHDjQej8ekpqaab33rW6agoKDNuVeuXGnGjx9vYmJiTHR0tDn33HPNr3/96/D706dPNzExMW32a+kPcKZxGENtFQC6kzlz5uiBBx7QsWPHwvOKAHQ85iQBAABEQEgCAACIgOE2AACACKgkAQAAREBIAgAAiICQBAAAEAGLSbZTKBTSkSNHFBcX95kPhAQAAPZgjFFVVZWysrLkdJ66VkRIaqcjR46od+/eVncDAAC0Q0FBwWc+1JmQ1E4tj3MoKChQfHy8xb0BAACno7KyUr179z7lY5laEJLaqWWILT4+npAEAEA3czpTZZi4DQAAEAEhCQAAIAJCEgAAQASEJAAAgAgISQAAABEQkgAAACIgJAEAAERASAIAAIiAkAQAABABIQkAACACQhIAAEAEhCQAAIAIeMCtzdQ2BnS8plFet1NpcX6ruwMAwFmLSpLNrNpxVJf8erVmvrjF6q4AAHBWIyTZjNPhkCSFQhZ3BACAsxwhyWbCIckYi3sCAMDZjZBkM87mjCQyEgAA1iIk2YyDShIAALZASLKZlkoSIQkAAGsRkmzmkzlJFncEAICzHCHJZpwnviOGShIAAJYiJNmMg0oSAAC2QEiymZbhtiApCQAASxGSbIaJ2wAA2AMhyWZaKklkJAAArEVIshlW3AYAwB4ISTbDcBsAAPZASLIZp5PhNgAA7ICQZDNUkgAAsAdCks2wThIAAPZASLIZJm4DAGAPhCSbaRluIyMBAGAtQpLNUEkCAMAeCEk242DiNgAAtkBIshknE7cBALAFQpLNhEMSKQkAAEsRkmyGdZIAALAHQpLNsE4SAAD2QEiyGSpJAADYAyHJZlw8uw0AAFsgJNkM6yQBAGAPhCSbYZ0kAADsgZBkM6yTBACAPRCSbKYlJBkqSQAAWIqQZDOf3N1mbT8AADjbEZJsxsHEbQAAbIGQZDMtlSRjGHIDAMBKhCSbaZmTJDHkBgCAlQhJNtM6JJGSAACwiuUhadGiRcrJyZHf71dubq7efvvtU7Zfu3atcnNz5ff71a9fPy1ZsqTV+0888YTGjRunpKQkJSUlaeLEiXrvvfdatZkzZ44cDkerV0ZGRod/tvZwfOo7QkgCAMA6loakF198Ubfffrvuvfde5eXlady4cZo8ebIOHjwYsf2+ffs0ZcoUjRs3Tnl5eZo9e7Zuu+02LVu2LNxmzZo1mjZtmlavXq3169erT58+mjRpkg4fPtzqWOedd54KCwvDr23btnXqZz1dn64kkZEAALCOw1g4O3j06NEaOXKkFi9eHN42ZMgQXXPNNZo7d26b9nfddZdeeeUV5efnh7fNmDFDW7du1fr16yOeIxgMKikpSQsWLNBNN90kqbmS9PLLL2vLli3t7ntlZaUSEhJUUVGh+Pj4dh/n39U2BnTuL16TJO148ApFe90ddmwAAM52n+f3t2WVpMbGRm3atEmTJk1qtX3SpElat25dxH3Wr1/fpv0VV1yhjRs3qqmpKeI+tbW1ampqUnJycqvtu3fvVlZWlnJycnTjjTdq7969p+xvQ0ODKisrW706AxO3AQCwB8tCUklJiYLBoNLT01ttT09PV1FRUcR9ioqKIrYPBAIqKSmJuM/dd9+tnj17auLEieFto0eP1rPPPqvXXntNTzzxhIqKijR27FiVlpaetL9z585VQkJC+NW7d+/T/aify6cyEnOSAACwkOUTtx2fTgVqXhvo37d9VvtI2yVp3rx5ev7557V8+XL5/f7w9smTJ+vaa6/VsGHDNHHiRK1YsUKS9Mwzz5z0vPfcc48qKirCr4KCgs/+cO3g+vScpFCnnAIAAJwGyya8pKamyuVytakaFRcXt6kWtcjIyIjY3u12KyUlpdX2Rx55RL/61a/0xhtvaPjw4afsS0xMjIYNG6bdu3eftI3P55PP5zvlcToCSwAAAGAPllWSvF6vcnNztWrVqlbbV61apbFjx0bcZ8yYMW3av/766xo1apQ8Hk94229+8xs99NBDevXVVzVq1KjP7EtDQ4Py8/OVmZnZjk/SsRhuAwDAHiwdbps1a5b++Mc/6sknn1R+fr5mzpypgwcPasaMGZKah7ha7kiTmu9kO3DggGbNmqX8/Hw9+eSTWrp0qe68885wm3nz5unnP/+5nnzySfXt21dFRUUqKipSdXV1uM2dd96ptWvXat++fdqwYYOuu+46VVZWavr06V334U+ied2m5j8zcRsAAOtYen/5DTfcoNLSUj344IMqLCzU0KFDtXLlSmVnZ0uSCgsLW62ZlJOTo5UrV2rmzJlauHChsrKyNH/+fF177bXhNosWLVJjY6Ouu+66Vue6//77NWfOHEnSoUOHNG3aNJWUlKhHjx666KKL9O6774bPazWnw6GgMTy7DQAAC1m6TlJ31lnrJEnSOfeuVFPQ6N17Jigjwf/ZOwAAgNPSLdZJwsm13KkXJL8CAGAZQpINOVvmJDEpCQAAyxCSbKhlGQAKSQAAWIeQZEMtIYklAAAAsA4hyYY+WQKAkAQAgFUISTb0SSXJ4o4AAHAWIyTZUMvEbVZnAADAOoQkG6KSBACA9QhJNuR0MnEbAACrEZJsyMnEbQAALEdIsiHWSQIAwHqEJBtinSQAAKxHSLKhT9ZJsrYfAACczQhJNtRSSQqSkgAAsAwhyYZYJwkAAOsRkmyIdZIAALAeIcmGeHYbAADWIyTZEHe3AQBgPUKSDbFOEgAA1iMk2RDDbQAAWI+QZENM3AYAwHqEJBtynviuUEkCAMA6hCQb+mROEiEJAACrEJJsKDzcFrK4IwAAnMUISTbkZOI2AACWIyTZEBO3AQCwHiHJhlhMEgAA6xGSbIh1kgAAsB4hyYYYbgMAwHqEJBtqWSeJJQAAALAOIcmGmJMEAID1CEk25GCdJAAALEdIsiHWSQIAwHqEJBv65LEkFncEAICzGCHJhqgkAQBgPUKSDTlYAgAAAMsRkmyIShIAANYjJNmQy9kyJ4mQBACAVQhJNsRwGwAA1iMk2VDL3W1BUhIAAJYhJNkQc5IAALAeIcmGWCcJAADrEZJsyEElCQAAyxGSbMjJxG0AACxHSLIh5iQBAGA9QpINfTIniZAEAIBVCEk2xDpJAABYj5BkQwy3AQBgPUKSDTFxGwAA6xGSbKilksScJAAArENIsqFP5iQRkgAAsAohyYZczpZnt1ncEQAAzmKEJBtiuA0AAOsRkmzIyXAbAACWIyTZEOskAQBgPUKSDbFOEgAA1iMk2dAnjyWxuCMAAJzFCEk2RCUJAADrEZJsiHWSAACwHiHJhngsCQAA1iMk2RDrJAEAYD1Ckg05T6SkECtuAwBgGUKSDTmYuA0AgOUISTbEnCQAAKxHSLIhlgAAAMB6hCQbaqkkBSklAQBgGUKSDblPlJKCVJIAALAMIcmGXK7mb0swSEgCAMAqhCQbaqkkBRhuAwDAMoQkG3K1DLexUBIAAJaxPCQtWrRIOTk58vv9ys3N1dtvv33K9mvXrlVubq78fr/69eunJUuWtHr/iSee0Lhx45SUlKSkpCRNnDhR77333hc+b1eikgQAgPUsDUkvvviibr/9dt17773Ky8vTuHHjNHnyZB08eDBi+3379mnKlCkaN26c8vLyNHv2bN12221atmxZuM2aNWs0bdo0rV69WuvXr1efPn00adIkHT58uN3n7WqfVJIISQAAWMVhLHxA2OjRozVy5EgtXrw4vG3IkCG65pprNHfu3Dbt77rrLr3yyivKz88Pb5sxY4a2bt2q9evXRzxHMBhUUlKSFixYoJtuuqld542ksrJSCQkJqqioUHx8/Gntc7pWfFCoH/1lsy7MSdZL/9+YDj02AABns8/z+9uySlJjY6M2bdqkSZMmtdo+adIkrVu3LuI+69evb9P+iiuu0MaNG9XU1BRxn9raWjU1NSk5Obnd55WkhoYGVVZWtnp1FipJAABYz7KQVFJSomAwqPT09Fbb09PTVVRUFHGfoqKiiO0DgYBKSkoi7nP33XerZ8+emjhxYrvPK0lz585VQkJC+NW7d+/P/IztxZwkAACsZ/nEbUfL01xPMMa02fZZ7SNtl6R58+bp+eef1/Lly+X3+7/Qee+55x5VVFSEXwUFBSdt+0W5XNzdBgCA1dxWnTg1NVUul6tN9aa4uLhNladFRkZGxPZut1spKSmttj/yyCP61a9+pTfeeEPDhw//QueVJJ/PJ5/Pd1qf7YsKr7hNRgIAwDKWVZK8Xq9yc3O1atWqVttXrVqlsWPHRtxnzJgxbdq//vrrGjVqlDweT3jbb37zGz300EN69dVXNWrUqC983q7GOkkAAFjPskqSJM2aNUvf/va3NWrUKI0ZM0aPP/64Dh48qBkzZkhqHuI6fPiwnn32WUnNd7ItWLBAs2bN0ve+9z2tX79eS5cu1fPPPx8+5rx583TffffpL3/5i/r27RuuGMXGxio2Nva0zms1t7M5uzInCQAA61gakm644QaVlpbqwQcfVGFhoYYOHaqVK1cqOztbklRYWNhq7aKcnBytXLlSM2fO1MKFC5WVlaX58+fr2muvDbdZtGiRGhsbdd1117U61/333685c+ac1nmtxt1tAABYz9J1krqzzlwnaWtBub628P/UMzFK/3f3ZR16bAAAzmbdYp0knByVJAAArEdIsiG3i3WSAACwGiHJhtzc3QYAgOUISTbk4u42AAAsR0iyITdzkgAAsBwhyYZcPLsNAADLEZJsiEoSAADWIyTZ0KeXAGAZKwAArEFIsqGWx5JIVJMAALAKIcmGXCfWSZKYlwQAgFUISTbUMidJopIEAIBVCEk25HJSSQIAwGqEJBtyOagkAQBgNUKSDTmdDrUUkwI8mgQAAEsQkmyq5Q43KkkAAFiDkGRT4VW3g4QkAACsQEiyKVbdBgDAWoQkm2pZK4m72wAAsAYhyaaoJAEAYC1Ckk2F5yRxdxsAAJYgJNkUd7cBAGAtQpJNfVJJIiQBAGAFQpJNMScJAABrEZJsinWSAACwFiHJplxUkgAAsBQhyabcLu5uAwDASoQkm3JxdxsAAJYiJNmUm7vbAACwFCHJppiTBACAtQhJNkUlCQAAaxGSbOqTShITtwEAsEK7QtIzzzyjFStWhL/+2c9+psTERI0dO1YHDhzosM6dzdyskwQAgKXaFZJ+9atfKSoqSpK0fv16LViwQPPmzVNqaqpmzpzZoR08W3F3GwAA1nK3Z6eCggINGDBAkvTyyy/ruuuu0/e//31dfPHF+spXvtKR/TtrMScJAABrtauSFBsbq9LSUknS66+/rokTJ0qS/H6/6urqOq53ZzGXi7vbAACwUrsqSZdffrluueUWnX/++dq1a5euvPJKSdL27dvVt2/fjuzfWYtKEgAA1mpXJWnhwoUaM2aMjh07pmXLliklJUWStGnTJk2bNq1DO3i24u42AACs1a5KUmJiohYsWNBm+wMPPPCFO4RmVJIAALBWuypJr776qt55553w1wsXLtSXvvQl/ed//qfKyso6rHNns/DdbSwBAACAJdoVkn7605+qsrJSkrRt2zbdcccdmjJlivbu3atZs2Z1aAfPVlSSAACwVruG2/bt26dzzz1XkrRs2TJNnTpVv/rVr7R582ZNmTKlQzt4tuLZbQAAWKtdlSSv16va2lpJ0htvvKFJkyZJkpKTk8MVJnwxVJIAALBWuypJl1xyiWbNmqWLL75Y7733nl588UVJ0q5du9SrV68O7eDZqmWdpECQu9sAALBCuypJCxYskNvt1l//+lctXrxYPXv2lCT985//1Fe/+tUO7eDZyudq/tY0EpIAALBEuypJffr00T/+8Y8223//+99/4Q6hmdd9IiQFCEkAAFihXSFJkoLBoF5++WXl5+fL4XBoyJAh+trXviaXy9WR/Ttr+dzN17GBkAQAgCXaFZL27NmjKVOm6PDhwxo0aJCMMdq1a5d69+6tFStWqH///h3dz7MOlSQAAKzVrjlJt912m/r376+CggJt3rxZeXl5OnjwoHJycnTbbbd1dB/PSi0hiUoSAADWaFclae3atXr33XeVnJwc3paSkqKHH35YF198cYd17mzmC4ekoMU9AQDg7NSuSpLP51NVVVWb7dXV1fJ6vV+4U2C4DQAAq7UrJE2dOlXf//73tWHDBhljZIzRu+++qxkzZujqq6/u6D6elbwsAQAAgKXaFZLmz5+v/v37a8yYMfL7/fL7/Ro7dqwGDBigRx99tIO7eHbyeU7c3dZESAIAwArtmpOUmJio//3f/9WePXuUn58vY4zOPfdcDRgwoKP7d9aikgQAgLVOOyTNmjXrlO+vWbMm/Off/e537e4QmjEnCQAAa512SMrLyzutdg6Ho92dwSe4uw0AAGuddkhavXp1Z/YD/8ZHJQkAAEu1a+I2Oh+LSQIAYC1Ckk21PLuNShIAANYgJNlUSyUpEDIKhozFvQEA4OxDSLKplpAkUU0CAMAKhCSb8hGSAACwFCHJptxOh1pWU2gIsgwAAABdjZBkUw6HI7zqNo8mAQCg6xGSbCy8VhKPJgEAoMsRkmzMyzIAAABYhpBkYz4WlAQAwDKEJBvj0SQAAFiHkGRjXkISAACWISTZ2CfDbSwBAABAVyMk2RiVJAAArGN5SFq0aJFycnLk9/uVm5urt99++5Tt165dq9zcXPn9fvXr109Llixp9f727dt17bXXqm/fvnI4HHr00UfbHGPOnDlyOBytXhkZGR35sTqElyUAAACwjKUh6cUXX9Ttt9+ue++9V3l5eRo3bpwmT56sgwcPRmy/b98+TZkyRePGjVNeXp5mz56t2267TcuWLQu3qa2tVb9+/fTwww+fMvicd955KiwsDL+2bdvW4Z/vi/KdWAKAxSQBAOh6bitP/rvf/U7/9V//pVtuuUWS9Oijj+q1117T4sWLNXfu3DbtlyxZoj59+oSrQ0OGDNHGjRv1yCOP6Nprr5UkXXDBBbrgggskSXffffdJz+12u21ZPfq08IrbVJIAAOhyllWSGhsbtWnTJk2aNKnV9kmTJmndunUR91m/fn2b9ldccYU2btyopqamz3X+3bt3KysrSzk5Obrxxhu1d+/ez/cBukDLcFtDExO3AQDoapaFpJKSEgWDQaWnp7fanp6erqKiooj7FBUVRWwfCARUUlJy2ucePXq0nn32Wb322mt64oknVFRUpLFjx6q0tPSk+zQ0NKiysrLVq7P5PSwmCQCAVSyfuO1oedT9CcaYNts+q32k7acyefJkXXvttRo2bJgmTpyoFStWSJKeeeaZk+4zd+5cJSQkhF+9e/c+7fO1V5SneU5SPZUkAAC6nGUhKTU1VS6Xq03VqLi4uE21qEVGRkbE9m63WykpKe3uS0xMjIYNG6bdu3eftM0999yjioqK8KugoKDd5ztdfi8hCQAAq1gWkrxer3Jzc7Vq1apW21etWqWxY8dG3GfMmDFt2r/++usaNWqUPB5Pu/vS0NCg/Px8ZWZmnrSNz+dTfHx8q1dn85+4u62OkAQAQJezdLht1qxZ+uMf/6gnn3xS+fn5mjlzpg4ePKgZM2ZIaq7e3HTTTeH2M2bM0IEDBzRr1izl5+frySef1NKlS3XnnXeG2zQ2NmrLli3asmWLGhsbdfjwYW3ZskV79uwJt7nzzju1du1a7du3Txs2bNB1112nyspKTZ8+ves+/GmIOlFJqmtkThIAAF3N0iUAbrjhBpWWlurBBx9UYWGhhg4dqpUrVyo7O1uSVFhY2GrNpJycHK1cuVIzZ87UwoULlZWVpfnz54dv/5ekI0eO6Pzzzw9//cgjj+iRRx7R+PHjtWbNGknSoUOHNG3aNJWUlKhHjx666KKL9O6774bPaxfhOUk8lgQAgC7nMC0zn/G5VFZWKiEhQRUVFZ029Pbi+wd117JtmjA4TUtvvqBTzgEAwNnk8/z+tvzuNpyc38OcJAAArEJIsrEoQhIAAJYhJNmYP7xOEhO3AQDoaoQkG4tinSQAACxDSLKx8HBbIyEJAICuRkiyMT9LAAAAYBlCko21POCWShIAAF2PkGRjLcNtDYGQQiGWswIAoCsRkmysZeK21ByUAABA1yEk2VjLA24l1koCAKCrEZJszOl0yOs+MS+JkAQAQJciJNlc+CG3hCQAALoUIcnmWCsJAABrEJJsrmUZACpJAAB0LUKSzfH8NgAArEFIsrmWZQCYuA0AQNciJNlcyzIAhCQAALoWIcnmYnzNIam2IWBxTwAAOLsQkmwu2uuWJNVwdxsAAF2KkGRzMb4TIYlKEgAAXYqQZHOxJ4bbCEkAAHQtQpLNfTLcRkgCAKArEZJsLjY83MacJAAAuhIhyeaYkwQAgDUISTbXsgQAw20AAHQtQpLNxZyYk1TNcBsAAF2KkGRz0SwmCQCAJQhJNhfLnCQAACxBSLK5lonb1YQkAAC6FCHJ5lrmJNU2BmWMsbg3AACcPQhJNtdyd1sgZNQQCFncGwAAzh6EJJtrWXFbaq4mAQCArkFIsjmX06EoD89vAwCgqxGSugEmbwMA0PUISd1Ay7ykWlbdBgCgyxCSugFW3QYAoOsRkrqB8PPbGG4DAKDLEJK6gRhW3QYAoMsRkroBQhIAAF2PkNQNxHhPDLexThIAAF2GkNQNUEkCAKDrEZK6gVhCEgAAXY6Q1A20PJqE4TYAALoOIakbiGUJAAAAuhwhqRuI9vJYEgAAuhohqRtombhdy3AbAABdhpDUDTBxGwCArkdI6gaiW+Yk8YBbAAC6DCGpG/ikksRwGwAAXYWQ1A1En1hxm4nbAAB0HUJSN9BSSWoMhNQUDFncGwAAzg6EpG6gZQkASaplyA0AgC5BSOoGvG6nvK7mb1U1k7cBAOgShKRuItZ/YkHJekISAABdgZDUTSRGeSRJ5bWNFvcEAICzAyGpm0iMbg5JZbVNFvcEAICzAyGpm0iK9kqikgQAQFchJHUTiSdCEpUkAAC6BiGpm0iKZk4SAABdiZDUTSTFtFSSCEkAAHQFQlI3wcRtAAC6FiGpm2DiNgAAXYuQ1E1QSQIAoGsRkroJKkkAAHQtQlI38UlIapIxxuLeAABw5iMkdRMtw22BkFFVA89vAwCgsxGSugm/x6Uoj0uSVF7DvCQAADobIakbSQpP3mZeEgAAnY2Q1I188mgSQhIAAJ2NkNSNJMW0PJqE4TYAADobIakboZIEAEDXsTwkLVq0SDk5OfL7/crNzdXbb799yvZr165Vbm6u/H6/+vXrpyVLlrR6f/v27br22mvVt29fORwOPfroox1yXjtIYkFJAAC6jKUh6cUXX9Ttt9+ue++9V3l5eRo3bpwmT56sgwcPRmy/b98+TZkyRePGjVNeXp5mz56t2267TcuWLQu3qa2tVb9+/fTwww8rIyOjQ85rFywoCQBA13EYC1cmHD16tEaOHKnFixeHtw0ZMkTXXHON5s6d26b9XXfdpVdeeUX5+fnhbTNmzNDWrVu1fv36Nu379u2r22+/XbfffvsXOm8klZWVSkhIUEVFheLj409rny9q6Tv79NA/duiqEVl6bNr5XXJOAADOJJ/n97dllaTGxkZt2rRJkyZNarV90qRJWrduXcR91q9f36b9FVdcoY0bN6qp6fSGoNpzXklqaGhQZWVlq1dXaxluo5IEAEDnsywklZSUKBgMKj09vdX29PR0FRUVRdynqKgoYvtAIKCSkpJOO68kzZ07VwkJCeFX7969T+t8HalluO14DSEJAIDOZvnEbYfD0eprY0ybbZ/VPtL2jj7vPffco4qKivCroKDgc52vIyRGswQAAABdxW3ViVNTU+VyudpUb4qLi9tUeVpkZGREbO92u5WSktJp55Ukn88nn893WufoLEksAQAAQJexrJLk9XqVm5urVatWtdq+atUqjR07NuI+Y8aMadP+9ddf16hRo+TxeDrtvHaRGtcc0mobg6rhIbcAAHQqyypJkjRr1ix9+9vf1qhRozRmzBg9/vjjOnjwoGbMmCGpeYjr8OHDevbZZyU138m2YMECzZo1S9/73ve0fv16LV26VM8//3z4mI2NjdqxY0f4z4cPH9aWLVsUGxurAQMGnNZ57SrW51aM16WaxqCKqxqU47P02wcAwBnN0t+yN9xwg0pLS/Xggw+qsLBQQ4cO1cqVK5WdnS1JKiwsbLV2UU5OjlauXKmZM2dq4cKFysrK0vz583XttdeG2xw5ckTnn//J7fGPPPKIHnnkEY0fP15r1qw5rfPaWVq8X/tKalRcWa+c1BiruwMAwBnL0nWSujMr1kmSpOv/e73e23dc86edr6tHZHXZeQEAOBN0i3WS0D5pJ+YlFVfWW9wTAADObISkbiY93i9JOlbVYHFPAAA4sxGSupmWStJRKkkAAHQqQlI3kxZ/YriNShIAAJ2KkNTNpMc1D7dRSQIAoHMRkrqZrMQoSdLh8jqFQtyYCABAZyEkdTO9kqLkdjpU3xRiyA0AgE5ESOpm3C6neiU1V5P2ldRY3BsAAM5chKRuKDuleaXtA6WEJAAAOgshqRvqmxItSdpfWmtxTwAAOHMRkrqhvqlUkgAA6GyEpG6oJSTtKa62uCcAAJy5CEnd0JCM5gfy7S2pUX1T0OLeAABwZiIkdUPp8T4lx3gVDBntPko1CQCAzkBI6oYcDoeGZMZJknYUVljcGwAAzkyEpG6qZcgtv7DK4p4AAHBmIiR1U+dmNYekHYWVFvcEAIAzEyGpmxqS2VJJqpQxPMMNAICORkjqpvr3iJXH5VBVfUCHyuqs7g4AAGccQlI35XU7NSCtefJ2PkNuAAB0OEJSN3ZuJvOSAADoLISkbmxYz+aQlHew3NqOAABwBiIkdWOj+iZLkjYfKFMwxORtAAA6EiGpGxuSGa9Yn1tVDQHmJQEA0MEISd2Yy+nQyOwkSdKancUW9wYAgDMLIambmzo8U5K0eM3HKqqot7g3AACcOQhJ3dx1I3vp/D6JqmkMav6bu63uDgAAZwxCUjfndDp0z+QhkqSX3i9QwfFai3sEAMCZgZB0BrgwJ1njzklVIGS04M09VncHAIAzAiHpDDHz8oGSpL9uPqQDpTUW9wYAgO6PkHSGGNknSeMH9lAwZLRk7cdWdwcAgG6PkHQG+fFlAyRJf910SBv2llrcGwAAujdC0hlkVN9kXTksU01BoxnPbVJFXZPVXQIAoNsiJJ1hfnv9CPXvEaOy2ib98e29VncHAIBui5B0hvF7XLpj0iBJ0oLVe3Tfyx/qcHmdxb0CAKD7ISSdgSYPzdDNY/vKGOlP7x7QZY+s0S3PvK89xdVWdw0AgG6DkHQGcjgcmnP1eXr2uxdqVHaSGgIhvZFfrB88t0n1TUEdKqvVzqIqq7sJAICtOYwxxupOdEeVlZVKSEhQRUWF4uPjre7OSYVCRqt3Fuv2F7aoqiGg7JRoHa9pVF1jUC//6GIN7ZlgdRcBAOgyn+f3N5WkM5zT6dCEIel6YvoopcX5dKC0VlX1AQVCRvf974cKBEOqrG/SzqIqNQZCkpqDFQAAZzsqSe3UXSpJn1bdENCSNR9r04Eyrf/UOkoOh2SMlBjtUWVdk+KjPJpz1Xnq1yNG0V6XBqTFWdhrAAA6zuf5/U1IaqfuGJI+7dUPizTjuU3hr11Oh4IRKkhup0N3XjFIPROjJEnDeyVow77jmjgkXckxXklSMGTkcjq6puMAAHwBhKQu0N1DkiRtPlim0upGDeuZoJRYr/749j6t2HZEZTVNKqyo06lG3RKiPBrbP0UfHKqQz+PU8h+MVWK0Vy0/ToUV9aptDKpPcrS8bkZ1AQD2QEjqAmdCSDqVYMgoEArp8bV7lVdQruqGgDYdKItYbWoR53erpiGgGK9bVQ0BSVKM16UbL+yjbYcrFOtza8b4/nr0jV3qEedTr6QoDcmM16RzMyIGKWOMDh6vVa+k6HClyhgjh4OqFQCgfQhJXeBMD0mRFFbU6YX3CnTViCwdKqvVqh1H9fetR1RZH2jT1uloXtiytjH4mcdNi/NpcGa8MuJ9Ol7TqC0F5eqXGiuv26l39pQo1udWTmqMSqobVFrTqEHpcTonLVYDM+LkczsVMtKXz0lV0BgFgkb7S2u0v6RGe4/VKDslRsN6xcvpcKigrE6DM+LUGAgpxueW0yE1BEL687sHlBDl0fe+3E+Hy+o0MD1Oe0tqdKyqQdUNAV3zpSy5XU5V1DWpoSmoyvqAfG6nYnxu+T1ORXlcent3iQKhkC4bnK5gyGhnUZWSYjzKiPfL4XCoKRhSwfFaldc1KTs5Wimxvs917ctqGtUUDCk11qeqhoASojwyxqiyLqDdxVXKSY1RSqxPpdUNen//cV08IFVxfo9qGwNqChglRHvUEAjK53Z9rvO2hNKmYEg7i6q0s6hK5/WMV/8esXp/33GNzE6S39O+Yx4orVFyjFdxfo8kqbiqXrUNQWWnRIeDcG1jQD63q9Vwbkl1gyrqmhTlcWnn0Sr1SY5Wv9QYORwOBYIh7S6uVp/kaMX43CftQyhk5DzJEHEgGJLL6ThpGK9rDMrtcsjjah3sK+ubFAgaxfvdcjgccjkdMsbo/f1lykmNUY+45u95wfFa1TcFdU56nMpqGtUYDCkx2iOvy9nmnEcr61XfFFR2Skyr8/s9bduerk//QyMYMjpSXqfMBL/cLqc+PlatYMhoYHrkeYj1TUHVNgaVGOVRyBi5XaeuElfVN8njcsrvcelgaa3SE3wKhaS9JdU6NzP+c32GQDCkhhN/d0/1mT69bX9prfokR5/WdIDqhoAq6prCUwtO9g+yll+Zn36v5aaXT/9jr74pqPqmoBKjvafx6U6urjGoKO/n+zv275qCIR0qq1NOakzE90urG5QU7dXh8jr1Sor6wv8QDYWMth2uUNAYfalX4kn/rtU0BLTtcIUu6JvcpVM2CEld4GwMSZEYY/T7VbtUHwjp6+f3VIzXrY+PVWtozwSlxHj1v1sP68l39mvX0aoT1anmH7cRvRLUMylK7+8v07GqBos/xallp0TL43JGXIzT6ZAy4v06UlEvSRqUHqfSmgaVVDdKah6WHNozXruOVoc/p9/j1OShmTpe06iN+48rKzFKCVEeVTcElJng1/7SWh0uq1OU16VAMKRon7vNNUqM9qj6xF2KkhTlcekrg3pow77jOl7TqGivS+ekxWr7kUoFQkZRHpfqmoLhfT0up8prG5UU7VWs363EKI+uOC9D8VEe7ThSqVi/Wx8erlDewXJNOjdd7+4tDX9GScpJjdG+khpJzZ9/RO8ENQRCqm8KatfRalU3BJQY5VF8lEeHymqVnRyj4b0StP1IpQ6U1sjvcam0plEOhzS8Z/O+H51Yuysrwa9z0uMUDBlt2FeqjAS/JgxO19u7j6kp2Fxd/Hd9kqPVr0eM9hRX61BZnaI8Ll2Yk6xor0vp8X4VVtTp42M1Kq9tUpTXqcNldUqJ9Wl0TrJG5yRrX0mtjlbW61h1gzYfKFNyjFe9kqLUI86nirrmX/T1TUGdmxmvv+UdVmV9QL2SotSvR6xivC59cKii1cr20V6XBqbHqaiiXkWV9XI7HTonPS4c4lp+rg6V1YWrsw6HFO/3qGdilOL8bg3JjNeyTYdU1RBQz8QoDeuZoECoec2zxGiP4vxu9U2JUUl1o4oq6uRwOJQQ5VFTMKQYr1tNoZD8bpfKaxtVVtukGJ9LaXF+7S2plkMODUiLVVFlvY5VNSja61Jmgl8fH2v+nsb73UqJ9Z0IblJJdaMyEnzaX1Kr6oZP/lGUEe9XQpRHWYl+VdY3LzESChmV1Tapd3KUlm8+rDi/W8N6JuiN/GIlx3gVDBlV1DWpb0q0zuuZoH6pMcpMiNJHRZXaX1qriromFVfWa2B6nL7UO1E+j1N+t0uPvblb5XVNykmN0cC0OBVW1KmosjlY1weCuqhfirISopRXUKY+yTEyxuhfHxXrS70TlZMao22HK9QUDCnO71Z2cowcDqlfj1g5JK3/uFSbD5YpEDK6sG+yLjknVX/ddEhRHpfOy4rX/31cotRYnxoDIRVW1J84jkfZKdFKivbord0lagqGlJMao6yEKHndTm06UKaKuiadkxYrv8clp9OheH/z3+WmYEhOR3PQzs1OUkVdk4LG6Hh1o9wuh/wel/IOlqmkulFOhzQkM14xPrf2l9TI6XCod3KU+veIVW52kg4er9WGvcd1Uf8Uxfpc2n20Wuv3lsrldMjpcCg7JVpHyuu062i1/B6nBqTFqriyQX2SoxUIGZXVNupA6Sd/p+J8bjkcUkaCX+nxfhUcr1UgZPTlgT2UGOXR4fI6jemXov2ltdp+pEI9Yn3aUVipQ2V16p0crawEv3YXV4f/nvbvEaOc1FjlF1aqvimoiwekKjnGqw8PV2jjgTJJ0uCMOE0dnqm9x2r0fx+XqK4xqDh/88/4Vwal6e7Jg0/2v+d2ISR1AULS52eM0cfHqpUW71f8iepBbWNAG/eXqaiyXkcr6hXldalXUpTe2l2iUMjoknNSdaC0VskxXhkjDc5s/sXzxo6jqmkMyO10al9JjXYUVsrnbv4f+nlZCUqP96lvSoze2n1MtQ1BVTUEFAiGVFHXpF5J0QqGjJqCIZXXNUlGivW7dbymMdxXh0NKiva22tayPdbrVuOJf9WejNftVDBkWg1P+txOxfnd4QDVUU426b6jxfndivK4VNyJofbzfpbMBL9Kq5urMcAX1XKnL+zj6+f31O9v+FKHHpOQ1AUISfbRMuwU53eftKzb4t+HWRoDITkczcMOr2w9osEZcSo4XqdxA1MV7/eotLpBG/Ydl9vp0Ki+yUqK9oRL0aGQUX5RpfYUV+uifimqrGvSzqNVSo/3a3iv5kU6PypsHqJKjPboK4PS5HY69I9thTpcVheuNrQMYUR7XSooq1WUx6VRfZMVCIYUMtLeE5W5uqag3tt3XOMH9lBlfZOSY7xKivbK53Zq/cel2rDvuHJSY/TVoRknKhu1GpWdrNRYnw6X16mirkn/s7FAudlJGpQRp+QYrz44VKHCinqV1zZqf2mtjtc0qE9yjNxOhxKjPfK5nTp4vFYD0mL17Yv6qrSmQT/682bFR3k0sk+S/m9PidIT/OqVFKWclBhF+9zqmehXWpxfxVUN2naoXDk9YlXTENCGvaWqawrK7XIqKdqj/8jtrZc2Figp2qv4KLcuOaf5X6pbD5Vrf0mt1uwsVkMgJLfTobqmoC7MSVaf5Ghd1C9FknSorE4X9E3SsaoGzX9ztxKiPBqSGa+L+6fqwPFafXCoXKGQ0dZDFfK4HJoyLFOpsc1DulmJUTpe06h39pTovX2lCoWk9AS/shL9+vr5PVVa3aiC47XaeqhcA9LiFOVxye1yKO9guXzu5uGjWJ9LXrdTbqdTgzPiNLRXgqrrAzpe06jSmkaVVjeoMRDSqL5J8rld+qioSmU1jbpsSJoCQaPtRyrUMylKA3rEqqYxqIZAUBv2Hte/8o9qYEac9h1rrhr8f+P76XB5nd7YcVRul1NTh2fK4XCoqr5JR8rrlBbvV7THpUde36m0eL8uH5Kut3YdU6zfrWhvc+UiGAqdGIJ165z0OBljtLWgQpkJfo3MTtKB0loVVtRpQFqs9hRXa19JjbYfqVTvpGj1TY1WfVNQR8rrm3/O65u0p7hamw+UqUecT5eck6oPD1cqPd6n6vqAHA4pIdqrj4urFR/l0cfHmttOHpqpiUPSVB8IamjPBG0tqGgeFi+p0cHjNeqZGKVBGfHadqhcw3olqiEQ1J4TVcniqgaNyk7Sdy/J0a6jVdpTXK3MhOZhsQPHa5TbJ0kfH6vR/tIaVdU3ae+xGoWM0fiBPXS4vE7Hqhq1u7hKHpdTVw7LVHKMV42BkD44XCGf26nz+yRq3IAe8nmcenrdfu0prlbflGglRHlUVR/QOenNQ/uJ0R5lJvj10sZD2nW0Shf3T5XL6dB5WfGK8rq0bNMhhYxU1xTUxCFpOi8rQR8fq5YxzUNeR09U7j48UqkJQ9LkdDi0+2i1MhP8kqQYn1tul0PFlc03vhRXNejczHg1BpuHGWO8LnlcTtU0BPRRUZV2F1epvLZJ0V6X4v0eRXldivN7NKZ/irYfrlBpTaPqm4LKSY1RlNelNR8d09fOz9KQzHit/7hUXpdT2SnRkprveJ50Xobi/W4lx3pVXNmgDw6VK9bnVnKsT3/fekSJUZ7w34PUWJ/GD+yh6oaAUmO96psao+ffO6iM+ChlJfp1xXkZqqoP6O3dx3SsqkExPre+1CdReQfLVdcYUHKMT8VV9cqI92vroXI1BZsr3jdc0Fvp8X5VNwRUVd+kpGhvhy96TEjqAoQkAAC6H1bcBgAA+IIISQAAABEQkgAAACIgJAEAAERASAIAAIiAkAQAABABIQkAACACQhIAAEAEhCQAAIAICEkAAAAREJIAAAAiICQBAABEQEgCAACIgJAEAAAQgdvqDnRXxhhJUmVlpcU9AQAAp6vl93bL7/FTISS1U1VVlSSpd+/eFvcEAAB8XlVVVUpISDhlG4c5nSiFNkKhkI4cOaK4uDg5HI4OPXZlZaV69+6tgoICxcfHd+ix8Qmuc9fgOncdrnXX4Dp3nc641sYYVVVVKSsrS07nqWcdUUlqJ6fTqV69enXqOeLj4/kL2AW4zl2D69x1uNZdg+vcdTr6Wn9WBakFE7cBAAAiICQBAABEQEiyIZ/Pp/vvv18+n8/qrpzRuM5dg+vcdbjWXYPr3HWsvtZM3AYAAIiAShIAAEAEhCQAAIAICEkAAAAREJIAAAAiICTZzKJFi5STkyO/36/c3Fy9/fbbVnepW3nrrbd01VVXKSsrSw6HQy+//HKr940xmjNnjrKyshQVFaWvfOUr2r59e6s2DQ0N+vGPf6zU1FTFxMTo6quv1qFDh7rwU9jf3LlzdcEFFyguLk5paWm65pprtHPnzlZtuNYdY/HixRo+fHh4Mb0xY8bon//8Z/h9rnPnmDt3rhwOh26//fbwNq71Fzdnzhw5HI5Wr4yMjPD7trvGBrbxwgsvGI/HY5544gmzY8cO85Of/MTExMSYAwcOWN21bmPlypXm3nvvNcuWLTOSzN/+9rdW7z/88MMmLi7OLFu2zGzbts3ccMMNJjMz01RWVobbzJgxw/Ts2dOsWrXKbN682Vx66aVmxIgRJhAIdPGnsa8rrrjCPPXUU+bDDz80W7ZsMVdeeaXp06ePqa6uDrfhWneMV155xaxYscLs3LnT7Ny508yePdt4PB7z4YcfGmO4zp3hvffeM3379jXDhw83P/nJT8LbudZf3P3332/OO+88U1hYGH4VFxeH37fbNSYk2ciFF15oZsyY0Wrb4MGDzd13321Rj7q3fw9JoVDIZGRkmIcffji8rb6+3iQkJJglS5YYY4wpLy83Ho/HvPDCC+E2hw8fNk6n07z66qtd1vfupri42Egya9euNcZwrTtbUlKS+eMf/8h17gRVVVXmnHPOMatWrTLjx48PhySudce4//77zYgRIyK+Z8drzHCbTTQ2NmrTpk2aNGlSq+2TJk3SunXrLOrVmWXfvn0qKipqdY19Pp/Gjx8fvsabNm1SU1NTqzZZWVkaOnQo34dTqKiokCQlJydL4lp3lmAwqBdeeEE1NTUaM2YM17kT/OhHP9KVV16piRMnttrOte44u3fvVlZWlnJycnTjjTdq7969kux5jXnArU2UlJQoGAwqPT291fb09HQVFRVZ1KszS8t1jHSNDxw4EG7j9XqVlJTUpg3fh8iMMZo1a5YuueQSDR06VBLXuqNt27ZNY8aMUX19vWJjY/W3v/1N5557bviXAte5Y7zwwgvatGmTNm7c2OY9fqY7xujRo/Xss89q4MCBOnr0qH75y19q7Nix2r59uy2vMSHJZhwOR6uvjTFttuGLac815vtwcrfeeqs++OADvfPOO23e41p3jEGDBmnLli0qLy/XsmXLNH36dK1duzb8Ptf5iysoKNBPfvITvf766/L7/Sdtx7X+YiZPnhz+87BhwzRmzBj1799fzzzzjC666CJJ9rrGDLfZRGpqqlwuV5skXFxc3CZVo31a7qA41TXOyMhQY2OjysrKTtoGn/jxj3+sV155RatXr1avXr3C27nWHcvr9WrAgAEaNWqU5s6dqxEjRugPf/gD17kDbdq0ScXFxcrNzZXb7Zbb7dbatWs1f/58ud3u8LXiWnesmJgYDRs2TLt377blzzMhySa8Xq9yc3O1atWqVttXrVqlsWPHWtSrM0tOTo4yMjJaXePGxkatXbs2fI1zc3Pl8XhatSksLNSHH37I9+FTjDG69dZbtXz5cr355pvKyclp9T7XunMZY9TQ0MB17kATJkzQtm3btGXLlvBr1KhR+uY3v6ktW7aoX79+XOtO0NDQoPz8fGVmZtrz57nDp4Kj3VqWAFi6dKnZsWOHuf32201MTIzZv3+/1V3rNqqqqkxeXp7Jy8szkszvfvc7k5eXF15G4eGHHzYJCQlm+fLlZtu2bWbatGkRby/t1auXeeONN8zmzZvNZZddxi28/+YHP/iBSUhIMGvWrGl1K29tbW24Dde6Y9xzzz3mrbfeMvv27TMffPCBmT17tnE6neb11183xnCdO9On724zhmvdEe644w6zZs0as3fvXvPuu++aqVOnmri4uPDvObtdY0KSzSxcuNBkZ2cbr9drRo4cGb6lGqdn9erVRlKb1/Tp040xzbeY3n///SYjI8P4fD7z5S9/2Wzbtq3VMerq6sytt95qkpOTTVRUlJk6dao5ePCgBZ/GviJdY0nmqaeeCrfhWneM7373u+H/J/To0cNMmDAhHJCM4Tp3pn8PSVzrL65l3SOPx2OysrLMN77xDbN9+/bw+3a7xg5jjOn4+hQAAED3xpwkAACACAhJAAAAERCSAAAAIiAkAQAAREBIAgAAiICQBAAAEAEhCQAAIAJCEgB0kDVr1sjhcKi8vNzqrgDoAIQkAACACAhJAAAAERCSAJwxjDGaN2+e+vXrp6ioKI0YMUJ//etfJX0yFLZixQqNGDFCfr9fo0eP1rZt21odY9myZTrvvPPk8/nUt29f/fa3v231fkNDg372s5+pd+/e8vl8Ouecc7R06dJWbTZt2qRRo0YpOjpaY8eO1c6dOzv3gwPoFIQkAGeMn//853rqqae0ePFibd++XTNnztS3vvUtrV27Ntzmpz/9qR555BG9//77SktL09VXX62mpiZJzeHm+uuv14033qht27Zpzpw5uu+++/T000+H97/pppv0wgsvaP78+crPz9eSJUsUGxvbqh/33nuvfvvb32rjxo1yu9367ne/2yWfH0DH4gG3AM4INTU1Sk1N1ZtvvqkxY8aEt99yyy2qra3V97//fV166aV64YUXdMMNN0iSjh8/rl69eunpp5/W9ddfr29+85s6duyYXn/99fD+P/vZz7RixQpt375du3bt0qBBg7Rq1SpNnDixTR/WrFmjSy+9VG+88YYmTJggSVq5cqWuvPJK1dXVye/3d/JVANCRqCQBOCPs2LFD9fX1uvzyyxUbGxt+Pfvss/r444/D7T4doJKTkzVo0CDl5+dLkvLz83XxxRe3Ou7FF1+s3bt3KxgMasuWLXK5XBo/fvwp+zJ8+PDwnzMzMyVJxcXFX/gzAuhabqs7AAAdIRQKSZJWrFihnj17tnrP5/O1Ckr/zuFwSGqe09Ty5xafLrZHRUWdVl88Hk+bY7f0D0D3QSUJwBnh3HPPlc/n08GDBzVgwIBWr969e4fbvfvuu+E/l5WVadeuXRo8eHD4GO+8806r465bt04DBw6Uy+XSsGHDFAqFWs1xAnDmopIE4IwQFxenO++8UzNnzlQoFNIll1yiyspKrVu3TrGxscrOzpYkPfjgg0pJSVF6erruvfdepaam6pprrpEk3XHHHbrgggv00EMP6YYbbtD69eu1YMECLVq0SJLUt29fTZ8+Xd/97nc1f/58jRgxQgcOHFBxcbGuv/56qz46gE5CSAJwxnjooYeUlpamuXPnau/evUpMTNTIkSM1e/bs8HDXww8/rJ/85CfavXu3RowYoVdeeUVer1eSNHLkSL300kv6xS9+oYceekiZmZl68MEHdfPNN4fPsXjxYs2ePVs//OEPVVpaqj59+mj27NlWfFwAnYy72wCcFVruPCsrK1NiYqLV3QHQDTAnCQAAIAJCEgAAQAQMtwEAAERAJQkAACACQhIAAEAEhCQAAIAICEkAAAAREJIAAAAiICQBAABEQEgCAACIgJAEAAAQASEJAAAggv8f6jHw44IiBB0AAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(train_loss_of_every_epoch)\n",
        "ax.set_xlabel('epoch')\n",
        "ax.set_ylabel('loss')\n",
        "ax.set_title('train loss vs epoch')\n",
        "fig.savefig(os.path.join(folder, 'train_loss_vs_epoch.png'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "QNBdYSVjha_P"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(validation_accuracy_of_every_epoch)\n",
        "ax.set_xlabel('epoch')\n",
        "ax.set_ylabel('loss')\n",
        "ax.set_title('validation accuracy vs epoch')\n",
        "fig.savefig(os.path.join(folder, 'validation_accuracy_vs_epoch.png'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "4be457d9cd553d6c07be4d0c8ec34e07be5ade88f5aab9cc8f32b69b8d65c8ac"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
